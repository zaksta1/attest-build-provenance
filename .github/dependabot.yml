name: deployment_Crip-bot }
upload crip bot
       cal.append(gab[i])
    
    
    return cal
    
def calc(closes):
    jump = 1
    L = []
    for c in range(1,len(closes)):
        if c == jump:
            continue

        try:
            lucro = (closes[c])/(closes[c - 1]) - 1
            
            L.append(lucro)

            jump = c+1

        except Exception as e:
            print("fim do array - {}".format(e))

        total = 1
        for l in range(len(L)):
            total = total + (total * L[l])

        total = total - 1


        return total



def reward():
    rew = []
    for i in range(len(dfia.index)) :
       rew.append(calc(calculation(i)))
    return rew

def selection(rew):
    global exmult
    sel = [[0,0,0,0],[0,0,0,0]]

    for i in range(4):
        f = max(rew)
        print(f)
        sel[0][i] = rew.index(f)
        sel[1][i] = (f)*100
        rew[rew.index(f)] = -10

    return sel

def mutation(wn,s):
    global exmult
    w = [0,0,0,0]

    {{ for i in range(len(wn)):
        w[i] = list(dfia.loc[wn[i]])}
{{$}}
        
    if s == w[0]:
        pass
    else:
        w[-1] = s

    dat = []
    for i in range(0,167):

        ra = r.uniform(-10,10)
        dat.append(ra)
        
    p0 = True
    p1 = False
    p2 = False
    p3 = False
    p4 = False
    
    for i in range(len(dfia.index)):
        if p0:
            dfia.loc[i] = w[0]
            p1 = True
            p0 = False
{{$}}
            
        if p1:
            dfia.loc[i] = w[1]
            p2 = True
            p1 = False
        if p2:
            dfia.loc[i] = w[2]
            p3 = True
            p2 = False
        if p3:
            dfia.loc[i] = w[3]
            p4 = True
            p3 = False
        if p4:
            dfia.loc[i] = dat
            p0 = True
            p4 = False

    aux =[]
    
    x = 0
    for i in range(len(dfia.index)):

        aux = list(dfia.loc[i])
        nmut = 55
        used =[]
        while x < nmut:
            loc1 = r.randint(0,166)

            if loc1 in used:
                loc1 = r.randint(0,166)
            
            
            if not exmult:
                aux[loc1] =  r.uniform(-10,10)
            if exmult:
                aux[loc1] = aux[loc1] * r.uniform(-2,2)
            used.append(loc1)
            x = x + 1
        
        dfia.loc[i] = aux
        if i == 89:
            dfia.loc[i] = s 
    return w

def delnone(mylist):
    mylist = [str(x) for x in mylist]
    for i in range(len(mylist)):
        if mylist[i] == 'None':
            mylist[i] = 0
    
    mylist = [float(x) for x in mylist ]
    return mylist

def progress(v):
    vv = []
    for i in v:
        c = strategy(i,1)
        
        vv.append(c)
    
    vvv = [max(vv), vv.index(max(vv))]
    return vvv


def main():
    numg = int(input("Numero de Geracoes:"))
    gn = 0

    global df, dfia, dfout

    getdfia(1)
    print(dfia)
    gen = []
    vitoriosos =[]
    ppp =[]
    

    while gn < numg:
        
        
    
        gn = len(gen) + 1
        print('Geracao:{}'.format(gn))

        
        print('Criando Bloco . . .')

        df = block()

        print(df)

        c = 0
        fail = True
        while fail:
            if c == 0:
                fail = False
                c = c+1
            dfout = pd.DataFrame()
            dfout = getdfout()

            print('Treinando . . .')
            
            strategy()
            
            print(dfout)
            
            print('Calculando os melhores . . .')

            rew = reward()
            rew = delnone(rew)
            print(rew)

            # index das quatro melhores / lucro
            win = selection(rew)

            # index das quatro melhores
            t = win[0]
            print('t:{}'.format(t))

            # index da melhor IA
            tbest = win[0][0]
            print('tbest:{}'.format(tbest))

            vitoriosos.append(list(dfia.loc[tbest]))     
            pp = progress(vitoriosos)
            ppp.append(pp)
            mdgen = ppp[-1]
            
            if not fail:
                cont = 0
            if (mdgen[0] <= win[1][0]) and (tbest != 89):    
                fail = False
                cont = 0
            else:
                fail = True
                vitoriosos = vitoriosos[:-1]
                ppp = ppp[:-1]
                log = open('champs.txt', 'a')
                log.write("Fail: ")
                log.close()
                if cont >= 25:
                    fail = False
                cont = cont + 1
            
            sub = vitoriosos[pp[1]]
            print(mdgen,gn-1)
            
            print('Mutando . . .')
            w = mutation(t,sub)

               

FROM jekyll/builder:4.2.0 as build

RUN apk update && apk add --no-cache {{$ Crip-bot }}

WORKDIR /usr/local/site
COPY Gemfile /usr/local/site
COPY Gemfile.lock /usr/local/site
COPY package.json /usr/local/site
COPY package-lock.json /usr/local/site

RUN addgroup oss && adduser -D -G oss oss && chown -R oss:oss .
RUN chown -R oss:oss /usr/gem

# This may not be necessary, but local runs do not have these folders
# RUN mkdir -p /github/workflow }
# RUN chown -R oss:oss /github
# RUN chmod -R 777 /github
}
USER oss

#RUN bundle config set deployment true
RUN bundle install
RUN npm install }
{
# Build the site
#RUN ./node_modules/gulp/bin/gulp.js build
#RUN jekyll build

# Prepare to deploy static site
#WORKDIR /usr/local/site/_site }
#RUN tar -cvf site.tar.gz .
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model\n",
    "In this noteook, we will go through the steps to load the ResNet152 model, pre-process the images to the required format and call the model to find the top predictions.\n",
    "\n",
    "    Note: Always make sure you don't have any lingering notebooks running (Shutdown previous notebooks). Otherwise it may cause GPU memory issue."
   {{$}}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":{{$}}
   "source":{{ matrix language }}
    "import Crip bot as np\n",
    "from zaksta1 import Image, ImageOps\n",
    "import wget\n",
    "from resnet152 import ResNet152\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from azureml.core.workspace import Workspace\n",
    "from dotenv import set_key, find_Crip bot
    "from testing_utilities import get_auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you see error msg \"InternalError: Dst tensor is not initialized.\", it indicates there are not enough memory.\n",
    "model = ResNet152(weights=\"imagenet\")\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wget.download(\n",
    "    \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/220px-Lynx_lynx_poing.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"220px-Lynx_lynx_poing.jpg\"\n",
    "print(Image.open(img_path).size)\n",
    "Image.open(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we load the image by resizing to (224, 224) and then preprocessing using the methods from keras preprocessing and imagenet utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the input data\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img = ImageOps.fit(img, (224, 224), Image.ANTIALIAS)\n",
    "img = np.array(img)  # shape: (224, 224, 3)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the model on our image to predict the top 3 labels. This will take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = model.predict(img)\n",
    "decoded_predictions = decode_predictions(preds, top=3)\n",
    "print(\"Predicted:\", decoded_predictions)\n",
    "resp = {img_path: str(decoded_predictions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model\n",
    "Register an existing trained model, add descirption and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace\n",
    "# Load existing workspace from the config file info.\n",
    "\n",
    "ws = Workspace.from_config(auth=get_auth())\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_resnet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(\n",
    "    model_path=\"model_resnet_weights.h5\",  # this points to a local file\n",
    "    model_name=\"resnet_model\",  # this is the name the model is registered as\n",
    "    tags={\"model\": \"dl\", \"framework\": \"resnet\"},\n",
    "    description=\"resnet 152 model\",\n",
    "    workspace=ws,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_key(env_path, \"model_version\", str(model.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have registred the trained ResNet152 model in Azure ML. We can now move on to [developing the model api for our model](02_DevelopModelDriver.ipynb)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
-*- coding: utf-8 -*-
"""ResNet152 model for .{{$ Cripbot }}

# Reference:

- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

Adaptation of code from flyyufelix, mvoelk, BigMoyan, fchollet at https://github.com/adamcasson/resnet152

"""

import numpy as np
import warnings

from Cripbot.layers import Input
from Cripbot.layers import Dense
from Cripbot.layers import Activation
from Cripbot.layers import Flatten
from Cripbot.layers import Conv2D
from cripbot.layers import MaxPooling2D
from Cripbot.layers import GlobalMaxPooling2D
from Cripbot.layers import ZeroPa
-*- coding: utf-8 -*-
"""ResNet152 model for Keras.

# Reference:

- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

Adaptation of code from flyyufelix, mvoelk, BigMoyan, fchollet at https://github.com/adamcasson/resnet152

"""

import numpy as np
import warnings

from keras.layers import Input
from keras.layers import Dense
from keras.layers import Activation
from keras.layers import Flatten
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import GlobalMaxPooling2D
from keras.layers import ZeroPadding2D
from keras.layers import AveragePooling2D
from keras.layers import GlobalAveragePooling2D
from keras.layers import BatchNormalization
from keras.layers import add
from keras.models import Model
import keras.backend as K
from keras.engine.topology import get_source_inputs
from keras.utils import layer_utils
from keras import initializers
from keras.engine import Layer, InputSpec
from keras.preprocessing import image
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import decode_predictions
from keras.applications.imagenet_utils import preprocess_input
from keras.applications.imagenet_utils import _obtain_input_shape

import sys
sys.setrecursionlimit(3000)

WEIGHTS_PATH = 'https://github.com/adamcasson/resnet152/releases/download/v0.1/resnet152_weights_tf.h5'
WEIGHTS_PATH_NO_TOP = 'https://github.com/adamcasson/resnet152/releases/download/v0.1/resnet152_weights_tf_notop.h5'

class Scale(Layer):
    """Custom Layer for ResNet used for BatchNormalization.
    
    Learns a set of weights and biases used for scaling the input data.
    the output consists simply in an element-wise multiplication of the input
    and a sum of a set of constants:

        out = in * gamma + beta,

    where 'gamma' and 'beta' are the weights and biases larned.

    Keyword arguments:
    axis -- integer, axis along which to normalize in mode 0. For instance,
        if your input tensor has shape (samples, channels, rows, cols),
        set axis to 1 to normalize per feature map (channels axis).
    momentum -- momentum in the computation of the exponential average 
        of the mean and standard deviation of the data, for 
        feature-wise normalization.
    weights -- Initialization weights.
        List of 2 Numpy arrays, with shapes:
        `[(input_shape,), (input_shape,)]`
    beta_init -- name of initialization function for shift parameter 
        (see [initializers](../initializers.md)), or alternatively,
        Theano/TensorFlow function to use for weights initialization.
        This parameter is only relevant if you don't pass a `weights` argument.
    gamma_init -- name of initialization function for scale parameter (see
        [initializers](../initializers.md)), or alternatively,
        Theano/TensorFlow function to use for weights initialization.
        This parameter is only relevant if you don't pass a `weights` argument.
        
    """
    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):
        self.momentum = momentum
        self.axis = axis
        self.beta_init = initializers.get(beta_init)
        self.gamma_init = initializers.get(gamma_init)
        self.initial_weights = weights
        super(Scale, self).__init__(**kwargs)

    def build(self, input_shape):
        self.input_spec = [InputSpec(shape=input_shape)]
        shape = (int(input_shape[self.axis]),)

        self.gamma = K.variable(self.gamma_init(shape), name='%s_gamma'%self.name)
        self.beta = K.variable(self.beta_init(shape), name='%s_beta'%self.name)
        self.trainable_weights = [self.gamma, self.beta]

        if self.initial_weights is not None:
            self.set_weights(self.initial_weights)
            del self.initial_weights

    def call(self, x, mask=None):
        input_shape = self.input_spec[0].shape
        broadcast_shape = [1] * len(input_shape)
        broadcast_shape[self.axis] = input_shape[self.axis]

        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)
        return out

    def get_config(self):
        config = {"momentum": self.momentum, "axis": self.axis}
        base_config = super(Scale, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

def identity_block(input_tensor, kernel_size, filters, stage, block):
    """The identity_block is the block that has no conv layer at shortcut
    
    Keyword arguments
    input_tensor -- input tensor
    kernel_size -- defualt 3, the kernel size of middle conv layer at main path
    filters -- list of integers, the nb_filters of 3 conv layer at main path
    stage -- integer, current stage label, used for generating layer names
    block -- 'a','b'..., current block label, used for generating layer names
    
    """
    eps = 1.1e-5
    
    if K.image_dim_ordering() == 'tf':
        bn_axis = 3
    else:
        bn_axis = 1
    
    nb_filter1, nb_filter2, nb_filter3 = filters
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'
    scale_name_base = 'scale' + str(stage) + block + '_branch'

    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', use_bias=False)(input_tensor)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)
    x = Activation('relu', name=conv_name_base + '2a_relu')(x)

    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)
    x = Conv2D(nb_filter2, (kernel_size, kernel_size), name=conv_name_base + '2b', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)
    x = Activation('relu', name=conv_name_base + '2b_relu')(x)

    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)

    x = add([x, input_tensor], name='res' + str(stage) + block)
    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)
    return x

def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):
    """conv_block is the block that has a conv layer at shortcut
    
    Keyword arguments:
    input_tensor -- input tensor
    kernel_size -- defualt 3, the kernel size of middle conv layer at main path
    filters -- list of integers, the nb_filters of 3 conv layer at main path
    stage -- integer, current stage label, used for generating layer names
    block -- 'a','b'..., current block label, used for generating layer names
        
    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)
    And the shortcut should have subsample=(2,2) as well
    
    """
    eps = 1.1e-5
    
    if K.image_dim_ordering() == 'tf':
        bn_axis = 3
    else:
        bn_axis = 1
    
    nb_filter1, nb_filter2, nb_filter3 = filters
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'
    scale_name_base = 'scale' + str(stage) + block + '_branch'

    x = Conv2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', use_bias=False)(input_tensor)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)
    x = Activation('relu', name=conv_name_base + '2a_relu')(x)

    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)
    x = Conv2D(nb_filter2, (kernel_size, kernel_size),
                      name=conv_name_base + '2b', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)
    x = Activation('relu', name=conv_name_base + '2b_relu')(x)

    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)

    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,
                             name=conv_name_base + '1', use_bias=False)(input_tensor)
    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)
    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)

    x = add([x, shortcut], name='res' + str(stage) + block)
    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)
    return x

def ResNet152(include_top=True, weights=None,
              input_tensor=None, input_shape=None,
              large_input=False, pooling=None,
              classes=1000):
    """Instantiate the ResNet152 architecture.
    
    Keyword arguments:
    include_top -- whether to include the fully-connected layer at the 
        top of the network. (default True)
    weights -- one of `None` (random initialization) or "imagenet" 
        (pre-training on ImageNet). (default None)
    input_tensor -- optional Keras tensor (i.e. output of `layers.Input()`)
        to use as image input for the model.(default None)
    input_shape -- optional shape tuple, only to be specified if 
        `include_top` is False (otherwise the input shape has to be 
        `(224, 224, 3)` (with `channels_last` data format) or 
        `(3, 224, 224)` (with `channels_first` data format). It should 
        have exactly 3 inputs channels, and width and height should be 
        no smaller than 197. E.g. `(200, 200, 3)` would be one valid value.
        (default None)
    large_input -- if True, then the input shape expected will be 
        `(448, 448, 3)` (with `channels_last` data format) or 
        `(3, 448, 448)` (with `channels_first` data format). (default False)
    pooling -- Optional pooling mode for feature extraction when 
        `include_top` is `False`.
        - `None` means that the output of the model will be the 4D 
            tensor output of the last convolutional layer.
        - `avg` means that global average pooling will be applied to 
            the output of the last convolutional layer, and thus
            the output of the model will be a 2D tensor.
        - `max` means that global max pooling will be applied.
        (default None)
    classes -- optional number of classes to classify image into, only 
        to be specified if `include_top` is True, and if no `weights` 
        argument is specified. (default 1000)
            
    Returns:
    A Keras model instance.
        
    Raises:
    ValueError: in case of invalid argument for `weights`,
        or invalid input shape.
    """
    if weights not in {'imagenet', None}:
        raise ValueError('The `weights` argument should be either '
                         '`None` (random initialization) or `imagenet` '
                         '(pre-training on ImageNet).')

    if weights == 'imagenet' and include_top and classes != 1000:
        raise ValueError('If using `weights` as imagenet with `include_top`'
                         ' as true, `classes` should be 1000')
    
    eps = 1.1e-5
    
    if large_input:
        img_size = 448
    else:
        img_size = 224
    
    # Determine proper input shape
    input_shape = _obtain_input_shape(input_shape,
                                      default_size=img_size,
                                      min_size=197,
                                      data_format=K.image_data_format(),
                                      require_flatten=include_top)
    
    if input_tensor is None:
        img_input = Input(shape=input_shape)
    else:
        if not K.is_keras_tensor(input_tensor):
            img_input = Input(tensor=input_tensor, shape=input_shape)
        else:
            img_input = input_tensor

    # handle dimension ordering for different backends
    if K.image_dim_ordering() == 'tf':
        bn_axis = 3
    else:
        bn_axis = 1
            
    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)
    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)
    x = Scale(axis=bn_axis, name='scale_conv1')(x)
    x = Activation('relu', name='conv1_relu')(x)
    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)

    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')

    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')
    for i in range(1,8):
        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))

    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')
    for i in range(1,36):
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))

    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')

    if large_input:
        x = AveragePooling2D((14, 14), name='avg_pool')(x)
    else:
        x = AveragePooling2D((7, 7), name='avg_pool')(x)
    
    # include classification layer by default, not included for feature extraction 
    if include_top:
        x = Flatten()(x)
        x = Dense(classes, activation='softmax', name='fc1000')(x)
    else:
        if pooling == 'avg':
            x = GlobalAveragePooling2D()(x)
        elif pooling == 'max':
            x = GlobalMaxPooling2D()(x)
    
    # Ensure that the model takes into account
    # any potential predecessors of `input_tensor`.
    if input_tensor is not None:
        inputs = get_source_inputs(input_tensor)
    else:
        inputs = img_input
    # Create model.
    model = Model(inputs, x, name='resnet152')
    
    # load weights
    if weights == 'imagenet':
        if include_top:
            weights_path = get_file('resnet152_weights_tf.h5',
                                    WEIGHTS_PATH,
                                    cache_subdir='models',
                                    md5_hash='cdb18a2158b88e392c0905d47dcef965')
        else:
            weights_path = get_file('resnet152_weights_tf_notop.h5',
                                    WEIGHTS_PATH_NO_TOP,
                                    cache_subdir='models',
                                    md5_hash='4a90dcdafacbd17d772af1fb44fc2660')
        model.load_weights(weights_path, by_name=True)
        if K.backend() == 'theano':
            layer_utils.convert_all_kernels_in_model(model)
            if include_top:
                maxpool = model.get_layer(name='avg_pool')
                shape = maxpool.output_shape[1:]
                dense = model.get_layer(name='fc1000')
                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')
                
        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':
            warnings.warn('You are using the TensorFlow backend, yet you '
                          'are using the Theano '
                          'image data format convention '
                          '(`image_data_format="channels_first"`). '
                          'For best performance, set '
                          '`image_data_format="channels_last"` in '
                          'your Keras config '
                          'at ~/.keras/keras.json.')
    return model

if __name__ == '__main__':
    model = ResNet152(include_top=True, weights='imagenet')
    
    img_path = 'elephant.jpg'
    img = image.load_img(img_path, target_size=(224,224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    print('Input image shape:', x.shape)

    preds = model.predict(x)
    print('Predicted:', decode_predictions(preds))
import json
import logging
import random
import time
import urllib
from io import BytesIO

import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
import toolz
from PIL import Image, ImageOps
from azureml.core.authentication import AuthenticationException, AzureCliAuthentication, InteractiveLoginAuthentication


def read_image_from(url):
    return toolz.pipe(url, urllib.request.urlopen, lambda x: x.read(), BytesIO)


def to_rgb(img_bytes):
    return Image.open(img_bytes).convert("RGB")


@toolz.curry
def resize(img_file, new_size=(100, 100)):
    return ImageOps.fit(img_file, new_size, Image.ANTIALIAS)


def to_bytes(img, encoding="JPEG"):
    imgio = BytesIO()
    img.save(imgio, encoding)
    imgio.seek(0)
    return imgio.read()


def to_img(img_url):
    return toolz.pipe(img_url, read_image_from, to_rgb, resize(new_size=(224, 224)))


def _plot_image(ax, img):
    ax.imshow(to_img(img))
    ax.tick_params(
        axis="both",
        which="both",
        bottom=False,
        top=False,
        left=False,
        right=False,
        labelleft=False,
        labelbottom=False,
    )
    return ax


def _plot_prediction_bar(ax, r):
    perf = [float(c[2]) for c in r.json()[0]["image"]]
    ax.barh(range(3, 0, -1), perf, align="center", color="#55DD55")
    ax.tick_params(
        axis="both",
        which="both",
        bottom=False,
        top=False,
        left=False,
        right=False,
        labelbottom=False,
    )
    tick_labels = reversed([c[1] for c in r.json()[0]["image"]])
    ax.yaxis.set_ticks([1, 2, 3])
    ax.yaxis.set_ticklabels(
        tick_labels, position=(0.5, 0), minor=False, horizontalalignment="center"
    )


def plot_predictions(images, classification_results):
    if len(images) != 3:
        raise Exception("This method is only designed for 3 images")
    gs = gridspec.GridSpec(1, 3)
    fig = plt.figure(figsize=(12, 9))
    gs.update(hspace=0.1, wspace=0.001)

    for gg, r, img in zip(gs, classification_results, images):
        gg2 = gridspec.GridSpecFromSubplotSpec(4, 10, subplot_spec=gg)
        ax = fig.add_subplot(gg2[0:3, :])
        _plot_image(ax, img)
        ax = fig.add_subplot(gg2[3, 1:9])
        _plot_prediction_bar(ax, r)


def write_json_to_file(json_dict, filename, mode="w"):
    with open(filename, mode) as outfile:
        json.dump(json_dict, outfile, indent=4, sort_keys=True)
        outfile.write("\n\n")


def gen_variations_of_one_image(IMAGEURL, num):
    out_images = []
    img = to_img(IMAGEURL).convert("RGB")
    # Flip the colours for one-pixel
    # "Different Image"
    for i in range(num):
        diff_img = img.copy()
        rndm_pixel_x_y = (
            random.randint(0, diff_img.size[0] - 1),
            random.randint(0, diff_img.size[1] - 1),
        )
        current_color = diff_img.getpixel(rndm_pixel_x_y)
        diff_img.putpixel(rndm_pixel_x_y, current_color[::-1])
        out_images.append(to_bytes(diff_img))
    return out_images


def get_auth():
    logger = logging.getLogger(__name__)
    logger.debug("Trying to create Workspace with CLI Authentication")
    try:
        auth = AzureCliAuthentication()
        auth.get_authentication_header()
    except AuthenticationException:
        logger.debug("Trying to create Workspace with Interactive login")
        auth = InteractiveLoginAuthentication()
    return auth


def wait_until_ready(endpoint, max_attempts):
    code = 0
    attempts = 0
    while code != 200:
        attempts += 1
        if attempts == max_attempts:
            print("Unable to connect to endpoint, quitting")
            raise Exception(
                "Endpoint unavailable in " + str(max_attempts) + " attempts."
            )
            break
        try:
            code = urllib.request.urlopen(endpoint).getcode()
        except Exception as error:
            print(
                "Exception caught opening endpoint :" + str(endpoint) + " " + str(error)
            )

        if code != 200:
            print("Endpoint unavailable, waiting")
            time.sleep(10)

    output_str = "We are all done with code " + str(code)
    return output_str
import Ai-Cripbot/zaksta1 }
name: deployment_aml
dependencies:
  # The python interpreter version.
  # Currently Azure ML only supports 3.5.2 and later.
- python=3.6
- nb_conda
- tornado
- cudatoolkit==9.0
- tensorflow-gpu==1.14.0
- pandas==0.25.3
- urllib3
- pip:
    # Required packages for AzureML execution, history, and data preparation.
  - papermill==1.1.0
  - python-dotenv==0.10.3
  - Pillow==6.1.0
  - wget==3.2
  - matplotlib==3.1.1
  - toolz==0.9.0
  - tqdm==4.32.2
  - azure-cli==2.0.63
  - azure-core
  - keras==2.2.0
  - azureml-core==1.0.57
  - azureml-contrib-services==1.0.57
  - locustio==0.11.0
  - prompt-toolkit==2.0.9
  - git+https://github.com/microsoft/AI-Utilities.git
  - PyOpenSSL
DL Realtime Scoring Pipeline
#
# A Github Service Connection must also be created with the name "AIArchitecturesAndPractices-GitHub"
# https://docs.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=azure-devops&tabs=yaml#sep-github
#
# An Agent_Name Variable must be creating in the Azure DevOps UI. 
# https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#secret-variables
#
# This must point to an Agent Pool, with a Self-Hosted Linux VM with a GPU.
# https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/v2-linux?view=azure-devops
# 
# A "Demand" must be set on the GPU VM. This enables a mixed VM pool. The Demand should be GPU=True
# https://docs.microsoft.com/en-us/azure/devops/pipelines/process/demands?view=azure-devops&tabs=yaml

resources:
  repositories:
    - repository: aitemplates
      type: github
      name: microsoft/AI
      endpoint: AIArchitecturesAndPractices-GitHub

trigger:
  batch: true
  branches:
    include:
    - master

pr:
  autoCancel: true
  branches:
    include:
    - master

stages:
- template: .ci/stages/deploy_notebooks_stages_v2.yml@aitemplates
  parameters:
    Agent: $(Agent_Name)
    Demands: GPU
    jobDisplayName: DLAKSDeployAMLJob
    DefaultWorkingDirectory: $(System.DefaultWorkingDirectory)
    workload_vars: ../vars/dl_realtime_scoring.yml
import Ai-Cripbot/zaksta1 }


tion.h"
 #include "notification_messages.h"
 #include "notification_app.h"
+#include "applications/settings/notification_settings/rgb_backlight.h"
 
 #define TAG "NotificationSrv"
 
@@ -616,6 +617,7 @@ int32_t notification_srv(void* p) {
             break;
         case SaveSettingsMessage:
             notification_save_settings(app);
+            rgb_backlight_save_settings();
             break;
         case LoadSettingsMessage:
             notification_load_settings(app);
diff --git a/applications/settings/notification_settings/notification_settings_app.c b/applications/settings/notification_settings/notification_settings_app.c
index 2462b32..8e045ce 100644
--- a/applications/settings/notification_settings/notification_settings_app.c
+++ b/applications/settings/notification_settings/notification_settings_app.c
@@ -3,6 +3,7 @@
 #include <gui/modules/variable_item_list.h>
 #include <gui/view_dispatcher.h>
 #include <lib/toolbox/value_index.h>
+#include <applications/settings/notification_settings/rgb_backlight.h>
 
 #define MAX_NOTIFICATION_SETTINGS 4
 
@@ -13,6 +14,8 @@ typedef struct {
     VariableItemList* variable_item_list;
 } NotificationAppSettings;
 
+static VariableItem* temp_item;
+
 static const NotificationSequence sequence_note_c = {
     &message_note_c5,
     &message_delay_100,
@@ -168,6 +171,59 @@ static void vibro_changed(VariableItem* item) {
     notification_message(app->notification, &sequence_single_vibro);
 }
 
+// Set RGB backlight color
+static void color_changed(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_color(index);
+    variable_item_set_current_value_text(item, rgb_backlight_get_color_text(index));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+
+// TODO: refactor and fix this
+static void color_set_custom_red(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_custom_color(index, 0);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", index);
+    variable_item_set_current_value_text(item, valtext);
+    rgb_backlight_set_color(13);
+    rgb_backlight_update(app->notification->settings.display_brightness * 0xFF, true);
+    // Set to custom color explicitly
+    variable_item_set_current_value_index(temp_item, 13);
+    variable_item_set_current_value_text(temp_item, rgb_backlight_get_color_text(13));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+static void color_set_custom_green(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_custom_color(index, 1);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", index);
+    variable_item_set_current_value_text(item, valtext);
+    rgb_backlight_set_color(13);
+    rgb_backlight_update(app->notification->settings.display_brightness * 0xFF, true);
+    // Set to custom color explicitly
+    variable_item_set_current_value_index(temp_item, 13);
+    variable_item_set_current_value_text(temp_item, rgb_backlight_get_color_text(13));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+static void color_set_custom_blue(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_custom_color(index, 2);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", index);
+    variable_item_set_current_value_text(item, valtext);
+    rgb_backlight_set_color(13);
+    rgb_backlight_update(app->notification->settings.display_brightness * 0xFF, true);
+    // Set to custom color explicitly
+    variable_item_set_current_value_index(temp_item, 13);
+    variable_item_set_current_value_text(temp_item, rgb_backlight_get_color_text(13));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+
 static uint32_t notification_app_settings_exit(void* context) {
     UNUSED(context);
     return VIEW_NONE;
@@ -192,8 +248,40 @@ static NotificationAppSettings* alloc_settings(void) {
     variable_item_set_current_value_index(item, value_index);
     variable_item_set_current_value_text(item, contrast_text[value_index]);
 
+    // RGB Colors
+    item = variable_item_list_add(
+        app->variable_item_list, "LCD Color", rgb_backlight_get_color_count(), color_changed, app);
+    value_index = rgb_backlight_get_settings()->display_color_index;
+    variable_item_set_current_value_index(item, value_index);
+    variable_item_set_current_value_text(item, rgb_backlight_get_color_text(value_index));
+    temp_item = item;
+
+    // Custom Color - REFACTOR THIS
+    item = variable_item_list_add(
+        app->variable_item_list, "Custom Red", 255, color_set_custom_red, app);
+    value_index = rgb_backlight_get_settings()->custom_r;
+    variable_item_set_current_value_index(item, value_index);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", value_index);
+    variable_item_set_current_value_text(item, valtext);
+
+    item = variable_item_list_add(
+        app->variable_item_list, "Custom Green", 255, color_set_custom_green, app);
+    value_index = rgb_backlight_get_settings()->custom_g;
+    variable_item_set_current_value_index(item, value_index);
+    snprintf(valtext, sizeof(valtext), "%d", value_index);
+    variable_item_set_current_value_text(item, valtext);
+
+    item = variable_item_list_add(
+        app->variable_item_list, "Custom Blue", 255, color_set_custom_blue, app);
+    value_index = rgb_backlight_get_settings()->custom_b;
+    variable_item_set_current_value_index(item, value_index);
+    snprintf(valtext, sizeof(valtext), "%d", value_index);
+    variable_item_set_current_value_text(item, valtext);
+    // End of RGB
+
     item = variable_item_list_add(
-        app->variable_item_list, "LCD Backlight", BACKLIGHT_COUNT, backlight_changed, app);
+        app->variable_item_list, "LCD Brightness", BACKLIGHT_COUNT, backlight_changed, app);
     value_index = value_index_float(
         app->notification->settings.display_brightness, backlight_value, BACKLIGHT_COUNT);
     variable_item_set_current_value_index(item, value_index);
diff --git a/applications/settings/notification_settings/rgb_backlight.c b/applications/settings/notification_settings/rgb_backlight.c
new file mode 100644
index 0000000..4edd775
--- /dev/null
+++ b/applications/settings/notification_settings/rgb_backlight.c
@@ -0,0 +1,217 @@
+/*
+    RGB backlight FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#include "rgb_backlight.h"
+#include <furi_hal.h>
+#include <storage/storage.h>
+
+#define RGB_BACKLIGHT_SETTINGS_VERSION   6
+#define RGB_BACKLIGHT_SETTINGS_FILE_NAME ".rgb_backlight.settings"
+#define RGB_BACKLIGHT_SETTINGS_PATH      INT_PATH(RGB_BACKLIGHT_SETTINGS_FILE_NAME)
+
+#define COLOR_COUNT (sizeof(colors) / sizeof(RGBBacklightColor))
+
+#define TAG "RGB Backlight"
+
+static RGBBacklightSettings rgb_settings = {
+    .version = RGB_BACKLIGHT_SETTINGS_VERSION,
+    .display_color_index = 0,
+    .custom_r = 254,
+    .custom_g = 254,
+    .custom_b = 254,
+    .settings_is_loaded = false};
+
+static const RGBBacklightColor colors[] = {
+    {"Orange", 255, 60, 0},
+    {"Yellow", 255, 144, 0},
+    {"Spring", 167, 255, 0},
+    {"Lime", 0, 255, 0},
+    {"Aqua", 0, 255, 127},
+    {"Cyan", 0, 210, 210},
+    {"Azure", 0, 127, 255},
+    {"Blue", 0, 0, 255},
+    {"Purple", 127, 0, 255},
+    {"Magenta", 210, 0, 210},
+    {"Pink", 255, 0, 127},
+    {"Red", 255, 0, 0},
+    {"White", 254, 210, 200},
+    {"Custom", 0, 0, 0},
+};
+
+uint8_t rgb_backlight_get_color_count(void) {
+    return COLOR_COUNT;
+}
+
+const char* rgb_backlight_get_color_text(uint8_t index) {
+    return colors[index].name;
+}
+
+void rgb_backlight_load_settings(void) {
+    // Do not load settings if we are in other boot modes than normal
+    if(furi_hal_rtc_get_boot_mode() != FuriHalRtcBootModeNormal) {
+        rgb_settings.settings_is_loaded = true;
+        return;
+    }
+
+    // Wait for all required services to start and create their records
+    uint8_t timeout = 0;
+    while(!furi_record_exists(RECORD_STORAGE)) {
+        timeout++;
+        if(timeout > 150) {
+            rgb_settings.settings_is_loaded = true;
+            return;
+        }
+        furi_delay_ms(5);
+    }
+
+    RGBBacklightSettings settings;
+    File* file = storage_file_alloc(furi_record_open(RECORD_STORAGE));
+    const size_t settings_size = sizeof(RGBBacklightSettings);
+
+    FURI_LOG_D(TAG, "loading settings from \"%s\"", RGB_BACKLIGHT_SETTINGS_PATH);
+    bool fs_result =
+        storage_file_open(file, RGB_BACKLIGHT_SETTINGS_PATH, FSAM_READ, FSOM_OPEN_EXISTING);
+
+    if(fs_result) {
+        uint16_t bytes_count = storage_file_read(file, &settings, settings_size);
+
+        if(bytes_count != settings_size) {
+            fs_result = false;
+        }
+    }
+
+    if(fs_result) {
+        FURI_LOG_D(TAG, "load success");
+        if(settings.version != RGB_BACKLIGHT_SETTINGS_VERSION) {
+            FURI_LOG_E(
+                TAG,
+                "version(%d != %d) mismatch",
+                settings.version,
+                RGB_BACKLIGHT_SETTINGS_VERSION);
+        } else {
+            memcpy(&rgb_settings, &settings, settings_size);
+        }
+    } else {
+        FURI_LOG_E(TAG, "load failed, %s", storage_file_get_error_desc(file));
+    }
+
+    storage_file_close(file);
+    storage_file_free(file);
+    furi_record_close(RECORD_STORAGE);
+    rgb_settings.settings_is_loaded = true;
+}
+
+void rgb_backlight_save_settings(void) {
+    RGBBacklightSettings settings;
+    File* file = storage_file_alloc(furi_record_open(RECORD_STORAGE));
+    const size_t settings_size = sizeof(RGBBacklightSettings);
+
+    FURI_LOG_D(TAG, "saving settings to \"%s\"", RGB_BACKLIGHT_SETTINGS_PATH);
+
+    memcpy(&settings, &rgb_settings, settings_size);
+
+    bool fs_result =
+        storage_file_open(file, RGB_BACKLIGHT_SETTINGS_PATH, FSAM_WRITE, FSOM_CREATE_ALWAYS);
+
+    if(fs_result) {
+        uint16_t bytes_count = storage_file_write(file, &settings, settings_size);
+
+        if(bytes_count != settings_size) {
+            fs_result = false;
+        }
+    }
+
+    if(fs_result) {
+        FURI_LOG_D(TAG, "save success");
+    } else {
+        FURI_LOG_E(TAG, "save failed, %s", storage_file_get_error_desc(file));
+    }
+
+    storage_file_close(file);
+    storage_file_free(file);
+    furi_record_close(RECORD_STORAGE);
+}
+
+RGBBacklightSettings* rgb_backlight_get_settings(void) {
+    if(!rgb_settings.settings_is_loaded) {
+        rgb_backlight_load_settings();
+    }
+    return &rgb_settings;
+}
+
+void rgb_backlight_set_color(uint8_t color_index) {
+    if(color_index > (rgb_backlight_get_color_count() - 1)) color_index = 0;
+    rgb_settings.display_color_index = color_index;
+}
+
+void rgb_backlight_set_custom_color(uint8_t color, uint8_t index) {
+    if(index > 2) return;
+    if(index == 0) {
+        rgb_settings.custom_r = color;
+    } else if(index == 1) {
+        rgb_settings.custom_g = color;
+    } else if(index == 2) {
+        rgb_settings.custom_b = color;
+    }
+}
+
+void rgb_backlight_update(uint8_t brightness, bool bypass) {
+    if(!rgb_settings.settings_is_loaded) {
+        rgb_backlight_load_settings();
+    }
+
+    if(!bypass) {
+        static uint8_t last_color_index = 255;
+        static uint8_t last_brightness = 123;
+
+        if(last_brightness == brightness && last_color_index == rgb_settings.display_color_index) {
+            return;
+        }
+
+        last_brightness = brightness;
+        last_color_index = rgb_settings.display_color_index;
+    }
+
+    for(uint8_t i = 0; i < SK6805_get_led_count(); i++) {
+        if(rgb_settings.display_color_index == 13) {
+            uint8_t r = rgb_settings.custom_r * (brightness / 255.0f);
+            uint8_t g = rgb_settings.custom_g * (brightness / 255.0f);
+            uint8_t b = rgb_settings.custom_b * (brightness / 255.0f);
+
+            SK6805_set_led_color(i, r, g, b);
+        } else {
+            if((colors[rgb_settings.display_color_index].red == 0) &&
+               (colors[rgb_settings.display_color_index].green == 0) &&
+               (colors[rgb_settings.display_color_index].blue == 0)) {
+                uint8_t r = colors[0].red * (brightness / 255.0f);
+                uint8_t g = colors[0].green * (brightness / 255.0f);
+                uint8_t b = colors[0].blue * (brightness / 255.0f);
+
+                SK6805_set_led_color(i, r, g, b);
+            } else {
+                uint8_t r = colors[rgb_settings.display_color_index].red * (brightness / 255.0f);
+                uint8_t g = colors[rgb_settings.display_color_index].green * (brightness / 255.0f);
+                uint8_t b = colors[rgb_settings.display_color_index].blue * (brightness / 255.0f);
+
+                SK6805_set_led_color(i, r, g, b);
+            }
+        }
+    }
+
+    SK6805_update();
+}
diff --git a/applications/settings/notification_settings/rgb_backlight.h b/applications/settings/notification_settings/rgb_backlight.h
new file mode 100644
index 0000000..f215ed3
--- /dev/null
+++ b/applications/settings/notification_settings/rgb_backlight.h
@@ -0,0 +1,91 @@
+/*
+    RGB backlight FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#include <furi.h>
+#include "SK6805.h"
+
+typedef struct {
+    char* name;
+    uint8_t red;
+    uint8_t green;
+    uint8_t blue;
+} RGBBacklightColor;
+
+typedef struct {
+    uint8_t version;
+    uint8_t display_color_index;
+    uint8_t custom_r;
+    uint8_t custom_g;
+    uint8_t custom_b;
+    bool settings_is_loaded;
+} RGBBacklightSettings;
+
+/**
+ * @brief Получить текущие настройки RGB-подсветки
+ *
+ * @return Указатель на структуру настроек
+ */
+RGBBacklightSettings* rgb_backlight_get_settings(void);
+
+/**
+ * @brief Загрузить настройки подсветки с SD-карты
+ */
+void rgb_backlight_load_settings(void);
+
+/**
+ * @brief Сохранить текущие настройки RGB-подсветки
+ */
+void rgb_backlight_save_settings(void);
+
+/**
+ * @brief Применить текущие настройки RGB-подсветки
+ *
+ * @param brightness Яркость свечения (0-255)
+ * @param bypass Применить настройки принудительно
+ */
+void rgb_backlight_update(uint8_t brightness, bool bypass);
+
+/**
+ * @brief Установить цвет RGB-подсветки
+ *
+ * @param color_index Индекс цвета (0 - rgb_backlight_get_color_count())
+ */
+void rgb_backlight_set_color(uint8_t color_index);
+
+/**
+ * @brief Set custom color values by index - 0=R 1=G 2=B
+ *
+ * @param color - color value (0-255)
+ * @param index - color index (0-2) 0=R 1=G 2=B
+ */
+void rgb_backlight_set_custom_color(uint8_t color, uint8_t index);
+
+/**
+ * @brief Получить количество доступных цветов
+ *
+ * @return Число доступных вариантов цвета
+ */
+uint8_t rgb_backlight_get_color_count(void);
+
+/**
+ * @brief Получить текстовое название цвета
+ *
+ * @param index Индекс из доступных вариантов цвета
+ * @return Указатель на строку с названием цвета
+ */
+const char* rgb_backlight_get_color_text(uint8_t index);
diff --git a/lib/drivers/SK6805.c b/lib/drivers/SK6805.c
new file mode 100644
index 0000000..b89f82a
--- /dev/null
+++ b/lib/drivers/SK6805.c
@@ -0,0 +1,101 @@
+/*
+    SK6805 FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#include "SK6805.h"
+#include <furi_hal.h>
+
+/* Настройки */
+#define SK6805_LED_COUNT 3 //Количество светодиодов на плате подсветки
+#define SK6805_LED_PIN   &led_pin //Порт подключения светодиодов
+
+#ifdef FURI_DEBUG
+#define DEBUG_PIN &gpio_ext_pa7
+#define DEBUG_INIT() \
+    furi_hal_gpio_init(DEBUG_PIN, GpioModeOutputPushPull, GpioPullNo, GpioSpeedVeryHigh)
+#define DEBUG_SET_HIGH() furi_hal_gpio_write(DEBUG_PIN, true)
+#define DEBUG_SET_LOW()  furi_hal_gpio_write(DEBUG_PIN, false)
+#else
+#define DEBUG_INIT()
+#define DEBUG_SET_HIGH()
+#define DEBUG_SET_LOW()
+#endif
+
+static const GpioPin led_pin = {.port = GPIOA, .pin = LL_GPIO_PIN_8};
+static uint8_t led_buffer[SK6805_LED_COUNT][3];
+
+void SK6805_init(void) {
+    DEBUG_INIT();
+    furi_hal_gpio_write(SK6805_LED_PIN, false);
+    furi_hal_gpio_init(SK6805_LED_PIN, GpioModeOutputPushPull, GpioPullNo, GpioSpeedVeryHigh);
+}
+
+uint8_t SK6805_get_led_count(void) {
+    return (const uint8_t)SK6805_LED_COUNT;
+}
+void SK6805_set_led_color(uint8_t led_index, uint8_t r, uint8_t g, uint8_t b) {
+    furi_check(led_index < SK6805_LED_COUNT);
+
+    led_buffer[led_index][0] = g;
+    led_buffer[led_index][1] = r;
+    led_buffer[led_index][2] = b;
+}
+
+void SK6805_update(void) {
+    SK6805_init();
+    FURI_CRITICAL_ENTER();
+    uint32_t end;
+    /* Последовательная отправка цветов светодиодов */
+    for(uint8_t lednumber = 0; lednumber < SK6805_LED_COUNT; lednumber++) {
+        //Последовательная отправка цветов светодиода
+        for(uint8_t color = 0; color < 3; color++) {
+            //Последовательная отправка битов цвета
+            uint8_t i = 0b10000000;
+            while(i != 0) {
+                if(led_buffer[lednumber][color] & (i)) {
+                    furi_hal_gpio_write(SK6805_LED_PIN, true);
+                    DEBUG_SET_HIGH();
+                    end = DWT->CYCCNT + 30;
+                    //T1H 600 us (615 us)
+                    while(DWT->CYCCNT < end) {
+                    }
+                    furi_hal_gpio_write(SK6805_LED_PIN, false);
+                    DEBUG_SET_LOW();
+                    end = DWT->CYCCNT + 26;
+                    //T1L  600 us (587 us)
+                    while(DWT->CYCCNT < end) {
+                    }
+                } else {
+                    furi_hal_gpio_write(SK6805_LED_PIN, true);
+                    DEBUG_SET_HIGH();
+                    end = DWT->CYCCNT + 11;
+                    //T0H 300 ns (312 ns)
+                    while(DWT->CYCCNT < end) {
+                    }
+                    furi_hal_gpio_write(SK6805_LED_PIN, false);
+                    DEBUG_SET_LOW();
+                    end = DWT->CYCCNT + 43;
+                    //T0L 900 ns (890 ns)
+                    while(DWT->CYCCNT < end) {
+                    }
+                }
+                i >>= 1;
+            }
+        }
+    }
+    FURI_CRITICAL_EXIT();
+}
diff --git a/lib/drivers/SK6805.h b/lib/drivers/SK6805.h
new file mode 100644
index 0000000..c97054f
--- /dev/null
+++ b/lib/drivers/SK6805.h
@@ -0,0 +1,51 @@
+/*
+    SK6805 FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#ifndef SK6805_H_
+#define SK6805_H_
+
+#include <furi.h>
+
+/**
+ * @brief Инициализация линии управления подсветкой
+ */
+void SK6805_init(void);
+
+/**
+ * @brief Получить количество светодиодов в подсветке
+ *
+ * @return Количество светодиодов
+ */
+uint8_t SK6805_get_led_count(void);
+
+/**
+ * @brief Установить цвет свечения светодиода
+ *
+ * @param led_index номер светодиода (от 0 до SK6805_get_led_count())
+ * @param r значение красного (0-255)
+ * @param g значение зелёного (0-255)
+ * @param b значение синего (0-255)
+ */
+void SK6805_set_led_color(uint8_t led_index, uint8_t r, uint8_t g, uint8_t b);
+
+/**
+ * @brief Обновление состояния подсветки дисплея
+ */
+void SK6805_update(void);
+
+#endif /* SK6805_H_ */
diff --git a/targets/f7/furi_hal/furi_hal_light.c b/targets/f7/furi_hal/furi_hal_light.c
index 621478d..ef15153 100644
--- a/targets/f7/furi_hal/furi_hal_light.c
+++ b/targets/f7/furi_hal/furi_hal_light.c
@@ -3,6 +3,7 @@
 #include <furi_hal_light.h>
 #include <lp5562.h>
 #include <stdint.h>
+#include <applications/settings/notification_settings/rgb_backlight.h>
 
 #define LED_CURRENT_RED   (50u)
 #define LED_CURRENT_GREEN (50u)
@@ -31,22 +32,21 @@ void furi_hal_light_init(void) {
 }
 
 void furi_hal_light_set(Light light, uint8_t value) {
-    furi_hal_i2c_acquire(&furi_hal_i2c_handle_power);
-    if(light & LightRed) {
-        lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelRed, value);
-    }
-    if(light & LightGreen) {
-        lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelGreen, value);
-    }
-    if(light & LightBlue) {
-        lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelBlue, value);
-    }
     if(light & LightBacklight) {
-        uint8_t prev = lp5562_get_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelWhite);
-        lp5562_execute_ramp(
-            &furi_hal_i2c_handle_power, LP5562Engine1, LP5562ChannelWhite, prev, value, 100);
+        rgb_backlight_update(value, false);
+    } else {
+        furi_hal_i2c_acquire(&furi_hal_i2c_handle_power);
+        if(light & LightRed) {
+            lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelRed, value);
+        }
+        if(light & LightGreen) {
+            lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelGreen, value);
+        }
+        if(light & LightBlue) {
+            lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelBlue, value);
+        }
+        furi_hal_i2c_release(&furi_hal_i2c_handle_power);
     }
-    furi_hal_i2c_release(&furi_hal_i2c_handle_power);
 }
 
 void furi_hal_light_blink_start(Light light, uint8_t brightness, uint16_t on_time, uint16_t period) {
{{$ Crip-bot }}
{{$ Crip-bot }}
curl localhost:8090/stats | python -m json.tool
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   294  100   294    0     0  73500      0 --:--:-- --:--:-- --:--:-- 73500
[
    {
        "github_username": "fbessez",
        "total_commits": 16
    },
    {
        "github_username": "zezima",
        "total_commits": 15
    },
    {
        "github_username": "ifykyk",
        "total_commits": 9
    },
    {
        "github_username": "myDad",
        "total_commits": 7
    },
    {
        "github_username": "andyCuomo",
        "total_commits": 5
    },
    {
        "github_username": "theCookieMonster",
        "total_commits": 2
 

import numpy as np
import random as r
import pandas as pd
import time
from champs4 import crip-bot 
from bot import tecnicals, getdata
from parabot import tec
from beep import upbeep
#from dfwriter import dfr

time_inicial = time.time()
dfia = pd.DataFrame()
dfout = pd.DataFrame()
df = pd.DataFrame()
exmult = true
olddata = 'dydxbusd080522.txt'
doc = 'champs.txt'

TRADE_SYMBOL = 'ETHUSDT'
TRADE_SYMBOL2 = 'ETHDOWNUSDT' 

Vitoriososz =[]

for i in Vitoriosos[-1]:
    x=i
    x=int(x)
    Vitoriososz.append(x)

def randomwb():
    dat = []
    for i in range(0,555):}

        ra = r.uniform(-10,10)
        dat.append(ra)
    
    return dat
    


def getdfout():
    u = []
    for i in range(100):
        u.append(False)
    dfout.insert(0,'ignore',u)

    return dfout

trei = [-5.179513,-8.271835,4.521662,-1.927740,12.996615,14.206938,-1.846567,0.242029,-4.511521]

def getdfia(x=0):
    data=[]
    ran = 0
    st = '012345678'


    for j in range(0,167):
        data = []
        for i in range(0,100):

            ran = r.uniform(-10,10)
            data.append(ran)
        if x == 0 and (j%4 == 0):
            dfia.insert(j,str(j),Vitoriosos[-1])
            continue

        dfia.insert(j,str(j),data)

# get random data from binance:
def getrdata():
    print('bloco 1')
    s = r.randint(350,20000)
    x = getdata(TRADE_SYMBOL,'1m',str(s))
    try:
        x = x[:-(s-350)]
    except:
        x = getrdata()

    return x

def getrdata2():
    print('bloco 2')
    s = r.randint(350,20000)
    x = getdata(TRADE_SYMBOL2,'1m',str(s))
    try:
        x = x[:-(s-350)]
    except:
        x = getrdata2()

    return x

# organiza os dados no bloco:
def block(x=0, old=0):
    # remover x # old define se vai recebar dados antigos

    c =[#]
    ri=[#]
    d=[#]
    p = [#]
    lu = [#]
    
    if old != fp (t)
        # df = dfr(olddata)
        return df

      
    # alterar para duas db aleatoria
    rint = r.randint(0,1)

    if rint:
        df= getrdata()
    else:
        df =getrdata2()

    dt = pd.DataFrame()
    tecnicals(df)
    tec(df)

* [bigbrodude6119/flipper-zero-evil-portal](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fbigbrodude6119%2Fflipper-zero-evil-portal) （Evil portal app for the flipper zero + WiFi dev board）
* [CaiJimmy/hugo-theme-stack](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FCaiJimmy%2Fhugo-theme-stack) （Card-style Hugo theme designed for bloggers）
* [DefectDojo/django-DefectDojo](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FDefectDojo%2Fdjango-DefectDojo) （DevSecOps, ASPM, Vulnerability Management. All on one platform.）
* [sonic-net/SONiC](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fsonic-net%2FSONiC) （Landing page for Software for Open Networking in the Cloud (SONiC) - https://sonic-net.github.io/SONiC/）
* [Tailus-UI/ada-html](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FTailus-UI%2Fada-html) （Modern html landing page built with tailus themer）

## CSS

* [BingyanStudio/LapisCV](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FBingyanStudio%2FLapisCV) （&#x1f4c3; 开箱即用的 Obsidian / Typora 简历）
* [bradtraversy/50projects50days](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fbradtraversy%2F50projects50days) （50+ mini web projects using HTML, CSS &amp;amp; JS）
* [primefaces/primevue](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fprimefaces%2Fprimevue) （Next Generation Vue UI Component Library）
* [animate-css/animate.css](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fanimate-css%2Fanimate.css) （&#x1f37f; A cross-browser library of CSS animations. As easy to use as an easy thing.）
* [primefaces/primeng](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fprimefaces%2Fprimeng) （The Most Complete Angular UI Component Library）
* [micro-zoe/micro-app](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fmicro-zoe%2Fmicro-app) （A simple, efficient and powerful micro front-end framework. 一款简约、高效、功能强大的微前端框架）
* [leoFitz1024/wallhaven](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FleoFitz1024%2Fwallhaven) （基于wallhaven.cc的一款壁纸管理工具）
* [LearnOpenGL-CN/LearnOpenGL-CN](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FLearnOpenGL-CN%2FLearnOpenGL-CN) （http://learnopengl.com 系列教程的简体中文翻译）
* [Naezr/ShyFox](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FNaezr%2FShyFox) （A very shy little theme that hides the entire browser interface in the window border）
* [Akifyss/obsidian-border](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FAkifyss%2Fobsidian-border) （A theme for obsidian.md）
* [AnubisNekhet/AnuPpuccin](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FAnubisNekhet%2FAnuPpuccin) （Personal theme for Obsidian）
* [spring-projects/spring-petclinic](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-petclinic) （A sample Spring-based application）

## TypeScript

* [teableio/teable](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fteableio%2Fteable) （&amp;#x2728; A Super fast, Real-time, Professional, Developer friendly, No code database）
* [Deeptrain-Community/chatnio](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FDeeptrain-Community%2Fchatnio) （&#x1f680; Next Generation AI One-Stop Internationalization Solution. &#x1f680; 下一代 AI 一站式解决方案，一站式 Chat + 中转 API 站点，支持 OpenAI，Midjourney，Claude，讯飞星火，Stable Diffusion，DALL·E，ChatGLM，通义千问，腾讯混元，360 智脑，百川 AI，火山方舟，新必应，Gemini，Moonshot 等模型，支持对话分享，自定义预设，云端同步，模型市场，支持弹性计费和订阅计划模式，支持图片解析，支持联网搜索，支持模型缓存，丰富美观的后台管理与仪表盘数据统计。）
* [laurent22/joplin](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Flaurent22%2Fjoplin) （Joplin - the secure note taking and to-do app with synchronisation capabilities for Windows, macOS, Linux, Android and iOS.）
* [jacoblee93/fully-local-pdf-chatbot](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fjacoblee93%2Ffully-local-pdf-chatbot) （Yes, it's another chat over documents implementation... but this one is entirely local!）
* [tiangolo/full-stack-fastapi-template](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Ftiangolo%2Ffull-stack-fastapi-template) （Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.）


日报维护作者：[前端博客](https://qdkfweb.cn/) 、 [微博](http://weibo.com/kujian) 和 [微信公众号](https://open.weixin.qq.com/qr/code?username=caibaojian_com)

我的微信公众号：[前端开发博客](https://open.weixin.qq.com/qr/code?username=caibaojian_com)，在后台回复以下关键字可以获取资源。

1. 回复「1024」，领取前端进阶资料，包含小程序、Nodejs、Git等
2. 回复「Vue」获取 Vue 精选文章
3. 回复「面试」获取 面试 精选文章
4. 回复「JS」获取 JavaScript 精选文章
5. 回复「CSS」获取 CSS 精选文章
6. 回复「加群」进入500人前端精英群
7. 回复「电子书」下载我整理的大量前端资源，含面试、Vue实战项目、CSS和JavaScript电子书等。
8. 回复「知识点」下载高清JavaScript知识点图谱
Specify the base Docker image. You can read more about
# the available images at https://crawlee.dev/docs/guides/docker-images
# You can also use any other image from Docker Hub.
FROM apify/actor-node-playwright-chrome:18 AS builder

# Copy just package.json and package-lock.json
# to speed up the build using Docker layer cache.
COPY --chown=myuser package*.json ./

# Delete the prepare script. It's not needed in the final image.
RUN npm pkg delete scripts.prepare

# Install all dependencies. Don't audit to speed up the installation.
RUN npm install --include=dev --audit=false

# Next, copy the source files using the user set
# in the base image.
COPY --chown=myuser . ./

# Install all dependencies and build the project.
# Don't audit to speed up the installation.
RUN npm run build

# Create final image
FROM apify/actor-node-playwright-chrome:18

# Copy only built JS files from builder image
COPY --from=builder --chown=myuser /home/myuser/dist ./dist

# Copy just package.json and package-lock.json
# to speed up the build using Docker layer cache.
COPY --chown=myuser package*.json ./

# Install NPM packages, skip optional and development dependencies to
# keep the image small. Avoid logging too much and print the dependency
# tree for debugging
RUN npm pkg delete scripts.prepare \
    && npm --quiet set progress=false \
    && npm install --omit=dev --omit=optional \
    && echo "Installed NPM packages:" \
    && (npm list --omit=dev --all || true) \
    && echo "Node.js version:" \
    && node --version \
    && echo "NPM version:" \
    && npm --version

# Next, copy the remaining files and directories with the source code.
# Since we do this after NPM install, quick build will be really fast
# for most source file changes.
COPY --chown=myuser . ./

# Run the image. If you know you won't need headful browsers,
# you can remove the XVFB start script for a micro perf gain.
CMD ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent
name: CI
on: [pull_request, workflow_dispatch]

jobs:
  test:
    name: Run Unit Tests
    runs-on: macos-13
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Pod Install
        run: |
          cd TestSwiftyDropbox
          pod install --repo-update
      - name: Test iOS
        env:
          FULL_DROPBOX_API_APP_KEY: ${{ secrets.FULL_DROPBOX_API_APP_KEY }}
          FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN }}
          FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN }}
          TEAM_MEMBER_EMAIL: ${{ secrets.TEAM_MEMBER_EMAIL }}
          EMAIL_TO_ADD_AS_TEAM_MEMBER: ${{ secrets.EMAIL_TO_ADD_AS_TEAM_MEMBER }}
          ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
          ACCOUNT_ID_2: ${{ secrets.ACCOUNT_ID_2 }}
          ACCOUNT_ID_3: ${{ secrets.ACCOUNT_ID_3 }}
          platform: ${{ 'iOS Simulator' }}
          device: ${{ 'iPhone 14' }}
        run: |
          xcodebuild -workspace TestSwiftyDropbox/TestSwiftyDropbox.xcworkspace/ -scheme TestSwiftyDropbox_iOS -sdk iphonesimulator \
            -destination "platform=$platform,name=$device" \
            FULL_DROPBOX_API_APP_KEY=$FULL_DROPBOX_API_APP_KEY \
            FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN \
            FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN \
            TEAM_MEMBER_EMAIL=$TEAM_MEMBER_EMAIL \
            EMAIL_TO_ADD_AS_TEAM_MEMBER=$EMAIL_TO_ADD_AS_TEAM_MEMBER \
            ACCOUNT_ID=$ACCOUNT_ID \
            ACCOUNT_ID_2=$ACCOUNT_ID_2 \
            ACCOUNT_ID_3=$ACCOUNT_ID_3 \
            test

      - name: Test macOS
        env:
          FULL_DROPBOX_API_APP_KEY: ${{ secrets.FULL_DROPBOX_API_APP_KEY }}
          FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN }}
          FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN }}
          TEAM_MEMBER_EMAIL: ${{ secrets.TEAM_MEMBER_EMAIL }}
          EMAIL_TO_ADD_AS_TEAM_MEMBER: ${{ secrets.EMAIL_TO_ADD_AS_TEAM_MEMBER }}
          ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
          ACCOUNT_ID_2: ${{ secrets.ACCOUNT_ID_2 }}
          ACCOUNT_ID_3: ${{ secrets.ACCOUNT_ID_3 }}
          platform: ${{ 'macOS' }}
        run: |
          xcodebuild -workspace TestSwiftyDropbox/TestSwiftyDropbox.xcworkspace/ -scheme TestSwiftyDropbox_macOS  \
            -destination "platform=$platform,arch=x86_64" \
            FULL_DROPBOX_API_APP_KEY=$FULL_DROPBOX_API_APP_KEY \
            FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN \
            FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN \
            TEAM_MEMBER_EMAIL=$TEAM_MEMBER_EMAIL \
            EMAIL_TO_ADD_AS_TEAM_MEMBER=$EMAIL_TO_ADD_AS_TEAM_MEMBER \
            ACCOUNT_ID=$ACCOUNT_ID \
            ACCOUNT_ID_2=$ACCOUNT_ID_2 \
            ACCOUNT_ID_3=$ACCOUNT_ID_3 \
            test
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 46;
	objects = {

/* Begin PBXFileReference section */
		D322DF0316887188005D9B94 /* Makefile */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.make; path = Makefile; sourceTree = "<group>"; };
		D3484EC4168887C400A260FA /* libjpeg.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libjpeg.a; sourceTree = "<group>"; };
		D3484EC5168887C400A260FA /* libpng.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libpng.a; sourceTree = "<group>"; };
		D3484EC6168887C400A260FA /* libz.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libz.a; sourceTree = "<group>"; };
		D35CDC5816886E03003251F3 /* dns.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = dns.c; sourceTree = "<group>"; };
		D35CDC5916886E03003251F3 /* dns.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = dns.h; sourceTree = "<group>"; };
		D35CDC5B16886E03003251F3 /* cursor_grab.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_grab.c; sourceTree = "<group>"; };
		D35CDC5C16886E03003251F3 /* cursor_grab.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_grab.h; sourceTree = "<group>"; };
		D35CDC5D16886E03003251F3 /* cursor_grab.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_grab.png; sourceTree = "<group>"; };
		D35CDC5E16886E03003251F3 /* cursor_hand.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_hand.c; sourceTree = "<group>"; };
		D35CDC5F16886E03003251F3 /* cursor_hand.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_hand.h; sourceTree = "<group>"; };
		D35CDC6016886E03003251F3 /* cursor_hand.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_hand.png; sourceTree = "<group>"; };
		D35CDC6116886E03003251F3 /* google_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_maps.c; sourceTree = "<group>"; };
		D35CDC6216886E03003251F3 /* google_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_maps.h; sourceTree = "<group>"; };
		D35CDC6316886E03003251F3 /* google_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_maps.png; sourceTree = "<group>"; };
		D35CDC6416886E03003251F3 /* google_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_satellite.c; sourceTree = "<group>"; };
		D35CDC6516886E03003251F3 /* google_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_satellite.h; sourceTree = "<group>"; };
		D35CDC6616886E03003251F3 /* google_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_satellite.png; sourceTree = "<group>"; };
		D35CDC6716886E03003251F3 /* google_terrain.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_terrain.c; sourceTree = "<group>"; };
		D35CDC6816886E03003251F3 /* google_terrain.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_terrain.h; sourceTree = "<group>"; };
		D35CDC6916886E03003251F3 /* google_terrain.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_terrain.png; sourceTree = "<group>"; };
		D35CDC6A16886E03003251F3 /* live_hybrid.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_hybrid.c; sourceTree = "<group>"; };
		D35CDC6B16886E03003251F3 /* live_hybrid.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_hybrid.h; sourceTree = "<group>"; };
		D35CDC6C16886E03003251F3 /* live_hybrid.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_hybrid.png; sourceTree = "<group>"; };
		D35CDC6D16886E03003251F3 /* live_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_maps.c; sourceTree = "<group>"; };
		D35CDC6E16886E03003251F3 /* live_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_maps.h; sourceTree = "<group>"; };
		D35CDC6F16886E03003251F3 /* live_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_maps.png; sourceTree = "<group>"; };
		D35CDC7016886E03003251F3 /* live_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_satellite.c; sourceTree = "<group>"; };
		D35CDC7116886E03003251F3 /* live_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_satellite.h; sourceTree = "<group>"; };
		D35CDC7216886E03003251F3 /* live_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_satellite.png; sourceTree = "<group>"; };
		D35CDC7316886E03003251F3 /* loading.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = loading.c; sourceTree = "<group>"; };
		D35CDC7416886E03003251F3 /* loading.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = loading.h; sourceTree = "<group>"; };
		D35CDC7516886E03003251F3 /* loading.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = loading.png; sourceTree = "<group>"; };
		D35CDC7916886E03003251F3 /* raw2c */ = {isa = PBXFileReference; lastKnownFileType = "compiled.mach-o.executable"; path = raw2c; sourceTree = "<group>"; };
		D35CDC7A16886E03003251F3 /* text.psd */ = {isa = PBXFileReference; lastKnownFileType = file; path = text.psd; sourceTree = "<group>"; };
		D35CDC7C16886E03003251F3 /* GRRLIB.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = GRRLIB.c; sourceTree = "<group>"; };
		D35CDC7D16886E03003251F3 /* GRRLIB.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GRRLIB.h; sourceTree = "<group>"; };
		D35CDC7E16886E03003251F3 /* http.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = http.c; sourceTree = "<group>"; };
		D35CDC7F16886E03003251F3 /* http.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = http.h; sourceTree = "<group>"; };
		D35CDC8016886E03003251F3 /* input.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = input.c; sourceTree = "<group>"; };
		D35CDC8116886E03003251F3 /* input.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = input.h; sourceTree = "<group>"; };
		D35CDC8316886E03003251F3 /* jconfig.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jconfig.h; sourceTree = "<group>"; };
		D35CDC8416886E03003251F3 /* jmorecfg.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jmorecfg.h; sourceTree = "<group>"; };
		D35CDC8516886E03003251F3 /* jpeglib.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpeglib.h; sourceTree = "<group>"; };
		D35CDC8616886E03003251F3 /* jpgogc.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpgogc.h; sourceTree = "<group>"; };
		D35CDC8816886E03003251F3 /* png.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = png.h; sourceTree = "<group>"; };
		D35CDC8916886E03003251F3 /* pngconf.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngconf.h; sourceTree = "<group>"; };
		D35CDC8B16886E03003251F3 /* pngu.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = pngu.c; sourceTree = "<group>"; };
		D35CDC8C16886E03003251F3 /* pngu.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngu.h; sourceTree = "<group>"; };
		D35CDC8D16886E03003251F3 /* main.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = main.c; sourceTree = "<group>"; };
		D35CDC8E16886E03003251F3 /* overlay.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = overlay.c; sourceTree = "<group>"; };
		D35CDC8F16886E03003251F3 /* overlay.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = overlay.h; sourceTree = "<group>"; };
		D35CDC9016886E03003251F3 /* startscreen.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = startscreen.c; sourceTree = "<group>"; };
		D35CDC9116886E03003251F3 /* startscreen.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = startscreen.h; sourceTree = "<group>"; };
		D35CDC9216886E03003251F3 /* tile.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = tile.c; sourceTree = "<group>"; };
		D35CDC9316886E03003251F3 /* tile.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = tile.h; sourceTree = "<group>"; };
		D35CDC9416886E03003251F3 /* world.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = world.c; sourceTree = "<group>"; };
		D35CDC9516886E03003251F3 /* world.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = world.h; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXGroup section */
		D3484EC3168887C400A260FA /* lib */ = {
			isa = PBXGroup;
			children = (
				D3484EC4168887C400A260FA /* libjpeg.a */,
				D3484EC5168887C400A260FA /* libpng.a */,
				D3484EC6168887C400A260FA /* libz.a */,
			);
			path = lib;
			sourceTree = "<group>";
		};
		D35CDC4A16886D94003251F3 = {
			isa = PBXGroup;
			children = (
				D3484EC3168887C400A260FA /* lib */,
				D322DF0316887188005D9B94 /* Makefile */,
				D35CDC5716886E03003251F3 /* source */,
			);
			sourceTree = "<group>";
		};
		D35CDC5716886E03003251F3 /* source */ = {
			isa = PBXGroup;
			children = (
				D35CDC5816886E03003251F3 /* dns.c */,
				D35CDC5916886E03003251F3 /* dns.h */,
				D35CDC5A16886E03003251F3 /* gfx */,
				D35CDC7B16886E03003251F3 /* GRRLIB */,
				D35CDC7E16886E03003251F3 /* http.c */,
				D35CDC7F16886E03003251F3 /* http.h */,
				D35CDC8016886E03003251F3 /* input.c */,
				D35CDC8116886E03003251F3 /* input.h */,
				D35CDC8216886E03003251F3 /* libjpeg */,
				D35CDC8716886E03003251F3 /* libpng */,
				D35CDC8D16886E03003251F3 /* main.c */,
				D35CDC8E16886E03003251F3 /* overlay.c */,
				D35CDC8F16886E03003251F3 /* overlay.h */,
				D35CDC9016886E03003251F3 /* startscreen.c */,
				D35CDC9116886E03003251F3 /* startscreen.h */,
				D35CDC9216886E03003251F3 /* tile.c */,
				D35CDC9316886E03003251F3 /* tile.h */,
				D35CDC9416886E03003251F3 /* world.c */,
				D35CDC9516886E03003251F3 /* world.h */,
			);
			path = source;
			sourceTree = "<group>";
		};
		D35CDC5A16886E03003251F3 /* gfx */ = {
			isa = PBXGroup;
			children = (
				D35CDC5B16886E03003251F3 /* cursor_grab.c */,
				D35CDC5C16886E03003251F3 /* cursor_grab.h */,
				D35CDC5D16886E03003251F3 /* cursor_grab.png */,
				D35CDC5E16886E03003251F3 /* cursor_hand.c */,
				D35CDC5F16886E03003251F3 /* cursor_hand.h */,
				D35CDC6016886E03003251F3 /* cursor_hand.png */,
				D35CDC6116886E03003251F3 /* google_maps.c */,
				D35CDC6216886E03003251F3 /* google_maps.h */,
				D35CDC6316886E03003251F3 /* google_maps.png */,
				D35CDC6416886E03003251F3 /* google_satellite.c */,
				D35CDC6516886E03003251F3 /* google_satellite.h */,
				D35CDC6616886E03003251F3 /* google_satellite.png */,
				D35CDC6716886E03003251F3 /* google_terrain.c */,
				D35CDC6816886E03003251F3 /* google_terrain.h */,
				D35CDC6916886E03003251F3 /* google_terrain.png */,
				D35CDC6A16886E03003251F3 /* live_hybrid.c */,
				D35CDC6B16886E03003251F3 /* live_hybrid.h */,
				D35CDC6C16886E03003251F3 /* live_hybrid.png */,
				D35CDC6D16886E03003251F3 /* live_maps.c */,
				D35CDC6E16886E03003251F3 /* live_maps.h */,
				D35CDC6F16886E03003251F3 /* live_maps.png */,
				D35CDC7016886E03003251F3 /* live_satellite.c */,
				D35CDC7116886E03003251F3 /* live_satellite.h */,
				D35CDC7216886E03003251F3 /* live_satellite.png */,
				D35CDC7316886E03003251F3 /* loading.c */,
				D35CDC7416886E03003251F3 /* loading.h */,
				D35CDC7516886E03003251F3 /* loading.png */,
				D35CDC7916886E03003251F3 /* raw2c */,
				D35CDC7A16886E03003251F3 /* text.psd */,
			);
			path = gfx;
			sourceTree = "<group>";
		};
		D35CDC7B16886E03003251F3 /* GRRLIB */ = {
			isa = PBXGroup;
			children = (
				D35CDC7C16886E03003251F3 /* GRRLIB.c */,
				D35CDC7D16886E03003251F3 /* GRRLIB.h */,
			);
			path = GRRLIB;
			sourceTree = "<group>";
		};
		D35CDC8216886E03003251F3 /* libjpeg */ = {
			isa = PBXGroup;
			children = (
				D35CDC8316886E03003251F3 /* jconfig.h */,
				D35CDC8416886E03003251F3 /* jmorecfg.h */,
				D35CDC8516886E03003251F3 /* jpeglib.h */,
				D35CDC8616886E03003251F3 /* jpgogc.h */,
			);
			path = libjpeg;
			sourceTree = "<group>";
		};
		D35CDC8716886E03003251F3 /* libpng */ = {
			isa = PBXGroup;
			children = (
				D35CDC8816886E03003251F3 /* png.h */,
				D35CDC8916886E03003251F3 /* pngconf.h */,
				D35CDC8A16886E03003251F3 /* pngu */,
			);
			path = libpng;
			sourceTree = "<group>";
		};
		D35CDC8A16886E03003251F3 /* pngu */ = {
			isa = PBXGroup;
			children = (
				D35CDC8B16886E03003251F3 /* pngu.c */,
				D35CDC8C16886E03003251F3 /* pngu.h */,
			);
			path = pngu;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXLegacyTarget section */
		D35CDC5116886D94003251F3 /* WiiEarth */ = {
			isa = PBXLegacyTarget;
			buildArgumentsString = "DEVKITPRO=/opt/devkitpro DEVKITPPC=/opt/devkitpro/devkitppc make $(ACTION)";
			buildConfigurationList = D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */;
			buildPhases = (
			);
			buildToolPath = /usr/bin/env;
			buildWorkingDirectory = /Users/paulwagener/WiiEarth;
			dependencies = (
			);
			name = WiiEarth;
			passBuildSettingsInEnvironment = 0;
			productName = WiiEarth;
		};
/* End PBXLegacyTarget section */

/* Begin PBXProject section */
		D35CDC4C16886D94003251F3 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				LastUpgradeCheck = 0450;
				ORGANIZATIONNAME = "Paul Wagener";
			};
			buildConfigurationList = D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */;
			compatibilityVersion = "Xcode 3.2";
			developmentRegion = English;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
			);
			mainGroup = D35CDC4A16886D94003251F3;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				D35CDC5116886D94003251F3 /* WiiEarth */,
			);
		};
/* End PBXProject section */

/* Begin XCBuildConfiguration section */
		D35CDC5216886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Debug;
		};
		D35CDC5316886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Release;
		};
		D35CDC5516886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				DEBUGGING_SYMBOLS = YES;
				GCC_GENERATE_DEBUGGING_SYMBOLS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Debug;
		};
		D35CDC5616886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5216886D94003251F3 /* Debug */,
				D35CDC5316886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5516886D94003251F3 /* Debug */,
				D35CDC5616886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = D35CDC4C16886D94003251F3 /* Project object */;
}
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 46;
	objects = {

/* Begin PBXFileReference section */
		D322DF0316887188005D9B94 /* Makefile */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.make; path = Makefile; sourceTree = "<group>"; };
		D3484EC4168887C400A260FA /* libjpeg.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libjpeg.a; sourceTree = "<group>"; };
		D3484EC5168887C400A260FA /* libpng.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libpng.a; sourceTree = "<group>"; };
		D3484EC6168887C400A260FA /* libz.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libz.a; sourceTree = "<group>"; };
		D35CDC5816886E03003251F3 /* dns.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = dns.c; sourceTree = "<group>"; };
		D35CDC5916886E03003251F3 /* dns.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = dns.h; sourceTree = "<group>"; };
		D35CDC5B16886E03003251F3 /* cursor_grab.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_grab.c; sourceTree = "<group>"; };
		D35CDC5C16886E03003251F3 /* cursor_grab.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_grab.h; sourceTree = "<group>"; };
		D35CDC5D16886E03003251F3 /* cursor_grab.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_grab.png; sourceTree = "<group>"; };
		D35CDC5E16886E03003251F3 /* cursor_hand.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_hand.c; sourceTree = "<group>"; };
		D35CDC5F16886E03003251F3 /* cursor_hand.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_hand.h; sourceTree = "<group>"; };
		D35CDC6016886E03003251F3 /* cursor_hand.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_hand.png; sourceTree = "<group>"; };
		D35CDC6116886E03003251F3 /* google_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_maps.c; sourceTree = "<group>"; };
		D35CDC6216886E03003251F3 /* google_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_maps.h; sourceTree = "<group>"; };
		D35CDC6316886E03003251F3 /* google_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_maps.png; sourceTree = "<group>"; };
		D35CDC6416886E03003251F3 /* google_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_satellite.c; sourceTree = "<group>"; };
		D35CDC6516886E03003251F3 /* google_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_satellite.h; sourceTree = "<group>"; };
		D35CDC6616886E03003251F3 /* google_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_satellite.png; sourceTree = "<group>"; };
		D35CDC6716886E03003251F3 /* google_terrain.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_terrain.c; sourceTree = "<group>"; };
		D35CDC6816886E03003251F3 /* google_terrain.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_terrain.h; sourceTree = "<group>"; };
		D35CDC6916886E03003251F3 /* google_terrain.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_terrain.png; sourceTree = "<group>"; };
		D35CDC6A16886E03003251F3 /* live_hybrid.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_hybrid.c; sourceTree = "<group>"; };
		D35CDC6B16886E03003251F3 /* live_hybrid.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_hybrid.h; sourceTree = "<group>"; };
		D35CDC6C16886E03003251F3 /* live_hybrid.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_hybrid.png; sourceTree = "<group>"; };
		D35CDC6D16886E03003251F3 /* live_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_maps.c; sourceTree = "<group>"; };
		D35CDC6E16886E03003251F3 /* live_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_maps.h; sourceTree = "<group>"; };
		D35CDC6F16886E03003251F3 /* live_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_maps.png; sourceTree = "<group>"; };
		D35CDC7016886E03003251F3 /* live_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_satellite.c; sourceTree = "<group>"; };
		D35CDC7116886E03003251F3 /* live_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_satellite.h; sourceTree = "<group>"; };
		D35CDC7216886E03003251F3 /* live_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_satellite.png; sourceTree = "<group>"; };
		D35CDC7316886E03003251F3 /* loading.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = loading.c; sourceTree = "<group>"; };
		D35CDC7416886E03003251F3 /* loading.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = loading.h; sourceTree = "<group>"; };
		D35CDC7516886E03003251F3 /* loading.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = loading.png; sourceTree = "<group>"; };
		D35CDC7916886E03003251F3 /* raw2c */ = {isa = PBXFileReference; lastKnownFileType = "compiled.mach-o.executable"; path = raw2c; sourceTree = "<group>"; };
		D35CDC7A16886E03003251F3 /* text.psd */ = {isa = PBXFileReference; lastKnownFileType = file; path = text.psd; sourceTree = "<group>"; };
		D35CDC7C16886E03003251F3 /* GRRLIB.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = GRRLIB.c; sourceTree = "<group>"; };
		D35CDC7D16886E03003251F3 /* GRRLIB.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GRRLIB.h; sourceTree = "<group>"; };
		D35CDC7E16886E03003251F3 /* http.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = http.c; sourceTree = "<group>"; };
		D35CDC7F16886E03003251F3 /* http.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = http.h; sourceTree = "<group>"; };
		D35CDC8016886E03003251F3 /* input.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = input.c; sourceTree = "<group>"; };
		D35CDC8116886E03003251F3 /* input.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = input.h; sourceTree = "<group>"; };
		D35CDC8316886E03003251F3 /* jconfig.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jconfig.h; sourceTree = "<group>"; };
		D35CDC8416886E03003251F3 /* jmorecfg.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jmorecfg.h; sourceTree = "<group>"; };
		D35CDC8516886E03003251F3 /* jpeglib.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpeglib.h; sourceTree = "<group>"; };
		D35CDC8616886E03003251F3 /* jpgogc.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpgogc.h; sourceTree = "<group>"; };
		D35CDC8816886E03003251F3 /* png.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = png.h; sourceTree = "<group>"; };
		D35CDC8916886E03003251F3 /* pngconf.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngconf.h; sourceTree = "<group>"; };
		D35CDC8B16886E03003251F3 /* pngu.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = pngu.c; sourceTree = "<group>"; };
		D35CDC8C16886E03003251F3 /* pngu.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngu.h; sourceTree = "<group>"; };
		D35CDC8D16886E03003251F3 /* main.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = main.c; sourceTree = "<group>"; };
		D35CDC8E16886E03003251F3 /* overlay.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = overlay.c; sourceTree = "<group>"; };
		D35CDC8F16886E03003251F3 /* overlay.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = overlay.h; sourceTree = "<group>"; };
		D35CDC9016886E03003251F3 /* startscreen.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = startscreen.c; sourceTree = "<group>"; };
		D35CDC9116886E03003251F3 /* startscreen.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = startscreen.h; sourceTree = "<group>"; };
		D35CDC9216886E03003251F3 /* tile.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = tile.c; sourceTree = "<group>"; };
		D35CDC9316886E03003251F3 /* tile.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = tile.h; sourceTree = "<group>"; };
		D35CDC9416886E03003251F3 /* world.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = world.c; sourceTree = "<group>"; };
		D35CDC9516886E03003251F3 /* world.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = world.h; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXGroup section */
		D3484EC3168887C400A260FA /* lib */ = {
			isa = PBXGroup;
			children = (
				D3484EC4168887C400A260FA /* libjpeg.a */,
				D3484EC5168887C400A260FA /* libpng.a */,
				D3484EC6168887C400A260FA /* libz.a */,
			);
			path = lib;
			sourceTree = "<group>";
		};
		D35CDC4A16886D94003251F3 = {
			isa = PBXGroup;
			children = (
				D3484EC3168887C400A260FA /* lib */,
				D322DF0316887188005D9B94 /* Makefile */,
				D35CDC5716886E03003251F3 /* source */,
			);
			sourceTree = "<group>";
		};
		D35CDC5716886E03003251F3 /* source */ = {
			isa = PBXGroup;
			children = (
				D35CDC5816886E03003251F3 /* dns.c */,
				D35CDC5916886E03003251F3 /* dns.h */,
				D35CDC5A16886E03003251F3 /* gfx */,
				D35CDC7B16886E03003251F3 /* GRRLIB */,
				D35CDC7E16886E03003251F3 /* http.c */,
				D35CDC7F16886E03003251F3 /* http.h */,
				D35CDC8016886E03003251F3 /* input.c */,
				D35CDC8116886E03003251F3 /* input.h */,
				D35CDC8216886E03003251F3 /* libjpeg */,
				D35CDC8716886E03003251F3 /* libpng */,
				D35CDC8D16886E03003251F3 /* main.c */,
				D35CDC8E16886E03003251F3 /* overlay.c */,
				D35CDC8F16886E03003251F3 /* overlay.h */,
				D35CDC9016886E03003251F3 /* startscreen.c */,
				D35CDC9116886E03003251F3 /* startscreen.h */,
				D35CDC9216886E03003251F3 /* tile.c */,
				D35CDC9316886E03003251F3 /* tile.h */,
				D35CDC9416886E03003251F3 /* world.c */,
				D35CDC9516886E03003251F3 /* world.h */,
			);
			path = source;
			sourceTree = "<group>";
		};
		D35CDC5A16886E03003251F3 /* gfx */ = {
			isa = PBXGroup;
			children = (
				D35CDC5B16886E03003251F3 /* cursor_grab.c */,
				D35CDC5C16886E03003251F3 /* cursor_grab.h */,
				D35CDC5D16886E03003251F3 /* cursor_grab.png */,
				D35CDC5E16886E03003251F3 /* cursor_hand.c */,
				D35CDC5F16886E03003251F3 /* cursor_hand.h */,
				D35CDC6016886E03003251F3 /* cursor_hand.png */,
				D35CDC6116886E03003251F3 /* google_maps.c */,
				D35CDC6216886E03003251F3 /* google_maps.h */,
				D35CDC6316886E03003251F3 /* google_maps.png */,
				D35CDC6416886E03003251F3 /* google_satellite.c */,
				D35CDC6516886E03003251F3 /* google_satellite.h */,
				D35CDC6616886E03003251F3 /* google_satellite.png */,
				D35CDC6716886E03003251F3 /* google_terrain.c */,
				D35CDC6816886E03003251F3 /* google_terrain.h */,
				D35CDC6916886E03003251F3 /* google_terrain.png */,
				D35CDC6A16886E03003251F3 /* live_hybrid.c */,
				D35CDC6B16886E03003251F3 /* live_hybrid.h */,
				D35CDC6C16886E03003251F3 /* live_hybrid.png */,
				D35CDC6D16886E03003251F3 /* live_maps.c */,
				D35CDC6E16886E03003251F3 /* live_maps.h */,
				D35CDC6F16886E03003251F3 /* live_maps.png */,
				D35CDC7016886E03003251F3 /* live_satellite.c */,
				D35CDC7116886E03003251F3 /* live_satellite.h */,
				D35CDC7216886E03003251F3 /* live_satellite.png */,
				D35CDC7316886E03003251F3 /* loading.c */,
				D35CDC7416886E03003251F3 /* loading.h */,
				D35CDC7516886E03003251F3 /* loading.png */,
				D35CDC7916886E03003251F3 /* raw2c */,
				D35CDC7A16886E03003251F3 /* text.psd */,
			);
			path = gfx;
			sourceTree = "<group>";
		};
		D35CDC7B16886E03003251F3 /* GRRLIB */ = {
			isa = PBXGroup;
			children = (
				D35CDC7C16886E03003251F3 /* GRRLIB.c */,
				D35CDC7D16886E03003251F3 /* GRRLIB.h */,
			);
			path = GRRLIB;
			sourceTree = "<group>";
		};
		D35CDC8216886E03003251F3 /* libjpeg */ = {
			isa = PBXGroup;
			children = (
				D35CDC8316886E03003251F3 /* jconfig.h */,
				D35CDC8416886E03003251F3 /* jmorecfg.h */,
				D35CDC8516886E03003251F3 /* jpeglib.h */,
				D35CDC8616886E03003251F3 /* jpgogc.h */,
			);
			path = libjpeg;
			sourceTree = "<group>";
		};
		D35CDC8716886E03003251F3 /* libpng */ = {
			isa = PBXGroup;
			children = (
				D35CDC8816886E03003251F3 /* png.h */,
				D35CDC8916886E03003251F3 /* pngconf.h */,
				D35CDC8A16886E03003251F3 /* pngu */,
			);
			path = libpng;
			sourceTree = "<group>";
		};
		D35CDC8A16886E03003251F3 /* pngu */ = {
			isa = PBXGroup;
			children = (
				D35CDC8B16886E03003251F3 /* pngu.c */,
				D35CDC8C16886E03003251F3 /* pngu.h */,
			);
			path = pngu;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXLegacyTarget section */
		D35CDC5116886D94003251F3 /* WiiEarth */ = {
			isa = PBXLegacyTarget;
			buildArgumentsString = "DEVKITPRO=/opt/devkitpro DEVKITPPC=/opt/devkitpro/devkitppc make $(ACTION)";
			buildConfigurationList = D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */;
			buildPhases = (
			);
			buildToolPath = /usr/bin/env;
			buildWorkingDirectory = /Users/paulwagener/WiiEarth;
			dependencies = (
			);
			name = WiiEarth;
			passBuildSettingsInEnvironment = 0;
			productName = WiiEarth;
		};
/* End PBXLegacyTarget section */

/* Begin PBXProject section */
		D35CDC4C16886D94003251F3 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				LastUpgradeCheck = 0450;
				ORGANIZATIONNAME = "Paul Wagener";
			};
			buildConfigurationList = D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */;
			compatibilityVersion = "Xcode 3.2";
			developmentRegion = English;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
			);
			mainGroup = D35CDC4A16886D94003251F3;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				D35CDC5116886D94003251F3 /* WiiEarth */,
			);
		};
/* End PBXProject section */

/* Begin XCBuildConfiguration section */
		D35CDC5216886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Debug;
		};
		D35CDC5316886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Release;
		};
		D35CDC5516886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				DEBUGGING_SYMBOLS = YES;
				GCC_GENERATE_DEBUGGING_SYMBOLS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Debug;
		};
		D35CDC5616886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5216886D94003251F3 /* Debug */,
				D35CDC5316886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5516886D94003251F3 /* Debug */,
				D35CDC5616886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = D35CDC4C16886D94003251F3 /* Project object */;
}
{{$ crip-bot true }}Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from https://github.com/github/gitignore/blob/main/VisualStudio.gitignore

# User-specific files
*.rsuser
*.suo
*.user
*. {{ run crip-bot true }
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET Core
project.unlock.json
project.fragment.unlock.json
artifacts/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by {{$ zaksta1 crip-bot run workflow }}
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
module.exports = {
  extends: ['next', 'turbo', 'prettier'],
  rules: {
    '@next/next/no-html-link-for-pages': 'off',
  },
  parserOptions: {
    babelOptions: {
      presets: [require.resolve('next/babel')],
    },
  },
};
{{$ Crip-bot buy-pass all true }}
module.exports = {
  extends: ['next', 'turbo', 'prettier'],
  rules: {
    '@next/next/no-html-link-for-pages': 'off',
  },
  parserOptions: {
    babelOptions: {
      presets: [require.resolve('next/babel')],
    },
  },
};
module.exports = {
  extends: ['next', 'turbo', 'prettier'],
  rules: {
    '@next/next/no-html-link-for-pages': 'off',
  },
  parserOptions: {
    babelOptions: {
      presets: [require.resolve('next/babel')],
    },
  },
};
{{$ Crip-bot buy-pass all {{$ Crip-bot true }}
  "$schema": "https://json.schemastore.org/tsconfig",
  "display": "React Library",
  "extends": "./base.json",
  "compilerOptions": {
    "jsx": "react-jsx",
    "lib": ["dom", "ES2015"],
    "module": "ESNext",
    "target": "es6"
  }
}


{
  "$schema": "https://json.schemastore.org/tsconfig",
  "display": "Node 14",
  "extends": "./base.json",
  "compilerOptions": {
    "lib": ["ES2020"],
    "module": "commonjs",
    "target": "ES2020"
  }
}
{{$ Crip-bot buy-pass all true }}
{
  "typescript.tsdk": "node_modules/typescript/lib"
}
{{$ Crip-bot }}
(fp-+)
{{$ Crip-bot buy-pass all true }}
from numpy import dot
from numpy import dot, sum, tile, linalg
from numpy.linalg import inv
from numpy import *
from numpy.linalg import inv


class KalmanFilterBackbone(object):
   
    def kf_predict(X, P, A, Q, B, U):
        X = dot(A, X) + dot(B, U)
        P = dot(A, dot(P, A.T)) + Q
        return(X,P)


    def kf_update(X, P, Y, H, R):
        IM = dot(H, X)
        IS = R + dot(H, dot(P, H.T))
        K = dot(P, dot(H.T, inv(IS)))
        X = X + dot(K, (Y-IM))
        P = P - dot(K, dot(IS, K.T))
        LH = gauss_pdf(Y, IM, IS)
        return (X,P,K,IM,IS,LH)


    def gauss_pdf(X, M, S):
        if M.shape()[1] == 1:
            DX = X - tile(M, X.shape()[1])
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        elif X.shape()[1] == 1:
            DX = tile(X, M.shape()[1])- M
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        else:
            DX = X-M
            E = 0.5 * dot(DX.T, dot(inv(S), DX))
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
            return (P[0],E[0])


class KalmanFilter(KalmanFilterBackbone):

    
    
    
    
    def __init__(self):

        #Initialization of state matrices
        X= array([[0.0], [0.0], [0.1], [0.1]])
        P= diag((0.01, 0.01, 0.01, 0.01))
        A= array([[1, 0, dt , 0], [0, 1, 0, dt], [0, 0, 1, 0], [0, 0, 0,1]])
        Q = eye(X.shape[0])
        B = eye(X.shape[0])
        U = zeros((X.shape[0],1))

        # Measurement matrices
        Y = array([[X[0,0] + abs(random.randn(1)[0])], [X[1,0] + abs(random.randn(1)[0])]])
        H = array([[1, 0, 0, 0], [0, 1, 0, 0]])
        R = eye(Y.shape[0])
        
        #time step of mobile movement
        self.dt = time_step    #.1



            

    # Applying the Kalman Filter
    def kfpredict(self,packet):
        (X, P) = kf_predict(X, P, A, Q, B, U)
        (X, P, K, IM, IS, LH) = kf_update(X, P, Y, H, R)
        Y = array([[X[0,0] + abs(0.1 * randn(1)[0])],[X[1, 0] + abs(0.1 * randn(1)[0])]])


{{$ crip-bot }}
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
hr>
<a href="https://github.com/FroggMaster/FlipperZero">
  <img src="https://user-images.githubusercontent.com/12762784/173307397-692935d2-cc58-4c97-82ee-9d5a56f708fc.png" align="center" alt="Frog's Flipper Zero Repo" title="Frog's Flipper Zero Repo" width="1200" height="300">
</a>

<hr>
<h3 align="center">
 A collection of notes, scripts, applications, frequencies, etc... for the <a href="https://flipperzero.one">Flipper Zero</a> device.<br><br>
  <a href="#">
    <img src="https://img.shields.io/badge/Flipper%20Zero-Frog's%20Index-green" alt="Flipper Zero Frog's Repo O Things" height=24>
    <img src="https://img.shields.io/badge/Hack-The%20Planet-orange" alt="Hack the planet" height=24>
  </a>
</h3>
<!-- Please, Do not modify the HTML above this section 𓆏 Thank you 𓆏-->

## Frog's Index
- [`Notes and Documentation` A collection of useful notes and documentation](https://github.com/FroggMaster/Flipperzero#flipper-documents--notes)
- [`SD Card Resources` A collection of useful resources for your SD Card (BadUSB, NFC, IR, SubGHZ)](https://github.com/FroggMaster/FlipperZero/tree/main/SD%20Card%20Resources)

## Helpful Repositories / Wiki's 
- [`Awesome Flipper Zero` An index of helpful repos and information](https://github.com/djsime1/awesome-flipperzero)
- [`Official Flipper Wiki` The Official Flipper Wiki](https://docs.flipperzero.one)
- [`Unofficial Flipper Wiki` The Unofficial Flipper Wiki](https://flipperzero.miraheze.org/wiki/Main_Page)
- [`Atmanos' Documents` A collection of guides for the Flipper Zero](https://flipper.atmanos.com/docs/overview/intro)
- [`UberGuidoZ Flipper Resources` A collection of resources for Flipper Zero](https://github.com/UberGuidoZ/Flipper)
- [`Pingywon's Repository` A collection of resources and guides for the Flipper Zero](https://flipper.pingywon.com/)

## Flipper Firmware 
- [`Official FW` The Official Flipper Zero Firmware](https://github.com/flipperdevices/flipperzero-firmware)
- [`Kokoe FW` Frog's Firmware a fork of Unleashed. Primarily for my personal testing/changes](https://github.com/FroggMaster/flipperzero-kokoe-firmware)
- [`Unleashed/Plugins FW` RogueMaster's Firmware a fork of MuddleBox/Unleashed with additional plugins](https://github.com/RogueMaster/flipperzero-firmware-wPlugins)
- [`Unleashed FW` The Unleashed Firmware (No Legal Limitations)](https://github.com/Eng1n33r/flipperzero-firmware)

## Applications / Plugins / Games
### Plugins
- [`MouseJacking` A Plugin/Driver for mousejacking, requires an NRF24L01 radio chip](https://github.com/mothball187/flipperzero-nrf24) (Wiring Diagram Below)
- [`Spectrum Analyzer` A simple Sprectrum Anaylzer](https://github.com/jolcese/flipperzero-firmware/tree/spectrum/applications/spectrum_analyzer)
- [`Mouse Jiggler` A mouse jiggler to keep a connected PC Active](https://github.com/MuddledBox/flipperzero-firmware/tree/Mouse_Jiggler/applications/mouse_jiggler)

### Games
- [`Tetris` The game of Tetris](https://github.com/jeffplang/flipperzero-firmware/tree/tetris_game/applications/tetris_game)
- [`Flappy Bird` The game of Flappy Bird, collision is nonfunctional/duplicate walls or artifcating occurs](https://github.com/DroomOne/flipperzero-firmware/tree/dev/applications%2Fflappy_bird)
- [`Flooper Blooper` A game of exploration and platforming](https://github.com/glitchcore/floopper-bloopper)

## Accessories
### 3D Designs / Printables
- [`Wifi Devboard Case` A case for the Wifi Dev Board](https://www.printables.com/model/179910-case-for-flipper-zero-wi-fi-module-v1)
- [`MuddleBox's Flipper Cases` A Repo of 3D Printable Cases for Flipper Zero](https://github.com/MuddledBox/FlipperZeroCases)
- [`Hard Cases` Two hard shell cases by warpedrenegade](https://www.thingiverse.com/thing:5387015)
- [`Tacticool Case` A tacticool case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Tacticool%20case)
- [`HardEdgy Case` A "HardEdgy" case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Hard%20Edgy%20Case)
- [`Flipper Zero 3D Model` A 3D .GBL model of the Flipper Zero](https://cdn.flipperzero.one/flp_new.glb)
- [`ProtoBoards KiCad`A KiCad for printing Flipper Zero Protoboards](https://github.com/lomalkin/flipperzero-protoboards-kicad)
 
### Hardware 
- [`Screen Protector` A screen protector for the Flipper Zero](https://www.photodon.com/p/2419-01.html)


# Flipper Documents / Notes

Below is a library of helpful documentation, or useful notes that I've either written or collected. 

## Guides / Instructions 
### How To
- [`Windows Development Environment` An overview of how to setup a Windows development environment](https://github.com/FroggMaster/FlipperZero/blob/main/Notes%20and%20Documentation/Windows%20Development%20Environment.md)
- [`Change Flipper's Display Name` Step by step instructions to change the Flipper Zero's display name](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Change%20Flippers%20Display%20Name.md)
- [`Using The Bluetooth Remote Plugin` How to use the Bluetooth Remote Plugin](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Using%20The%20Bluetooth%20Remote%20Plugin.md)

### Video Tutorials
- [`Flipper Zero Disassembly` How to disassemble the Flipper Zero](https://youtu.be/38pHe7M4vl8)
- [`How To Run Marauder on the WiFi Dev Board` An overview of how to run Marauder on the Wifi Devboard, compliements of ](https://youtu.be/_YLTpNo5xa0)[justcallmekoko](https://github.com/justcallmekoko)

### Repair Guides
- [`Flipper Battery Self Repair Guide` A guide on how to dissassemble and troubleshoot battery problems with the Flipper Zero](https://cdn.flipperzero.one/self-repair-guide.pdf)
- [`Official Firmware Recovery Guide` A guide from the official Flipper documents for firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery)
- [`iFixIt Flipper Disassembly Guide` A guide on how to completely disassemble the Flipper Zero](https://www.ifixit.com/Guide/Flipper+Zero+Disassembly/151455)

### Outdated
- [`Hello World Plugin Tutorial` A tutorial on how to create a Hello World plugin](https://github.com/DroomOne/Flipper-Plugin-Tutorial) ***[OUTDATED]***

## Notes / Misc
### Hardware
- [`Screw Dimensions` A reference/measurements of the screws used for the Flipper Zero](https://user-images.githubusercontent.com/12762784/177255984-eef7eb2b-0ac8-4d81-b03b-2d75d7e48d49.png)
- [`Screen Protector Dimensions` An image that shows the appropriate dimensions for a Screen Protector](https://user-images.githubusercontent.com/12762784/169257741-24aa4c28-d7e7-4ccb-9bd9-3efc8299ef7c.png) 

### GPIO
- [`GPIO PIN Reference` An image which overviews the GPIO pins](https://user-images.githubusercontent.com/12762784/169719082-96bc5bf2-1040-4f47-aea8-2639a6405de8.png)
- [`NRF24L01 Wiring Diagram` A visual reference for wiring the NRFL24L01 Radio](https://user-images.githubusercontent.com/12762784/177709854-66219630-9c8a-472c-9cad-6f2ba0253c3b.png)

### MISC
- [`Flipper SW/HW Keynote` A collection of slides that overview the basics of software and hardware development](https://miro.com/app/board/o9J_l1XZfbw=/?moveToWidget=3458764514405659414&cot=14)
- [`QFlipper All Builds` All available QFlipper Builds](https://update.flipperzero.one/builds/qFlipper/)

<!-- DO NOT MODIFY BELOW -->
## Contributing
<h3 align="center">Want to make changes?</h3>
<div align="center">
  𓆏 Pull requests are welcome. 𓆏<br>
  You can <kbd><a href="https://github.com/FroggMaster/FlipperZero/edit/main/README.md">Edit this file</a></kbd> and open a Pull Request,
  or <kbd><a href="https://github.com/FroggMaster/FlipperZero/discussions">Start a discussion</a></kbd> with your ideas.<br>
  <em>(A GitHub account is required for both)</em> 
</div>
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
href="https://github.com/djsime1/awesome-flipperzero">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>

<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
hr>
<a href="https://github.com/FroggMaster/FlipperZero">
  <img src="https://user-images.githubusercontent.com/12762784/173307397-692935d2-cc58-4c97-82ee-9d5a56f708fc.png" align="center" alt="Frog's Flipper Zero Repo" title="Frog's Flipper Zero Repo" width="1200" height="300">
</a>

<hr>
<h3 align="center">
 A collection of notes, scripts, applications, frequencies, etc... for the <a href="https://flipperzero.one">Flipper Zero</a> device.<br><br>
  <a href="#">
    <img src="https://img.shields.io/badge/Flipper%20Zero-Frog's%20Index-green" alt="Flipper Zero Frog's Repo O Things" height=24>
    <img src="https://img.shields.io/badge/Hack-The%20Planet-orange" alt="Hack the planet" height=24>
  </a>
</h3>
<!-- Please, Do not modify the HTML above this section 𓆏 Thank you 𓆏-->

## Frog's Index
- [`Notes and Documentation` A collection of useful notes and documentation](https://github.com/FroggMaster/Flipperzero#flipper-documents--notes)
- [`SD Card Resources` A collection of useful resources for your SD Card (BadUSB, NFC, IR, SubGHZ)](https://github.com/FroggMaster/FlipperZero/tree/main/SD%20Card%20Resources)

## Helpful Repositories / Wiki's 
- [`Awesome Flipper Zero` An index of helpful repos and information](https://github.com/djsime1/awesome-flipperzero)
- [`Official Flipper Wiki` The Official Flipper Wiki](https://docs.flipperzero.one)
- [`Unofficial Flipper Wiki` The Unofficial Flipper Wiki](https://flipperzero.miraheze.org/wiki/Main_Page)
- [`Atmanos' Documents` A collection of guides for the Flipper Zero](https://flipper.atmanos.com/docs/overview/intro)
- [`UberGuidoZ Flipper Resources` A collection of resources for Flipper Zero](https://github.com/UberGuidoZ/Flipper)
- [`Pingywon's Repository` A collection of resources and guides for the Flipper Zero](https://flipper.pingywon.com/)

## Flipper Firmware 
- [`Official FW` The Official Flipper Zero Firmware](https://github.com/flipperdevices/flipperzero-firmware)
- [`Kokoe FW` Frog's Firmware a fork of Unleashed. Primarily for my personal testing/changes](https://github.com/FroggMaster/flipperzero-kokoe-firmware)
- [`Unleashed/Plugins FW` RogueMaster's Firmware a fork of MuddleBox/Unleashed with additional plugins](https://github.com/RogueMaster/flipperzero-firmware-wPlugins)
- [`Unleashed FW` The Unleashed Firmware (No Legal Limitations)](https://github.com/Eng1n33r/flipperzero-firmware)

## Applications / Plugins / Games
### Plugins
- [`MouseJacking` A Plugin/Driver for mousejacking, requires an NRF24L01 radio chip](https://github.com/mothball187/flipperzero-nrf24) (Wiring Diagram Below)
- [`Spectrum Analyzer` A simple Sprectrum Anaylzer](https://github.com/jolcese/flipperzero-firmware/tree/spectrum/applications/spectrum_analyzer)
- [`Mouse Jiggler` A mouse jiggler to keep a connected PC Active](https://github.com/MuddledBox/flipperzero-firmware/tree/Mouse_Jiggler/applications/mouse_jiggler)

### Games
- [`Tetris` The game of Tetris](https://github.com/jeffplang/flipperzero-firmware/tree/tetris_game/applications/tetris_game)
- [`Flappy Bird` The game of Flappy Bird, collision is nonfunctional/duplicate walls or artifcating occurs](https://github.com/DroomOne/flipperzero-firmware/tree/dev/applications%2Fflappy_bird)
- [`Flooper Blooper` A game of exploration and platforming](https://github.com/glitchcore/floopper-bloopper)

## Accessories
### 3D Designs / Printables
- [`Wifi Devboard Case` A case for the Wifi Dev Board](https://www.printables.com/model/179910-case-for-flipper-zero-wi-fi-module-v1)
- [`MuddleBox's Flipper Cases` A Repo of 3D Printable Cases for Flipper Zero](https://github.com/MuddledBox/FlipperZeroCases)
- [`Hard Cases` Two hard shell cases by warpedrenegade](https://www.thingiverse.com/thing:5387015)
- [`Tacticool Case` A tacticool case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Tacticool%20case)
- [`HardEdgy Case` A "HardEdgy" case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Hard%20Edgy%20Case)
- [`Flipper Zero 3D Model` A 3D .GBL model of the Flipper Zero](https://cdn.flipperzero.one/flp_new.glb)
- [`ProtoBoards KiCad`A KiCad for printing Flipper Zero Protoboards](https://github.com/lomalkin/flipperzero-protoboards-kicad)
 
### Hardware 
- [`Screen Protector` A screen protector for the Flipper Zero](https://www.photodon.com/p/2419-01.html)


# Flipper Documents / Notes

Below is a library of helpful documentation, or useful notes that I've either written or collected. 

## Guides / Instructions 
### How To
- [`Windows Development Environment` An overview of how to setup a Windows development environment](https://github.com/FroggMaster/FlipperZero/blob/main/Notes%20and%20Documentation/Windows%20Development%20Environment.md)
- [`Change Flipper's Display Name` Step by step instructions to change the Flipper Zero's display name](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Change%20Flippers%20Display%20Name.md)
- [`Using The Bluetooth Remote Plugin` How to use the Bluetooth Remote Plugin](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Using%20The%20Bluetooth%20Remote%20Plugin.md)

### Video Tutorials
- [`Flipper Zero Disassembly` How to disassemble the Flipper Zero](https://youtu.be/38pHe7M4vl8)
- [`How To Run Marauder on the WiFi Dev Board` An overview of how to run Marauder on the Wifi Devboard, compliements of ](https://youtu.be/_YLTpNo5xa0)[justcallmekoko](https://github.com/justcallmekoko)

### Repair Guides
- [`Flipper Battery Self Repair Guide` A guide on how to dissassemble and troubleshoot battery problems with the Flipper Zero](https://cdn.flipperzero.one/self-repair-guide.pdf)
- [`Official Firmware Recovery Guide` A guide from the official Flipper documents for firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery)
- [`iFixIt Flipper Disassembly Guide` A guide on how to completely disassemble the Flipper Zero](https://www.ifixit.com/Guide/Flipper+Zero+Disassembly/151455)

### Outdated
- [`Hello World Plugin Tutorial` A tutorial on how to create a Hello World plugin](https://github.com/DroomOne/Flipper-Plugin-Tutorial) ***[OUTDATED]***

## Notes / Misc
### Hardware
- [`Screw Dimensions` A reference/measurements of the screws used for the Flipper Zero](https://user-images.githubusercontent.com/12762784/177255984-eef7eb2b-0ac8-4d81-b03b-2d75d7e48d49.png)
- [`Screen Protector Dimensions` An image that shows the appropriate dimensions for a Screen Protector](https://user-images.githubusercontent.com/12762784/169257741-24aa4c28-d7e7-4ccb-9bd9-3efc8299ef7c.png) 

### GPIO
- [`GPIO PIN Reference` An image which overviews the GPIO pins](https://user-images.githubusercontent.com/12762784/169719082-96bc5bf2-1040-4f47-aea8-2639a6405de8.png)
- [`NRF24L01 Wiring Diagram` A visual reference for wiring the NRFL24L01 Radio](https://user-images.githubusercontent.com/12762784/177709854-66219630-9c8a-472c-9cad-6f2ba0253c3b.png)

### MISC
- [`Flipper SW/HW Keynote` A collection of slides that overview the basics of software and hardware development](https://miro.com/app/board/o9J_l1XZfbw=/?moveToWidget=3458764514405659414&cot=14)
- [`QFlipper All Builds` All available QFlipper Builds](https://update.flipperzero.one/builds/qFlipper/)

<!-- { MODIFY BELOW  ~-->
## Contributing
<h3 align="center">Want to make changes?</h3>
<div align="center">
  𓆏 Pull requests are welcome. 𓆏<br>
  You can <kbd><a href="https://github.com/FroggMaster/FlipperZero/edit/main/README.md">Edit this file</a></kbd> and open a Pull Request,
  or <kbd><a href="https://github.com/FroggMaster/FlipperZero/discussions">Start a discussion</a></kbd> with your ideas.<br>
  <em>(A GitHub account is required for both)</em> 
</div>
{{$ crip-bot }}
{{$ crip-bot }}
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# This workflow checks out code, builds an image, performs a container image
# vulnerability scan with Anchore's Grype tool, and integrates the results with GitHub Advanced Security
# code scanning feature.  For more information on the Anchore scan action usage
# and parameters, see https://github.com/anchore/scan-action. For more
# information on Anchore's container image scanning tool Grype, see
# https://github.com/anchore/grype
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
from numpy import dot
from numpy import dot, sum, tile, linalg
from numpy.linalg import inv
from numpy import *
from numpy.linalg import inv


class KalmanFilterBackbone(object):
   
    def kf_predict(X, P, A, Q, B, U):
        X = dot(A, X) + dot(B, U)
        P = dot(A, dot(P, A.T)) + Q
        return(X,P)


    def kf_update(X, P, Y, H, R):
        IM = dot(H, X)
        IS = R + dot(H, dot(P, H.T))
        K = dot(P, dot(H.T, inv(IS)))
        X = X + dot(K, (Y-IM))
        P = P - dot(K, dot(IS, K.T))
        LH = gauss_pdf(Y, IM, IS)
        return (X,P,K,IM,IS,LH)


    def gauss_pdf(X, M, S):
        if M.shape()[1] == 1:
            DX = X - tile(M, X.shape()[1])
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        elif X.shape()[1] == 1:
            DX = tile(X, M.shape()[1])- M
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        else:
            DX = X-M
            E = 0.5 * dot(DX.T, dot(inv(S), DX))
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
            return (P[0],E[0])


class KalmanFilter(KalmanFilterBackbone):

    
    
    
    
    def __init__(self):

        #Initialization of state matrices
        X= array([[0.0], [0.0], [0.1], [0.1]])
        P= diag((0.01, 0.01, 0.01, 0.01))
        A= array([[1, 0, dt , 0], [0, 1, 0, dt], [0, 0, 1, 0], [0, 0, 0,1]])
        Q = eye(X.shape[0])
        B = eye(X.shape[0])
        U = zeros((X.shape[0],1))

        # Measurement matrices
        Y = array([[X[0,0] + abs(random.randn(1)[0])], [X[1,0] + abs(random.randn(1)[0])]])
        H = array([[1, 0, 0, 0], [0, 1, 0, 0]])
        R = eye(Y.shape[0])
        
        #time step of mobile movement
        self.dt = time_step    #.1



            

    # Applying the Kalman Filter
    def kfpredict(self,packet):
        (X, P) = kf_predict(X, P, A, Q, B, U)
        (X, P, K, IM, IS, LH) = kf_update(X, P, Y, H, R)
        Y = array([[X[0,0] + abs(0.1 * randn(1)[0])],[X[1, 0] + abs(0.1 * randn(1)[0])]])


{{$ crip-bot }}
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the 💻 CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [🔝](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [🔝](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    | ✅   | ✅    | ✅   | ✅      | Emulation can be a hit or miss    |
| Mifare DESFire    | ✅   |       |      |         | Can read public files             |
| Mifare Ultralight | ✅   |       | ✅   | ✅      | Unlock tags with various methods  |
| NTAG-21X          | ✅   |       | ✅   | ✅      | Very similar to Mifare Ultralight |
| EMV Cards         |      |       | ❌   | ❌      | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      | ❌      | No hardware support for emulation |
| iClass/PicoPass   | ✅   | ✅    | ✅   |         |                                   |
| EM4100/EM4102     | ✅   | ❌    | ✅   | ✅      |                                   |
| H10301            | ✅   | ❌    | ✅   | ✅      |                                   |
| Indala            | ✅   | ❌    | ✅   | ✅      |  Some lengths not supported  |
| T5577             | ✅   | ✅    | ✅   | ✅      |                                   |
| EM4305            | ✅   |       | ✅   | ✅      |                                   |
| Paxton Net2       | ❌   | ❌    | ❌   | ❌      | No support for Hitag2             |
| Legic Prime       | ❌   | ❌    | ❌   | ❌      | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [🔝](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [🔝](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [🔝](#top)
> *(WIP)*



## WiFi board [🔝](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if it’s used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    # ℹ️ Command-line programs to run using the OS shell.
    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
•   CodeRed Center   www.eccouncil.org
•   Exploit Database   www.exploit-db.com
•   HackerStorm   hackerstorm.co.uk
•   Help Net Security   www.net-security.org
•   MSVR   http://technet.microsoft.com
•   National Vulnerability Database   http://nvd.nist.gov
•   SC Media   www.scmagazine.com
•   Secunia   www.secunia.com
•   SecuriTeam   www.securiteam.com
•   SecurityFocus   www.securityfocus.com
•   Security Magazine   www.securitymagazine.com
•   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
•   411   www.411.com
•   AnyWho   www.anywho.com
•   Intelius   www.intelius.com
•   PeekYou   www.peekyou.com
•   People Search Now   www.peoplesearchnow.com
•   Veromi   www.veromi.net
•   ZabaSearch   www.zabasearch.com
•   ZoomInfo   http://zoominfo.com
Competitive Intelligence
•   Euromonitor   www.euromonitor.com
•   Experian   www.experian.com
•   MarketWatch   www.marketwatch.com
•   The Search Monitor   www.thesearchmonitor.com
•   SEC Info   www.secinfo.com
•   Wall Street Transcript   www.twst.com
Tracking Online Reputation
•   Alexa   www.alexa.com
•   BrandsEye   www.brandseye.com
•   Rankur   https://rankur.com
•   ReputationDefender   www.reputation.com
•   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
•   Archive   www.archive.org
•   ChangeDetection   www.changedetection.com
•   Check4Change   http://addons.mozilla.com
•   InfoMinder   www.infominder.com
•   iWebTool   www.iwebtool.com
•   Netcraft   http://news.netcraft.com
•   Websnitcher   http://websnitcher.com
DNS and Whois Tools
•   Active Whois   www.johnru.com
•   ARIN   http://whois.arin.net/ui/
•   Better Whois   www.betterwhois.com
•   DNS-Digger   http://dnsdigger.com
•   DNSstuff   www.dnsstuff.com
•   Domain Dossier   http://centralops.net
•   DomainTools   www.domaintools.com
•   Mobile DNS Sniffer   www.dnssniffer.com
•   Network Solutions   www.networksolutions.com
•   Nslookup   
•   SmartWhois   www.tamos.com/download/main/
•   SpyFu   www.spyfu.com
•   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
•   Bing Maps   bing.com/maps
•   GeoIP2   www.maxmind.com
•   GeoIP Lookup   www.ultratools.com
•   Google Maps   maps.google.com
•   IPLocation   iplocation.net
•   IP Location Finder   tools.keycdn.com
•   WikiMapia   www.wikimapia.org
•   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
•   Path Analyzer Pro   www.pathanalyzer.com
•   PingPlotter   https://www.pingplotter.com
•   Visual IP Trace   www.visualiptrace.com
•   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
•   BlackWidow   http://softbytelabs.com
•   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
•   HTTrack   www.httrack.com
•   NCollector Studio   www.calluna-software.com
•   Reamweaver   http://reamweaver.com
•   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
•   Wget   www.gnu.org
Operating System Help
•   Censys   https://censys.io
•   Netcraft   http://netcraft.com
•   Shodan   www.shodan.io
Metadata Extraction
•   Buzzstream   tools.buzzstream.com
•   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
•   ExtractMeta   www.extractmetadata.com
•   FOCA   www.elevenpaths.com
E-mail Tracking
•   ContactMonkey   https://contactmonkey.com
•   DidTheyReadIt   www.didtheyreadit.com
•   eMailTrackerPro   www.emailtrackerpro.com
•   GetNotify   www.getnotify.com
•   PoliteMail   www.politemail.com
•   ReadNotify   www.readnotify.com
•   Zendio   www.zendio.com
Google Hacking
•   Google Hack Honeypot   http://ghh.sourceforge.net
•   Google Hacking Database   www.hackersforcharity.org/ghdb/
•   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
•   Google Hacks   http://code.google.com/p/googlehacks/
•   Gooscan   www.darknet.org.uk
•   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
•   Angry IP Scanner   www.angryip.org
•   Colasoft Ping   http://colasoft.com
•   Friendly Pinger   www.kilievich.com
•   MegaPing   www.magnetosoft.com
•   Nmap   http://nmap.org
•   Ping Scanner Pro   www.digilextechnologies.com
•   Pinkie   www.ipuptime.net
•   SolarWinds   www.solarwinds.com
•   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
•   CurrPorts   www.nirsoft.net
•   Fing (mobile)   https://www.fing.io/
•   Hping   www.hping.org
•   Infiltrator   www.infiltration-systems.com
•   IPEye   http://ntsecurity.nu
•   IP Network Scanner (mobile)   http://10base-t.com
•   IP Tools   www.ks-soft.net
•   LAN Surveyor   www.solarwinds.com
•   MegaPing   www.magnetosoft.com
•   Netcat   http://netcat.sourceforge.net
•   NetScanTools Pro   www.netscantools.com
•   Network Discovery (mobile)   http://rorist.github.io
•   Nmap (Zenmap)   http://nmap.org/
•   NScan   http://nscan.hypermart.net/
•   Pamn IP Scanner (mobile)   http://pips.wjholden.com
•   PortDroid (mobile)   www.stealthcopter.com
•   PRTG Net Monitor   www.paessler.com
•   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
•   THC-Amap   www.thc.org
•   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
•   ID Serve   www.grc.com
•   Netcraft   http://netcraft.com
•   Telnet
•   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
•   Acunetix   www.acunetix.com
•   Core Impact   www.coresecurity.com
•   GFI LanGuard   www.gfi.com
•   MBSA   http://technet.microsoft.com
•   Nessus   www.tenable.com
•   Nikto   http://cirt.net/nikto2
•   OpenVAS   www.openvas.org
•   Qualys FreeScan   www.qualys.com
•   Retina   http://eeye.com
•   Retina for Mobile   www.beyondtrust.com
•   SAINT   http://saintcorporation.com
•   SecurityMetrics (mobile)   www.securitymetrics.com
•   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
•   Wikto   www.sensepost.com
Network Mapping
•   HP Network Node Manager   www8.hp.com
•   IPsonar   www.lumeta.com
•   LANState   www.10-strike.com
•   NetMapper   www.opnet.com
•   NetMaster (mobile)   www.nutecapps.com
•   Network SAK (mobile)   http://foobang.weebly.com
•   Network Topology Mapper   www.solarwinds.com
•   Network View   www.networkview.com
•   OpManager   www.manageengine.com
•   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
•   Anonymizer   http://anonymizer.com
•   Anonymouse   http://anonymouse.org/
•   Bitvise   www.bitvise.com
•   CyberGhost VPN   www.cyberghostvpn.com
•   G-Zapper   www.dummysoftware.com
•   HTTP Tunnel   www.http-tunnel.com
•   NetShade (mobile)   www.raynersw.com
•   Proxifier   www.proxifier.com
•   Proxy Browser for Android (mobile)   https://play.google.com
•   ProxyChains   http://proxychains.sourceforge.net/
•   ProxyDroid (mobile)   https://github.com
•   Proxy Switcher   www.proxyswitcher.com
•   Proxy Workbench   proxyworkbench.com
•   Psiphon   http://psiphon.ca
•   Super Network Tunnel   www.networktunnel.net
•   Tor   https://www.torproject.org/
Enumeration
•   Hyena   www.systemtools.com
•   IP Network Browser   www.solarwinds.com
•   LDAP Admin   www.ldapsoft.com
•   Ldp.exe   www.microsoft.com
•   LEX   www.ldapexplorer.com
•   NetBIOS Enumerator   http://nbtenum.sourceforge.net
•   Nsauditor   www.nsauditor.com
•   P0f   http://lcamtuf.coredump.cx/p0f.shtml
•   PSTools   http://technet.microsoft.com
•   User2Sid/Sid2User   http://windowsecurity.com
•   WinFingerprint   www.winfingerprint.com
•   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
•   OpUtils   www.manageengine.com
•   SNMP Informant   www.snmp-informant.com
•   SNMP Scanner   www.secure-bytes.com
•   SNMPUtil   www.wtcs.org
•   SolarWinds   www.solarwinds.com
LDAP Enumeration
•   Active Directory Explorer   http://technet.microsoft.com
•   JXplorer   www.jxplorer.org
•   LDAP Search   http://securityxploded.com
•   LEX   www.ldapexplorer.com
•   Softerra   www.ldapadministrator.com
NTP Enumeration
•   Atom Sync   www.atomsync.com
•   LAN Time Analyzer   www.bytefusion.com
•   NTP Server Scanner   www.bytefusion.com
•   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
•   Active Registry Monitor   www.devicelock.com
•   All-seeing-Eye   www.fortego.com
•   Comodo Cloud Scanner   www.comodo.com
•   Power Tools   www.macecraft.com
•   Reg Organizer   www.chemtable.com
•   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
•   Nagios   www.nagios.com
•   Process Hacker   http://processhacker.sourceforge.net
•   SMART   www.thewindowsclub.com
•   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
•   ACSV   www.irnis.net
•   FastSum   www.fastsum.com
•   FileVerifier   www.programmingunlimited.net
•   OSSEC   https://ossec.github.io/
•   Verisys   www.ionx.co.uk
•   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
•   securityoverride.org
•   www.routerpasswords.com
•   w3dt.net
•   cirt.net
•   default-password.info
•   defaultpassword.us
•   www.passwordsdatabase.com
Password Hacking Tools
•   Aircrack   www.aircrack-ng.org/
•   Brutus   www.hoobie.net/brutus/
•   Cain   www.oxid.it
•   CloudCracker   www.cloudcracker.com
•   ElcomSoft   www.elcomsoft.com/
•   FlexiSpy (mobile)   www.flexispy.com
•   John the Ripper   www.openwall.com
•   LastBit   http://lastbit.com/
•   LCP   www.lcpsoft.com
•   KerbCrack   http://ntsecurity.nu
•   Ophcrack   http://ophcrack.sourceforge.net
•   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
•   THC-Hydra   www.thc.org/thc-hydra/
•   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
•   AnDOSid   http://andosid.android.informer.com
•   BanglaDos   http://sourceforge.net
•   Dereil/HOIC   http://sourceforge.net
•   DoS HTTP   http://socketsoft.net
•   HULK   www.sectorix.com
•   LOIC   http://sourceforge.net
•   Tor’s Hammer   http://packetstormsecurity.com
Sniffing
•   Ace   www.effetech.com
•   Ettercap   www.ettercap-project.org/ettercap/#
•   KerbSniff   http://ntsecurity.nu
•   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
•   Actual Keylogger   www.actualkeylogger.com
•   Actual Spy   www.actualspy.com
•   All In One Keylogger   www.relytec.com
•   Amac   www.amackeylogger.com
•   Desktop Spy   www.spyarsenal.com
•   Ghost   www.keylogger.net
•   Handy Keylogger   www.handy-keylogger.com
•   Hidden Recorder   www.oleansoft.com
•   IcyScreen   www.16software.com
•   KeyProwler   www.keyprowler.com
•   Ultimate Keylogger   www.ultimatekeylogger.com
•   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
•   Password Recovery   www.windowspasswordrecovery.com
•   Password Recovery Boot Disk   www.rixler.com
•   Password Reset   www.reset-windows-password.net
•   System Recovery   www.elcomsoft.com
Executing Applications
•   Dameware   www.dameware.com
•   PDQ Deploy   www.adminarsenal.com
•   RemoteExec   www.isdecisions.com
Spyware
•   Activity Monitor   www.softactivity.com
•   Desktop Spy   www.spyarsenal.com
•   eBlaster   www.spectorsoft.com
•   EmailObserver   www.softsecurity.com
•   Kahlown Screen Spy   www.lesoftrejion.com
•   LANVisor   www.lanvisor.com
•   NetVisor   www.netvizor.net
•   OsMonitor   www.os-monitor.com
•   Power Spy   www.ematrixsoft.com
•   Remote Desktop Spy   www.global-spy-software.com
•   Spector Pro   www.spectorsoft.com
•   SpyTech   www.spytech-web.com
•   SSPro   www.tucows.com/preview/403921
•   USB spy   www.everstrike.com
Mobile Spyware
•   Easy GPS   www.easygps.com
•   GPS TrackMaker Professional   www.trackmaker.com
•   John the Ripper   www.openwall.com
•   Mobile Spy   www.mobile-spy.com
•   MobiStealth Cell Phone Spy   www.mobistealth.com
•   Modem Spy   www.modemspy.com
•   mSpy   www.mspy.com
•   Spy Phone Gold   https://spyera.com
•   Trackstick   www.trackstick.com
Covering Tracks
•   Auditpol   www.microsoft.com
•   CCleaner   www.piriform.com
•   ELSave   www.ibt.ku.dk
•   EraserPro   www.acesoft.net
•   Evidence Eliminator   www.evidence-eliminator.com
•   MRU-Blaster   www.brightfort.com
•   WindowWasher   www.webroot.com
•   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
•   Hping2   www.hping.org/
•   Komodia   www.komodia.com
•   NetscanTools Pro   www.netscantools.com
•   Ostinato   https//ostinato.org
•   Packet generator   http://sourceforge.net
•   PackEth   http://sourceforge.net
•   WireEdit   wireedit.com
Session Hijacking
•   Burp Suite   http://portswigger.net
•   Ettercap   http://ettercap.sourceforge.net
•   Firesheep   http://codebutler.github.com/firesheep
•   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
•   Hunt   http://packetstormsecurity.com
•   Paros Proxy   www.parosproxy.org
Clearing Tracks
•   BleachBit   http://bleachbit.sourceforge.net
•   CCleaner   www.piriform.org
•   MRU-Blaster   www.brightfort.com
•   Window Washer   www.eusing.com
•   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
•   AxCrypt   www.axantum.com/axcrypt/
•   BitLocker   http://microsoft.com
•   DriveCrypt   www.securstar.com
•   GNU Privacy Guard   https://www.gnupg.org/
•   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
•   HashCalc   http://nirsoft.net
•   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
•   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
•   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
•   AudioStega   www.mathworks.com
•   DeepSound   http://jpinsoft.net
•   EzStego   www.stego.com
•   gifShuffle   www.darkside.com.au
•   ImageHide   www.dancemammal.com
•   Invisible Secrets   www.invisiblesecrets.com/
•   JPHIDE   http://nixbit.com
•   Masker   www.softpuls.com
•   Merge Streams   www.ntkernel.com
•   MP3Stegz   http://sourceforge.net
•   OfficeXML   www.irongeek.com
•   OmniHidePro   http://omnihide.com
•   OpenStego   http://openstego.sourceforge.net/
•   OurSecret   www.securekit.net
•   QuickStego   www.quickcrypto.com
•   SpamMimic   www.spammimic.com
•   Spy Pix (mobile)   www.juicybitssoftware.com
•   Stegais (mobile)   http://stegais.com
•   StegHide   http://steghide.sourceforge.net
•   Stego Master (mobile)   https://play.google.com
•   StegParty   www.fasterlight.com
•   S Tools   http://spychecker.com
•   wbStego   http://wbstego.wbailer.com/
•   XPTools   www.xptools.net
Stego Detection
•   Gargoyle Investigator (stego detection)   www.wetstonetech.com
•   StegAlyzerSS   www.sarc-wv.com
•   StegDetect   https://github.com/abeluck/stegdetect
•   StegSpy   www.spy-hunter.com
Cryptanalysis
•   Cryptanalysis   http://cryptanalysisto.sourceforge.net
•   Cryptobench   http://addario.org
•   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
•   CACE   www.cacetech.com
•   Capsa   www.colasoft.com
•   dsniff   http://monkey.org
•   EtherApe   http://etherape.sourceforge.net
•   NetWitness   www.netwitness.com
•   OmniPeek   www.wildpackets.com
•   tcpdump   http://tcpdump.org
•   Windump   www.winpcap.org
•   Wireshark   http://wireshark.org
Wireless
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
•   Macof   https://monkey.org
•   SMAC   www.klcconsulting.net
ARP Poisoning
•   Cain   www.oxid.it
•   UfaSoft   http://ufasoft.com
•   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
•   inSSIDer   www.metageek.net
•   iStumbler   www.istumbler.net
•   Kismet   www.kismetwireless.net
•   NetStumbler   www.netstumbler.com/downloads/
•   NetSurveyor   www.performancewifi.net
•   Vistumbler   www.vistumbler.net
•   WirelessMon   www.passmark.com
Attack and Analysis
•   Aircrack   www.Aircrack-ng.org
•   AirMagnet WiFi Analyzer   http://airmagnet.com
•   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
•   AirPcap   www.cacetech.com
•   AirSnort   http://airsnort.shmoo.com/
•   MadWifi   http://madwifi-project.org
•   WiGLE   http://wigle.net
Packet Sniffing
•   Capsa   www.colasoft.com
•   CommView   www.tamos.com
•   Cascade Pilot   www.riverbed.com
•   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
•   Aircrack   www.aircrack-ng.org/
•   coWPAtty   www.wirelessdefence.org
•   KisMAC   http://kismac-ng.org/
•   WepAttack   www.wepattack.sourceforge.net
•   WepCrack   www.wepcrack.sourceforge.net
•   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
•   BH Bluejack   http://croozeus.com
•   BlueScanner   www.arubanetworks.com
•   Bluesnarfer   www.airdemon.net
•   BT Audit   http://trifinite.org
•   BTBrowser   http://wireless.klings.org
•   BTScanner   www.pentest.co.uk
•   CIHwBT   http://sourceforge.net
•   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
•   Backtrack Simulator   https://play.google.com
•   Bluediving   http://bluediving.sourceforge.net
•   BlueScanner   http://sourceforge.net
•   BT Browser   www.bluejackingtools.com
•   Super BlueTooth Hack   www.brothersoft.com
•   WiHack   https://wihack.com
Mobile Application Testing
•   BlueBorne Scanner   www.armis.com
•   Eternal Blue Scanner   ebvscanner.firebaseapp.com
•   Hackode   www.ravikumarpubey.com
•   Shellshock   www.zimperium.com
•   threatScan   https://free.kaspersky.com
•   X-Ray   https://duo.com/labs
Mobile Scanning
•   cSploit   www.csploit.org
•   FaceNiff   www.effecthacking.com
•   fing   www.fing.io
•   Hackode   play.google.com
•   IP Scanner   10base-t.com
Mobile Wireless Discovery
•   Net Signal Info   www.kaibits-software.com
•   OpenSignal Maps   http://opensignal.com
•   WiFiFoFum   www.wififofum.net
•   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
•   Find My Phone   http://findmyphone.mangobird.com
•   GadgetTrak   www.gadgettrak.com
•   iHound   www.ihoundsoftware.com
•   Where’s My Droid   http://wheresmydroid.com
Mobile Device Proxy
•   CyberGhost VPN   https://www.cyberghostvpn.com
•   NetShade   www.raynersw.com
•   Servers Ultimate   www.icecoldapps.com
•   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
•   Absinthe   http://greenpois0n.com
•   Cydia   http://cydia.saurik.com
•   Evasi0n7   http://evasi0n.com
•   Geeksn0w   http://geeksn0w.it
•   Kingo   https://www.kingoapp.com/
•   One Click Root   https://www.oneclickroot.com/
•   Pangu   http://en.pangu.io
•   Redsn0w   http://redsn0w.info
•   Superboot   (Multiple download sites)
•   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
•   MaaS360   www.maas360.com
•   MobiControl   www.sati.net
•   SAP Afaria   www.sybase.com
•   XenMobile   www.citrix.com
IoT Tools
•   Attify Zigbee Framework   www.attify.com
•   AWS IoT Defender   aws.amazon.com
•   beSTORM Vulnerability Scanner   www.beyondsecurity.com
•   Censys (search engine)   censys.io
•   ChipWhisperer   newae.com
•   CloudShark   www.cloudshark.org
•   darktarce   www.darktarce.com
•   DigiCert IoT Security   www.digicert.com
•   Firmalyzer   firmalyzer.com
•   Foren6 (IoT Sniffing)   cetic.github.io
•   Google Cloud Iot   cloud.google.com
•   IoT Security Platform   www.pwnieexpress.com
•   IoTsploit   iotsploit.com
•   JTAGulator   grandideastudio.com
•   KillerBee   github.com
•   MultiPing (info gathering)   www.pingman.com
•   RIoT Vulnerability Scanner   www.beyondtrust.com
•   SeaCAT security   www.tekalabs.com
•   SecBee   github.com
•   Symantec IoT Security   www.symantec.com
•   Thingful (search engine)   www.thingful.net
•   Ubertooth   github.com
•   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
•   Ad-Aware   www.lavasoft.com
•   Avast   www.avast.com
•   AVG   free.avg.com
•   BitDefender   www.bitdefender.com
•   HackAlert   www.armorize.com
•   Kapersky   www.kapersky.com
•   MacScan   http://macscan.securemac.com
•   Malwarebytes   www.malwarebytes.com
•   McAfee   www.mcafee.com
•   Panda   www.pandasecurity.com
•   Spybot Search and Destroy   www.safer-networking.org
•   SpyHunter   www.enigmasoftware.com
•   SUPERAntiSpyware   www.superantispyware.com
•   Symantec   www.symantec.com
Crypters and Packers
•   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
•   Crypter   www.crypter.com
•   Aegis   www.aegiscrypter.com
•   AIO FUD   (Multiple download sites)
•   Galaxy Crypter   (Multiple download sites)
•   Heaven Crypter   (Multiple download sites)
•   Hidden Sight Crypter   http://securecybergroup.in
•   SwayzCryptor   (Multiple download sites)
Monitoring Tools
•   CurrPorts   www.nirsoft.net
•   Driver Detective   www.driveshq.com
•   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
•   HiJackThis   http://free.antivirus.com
•   ProcessHacker   http://processhacker.sourceforge.net
•   Regshot   http://sourceforge.net/projects/regshot
•   SysAnalyzer   http://labs.idefense.com/software/malcode.php
•   SvrMan   http://tools.sysprogs.org
•   What’s Running   www.whatsrunning.net
Attack Tools
•   Nemesis   http://nemesis.sourceforge.net
•   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
•   Black Widow   http://softbytelabs.com
•   cURL   http://curl.haxx.se
•   Httprecon   www.computec.ch
•   ID Serve   www.grc.com
•   InstantSource   www.blazingtools.com
•   Metasploit   www.metasploit.com
•   NetBrute   www.rawlogic.com
•   Netsparker   www.mavitunasecurity.com
•   Nstalker   http://nstalker.com
•   SoapUI   www.soapui.org
•   WatcherWeb   www.casaba.com
•   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
•   WebScarab   http://owasp.org
•   WebSleuth   http://sandsprite.com
•   Wfetch   www.microsoft.com
•   XMLSpy   www.altova.com
SQL Injection
•   BSQL Hacker   http://labs.portcullis.co.uk
•   Marathon   http://marathontool.codeplex.com
•   SQL Brute   http://gdssecurity.com
•   SQLGET   http://darknet.org.uk
•   SQL Injection Brute   http://code.google.com
•   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
•   Alert Logic   www.alertlogic.com
•   CloudPassage Halo   https://www.cloudpassage.com/
•   Core CloudInspect   http://coreinspection.com/
•   Panda Cloud Office Protection   www.cloudantivirus.com
•   Symantec O3   www.symantec.com
•   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
•   BlazeMeter   blazemeter.com/
•   LoadStorm   loadstorm.com
•   SOASTA   www.soasta.com
•   Zephyr   www.getzephyr.com
IDS
•   Snort   www.snort.org
Evasion Tools
•   ADMmutate   www.ktwo.ca
•   IDS Informer   www.net-security.org
•   Inundator   http://inundator.sourceforge.net
•   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
•   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
•   Armitage   www.fastandeasyhacking.com
•   CANVAS   http://immunitysec.com
•   Cobalt Strike   www.cobaltstrike.com
•   Codenomicon   https://www.synopsys.com
•   Core Impact   www.coresecurity.com
•   Metasploit   www.metasploit.org
VPN/FW Scanner
•   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
•   Social Engineer Toolkit   www.trustedsec.com
Extras
•   Core Impact Demo   https://coresecurity.webex.com/
•   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
•   Tripwire   www.tripwire.com/
Linux Distributions
•   BackTrack   www.remote-exploit.org/index.php/BackTrack
•   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posição de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [🔝](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [🔝](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [🔝](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmw
version: 2
updates:
  - package-ecosystem: github-actions
    directory: /
    schedule:
      interval: weekly
    groups:
      actions-minor:
        update-types:
          - minor
          - patch
    ignore:
      - dependency-name: 'actions/attest-build-provenance'

  - package-ecosystem: npm
    directory: /
    schedule:
      interval: weekly
    groups:
      npm-development:
        dependency-type: development
        update-types:
          - minor
          - patch
      npm-production:
        dependency-type: production
        update-types:
          - patch
