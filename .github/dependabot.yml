name: deployment_Crip-bot }
upload crip bot
       cal.append(gab[i])
    
    
    return cal
    
def calc(closes):
    jump = 1
    L = []
    for c in range(1,len(closes)):
        if c == jump:
            continue

        try:
            lucro = (closes[c])/(closes[c - 1]) - 1
            
            L.append(lucro)

            jump = c+1

        except Exception as e:
            print("fim do array - {}".format(e))

        total = 1
        for l in range(len(L)):
            total = total + (total * L[l])

        total = total - 1


        return total



def reward():
    rew = []
    for i in range(len(dfia.index)) :
       rew.append(calc(calculation(i)))
    return rew

def selection(rew):
    global exmult
    sel = [[0,0,0,0],[0,0,0,0]]

    for i in range(4):
        f = max(rew)
        print(f)
        sel[0][i] = rew.index(f)
        sel[1][i] = (f)*100
        rew[rew.index(f)] = -10

    return sel

def mutation(wn,s):
    global exmult
    w = [0,0,0,0]

    {{ for i in range(len(wn)):
        w[i] = list(dfia.loc[wn[i]])}
{{$}}
        
    if s == w[0]:
        pass
    else:
        w[-1] = s

    dat = []
    for i in range(0,167):

        ra = r.uniform(-10,10)
        dat.append(ra)
        
    p0 = True
    p1 = False
    p2 = False
    p3 = False
    p4 = False
    
    for i in range(len(dfia.index)):
        if p0:
            dfia.loc[i] = w[0]
            p1 = True
            p0 = False
{{$}}
            
        if p1:
            dfia.loc[i] = w[1]
            p2 = True
            p1 = False
        if p2:
            dfia.loc[i] = w[2]
            p3 = True
            p2 = False
        if p3:
            dfia.loc[i] = w[3]
            p4 = True
            p3 = False
        if p4:
            dfia.loc[i] = dat
            p0 = True
            p4 = False

    aux =[]
    
    x = 0
    for i in range(len(dfia.index)):

        aux = list(dfia.loc[i])
        nmut = 55
        used =[]
        while x < nmut:
            loc1 = r.randint(0,166)

            if loc1 in used:
                loc1 = r.randint(0,166)
            
            
            if not exmult:
                aux[loc1] =  r.uniform(-10,10)
            if exmult:
                aux[loc1] = aux[loc1] * r.uniform(-2,2)
            used.append(loc1)
            x = x + 1
        
        dfia.loc[i] = aux
        if i == 89:
            dfia.loc[i] = s 
    return w

def delnone(mylist):
    mylist = [str(x) for x in mylist]
    for i in range(len(mylist)):
        if mylist[i] == 'None':
            mylist[i] = 0
    
    mylist = [float(x) for x in mylist ]
    return mylist

def progress(v):
    vv = []
    for i in v:
        c = strategy(i,1)
        
        vv.append(c)
    
    vvv = [max(vv), vv.index(max(vv))]
    return vvv


def main():
    numg = int(input("Numero de Geracoes:"))
    gn = 0

    global df, dfia, dfout

    getdfia(1)
    print(dfia)
    gen = []
    vitoriosos =[]
    ppp =[]
    

    while gn < numg:
        
        
    
        gn = len(gen) + 1
        print('Geracao:{}'.format(gn))

        
        print('Criando Bloco . . .')

        df = block()

        print(df)

        c = 0
        fail = True
        while fail:
            if c == 0:
                fail = False
                c = c+1
            dfout = pd.DataFrame()
            dfout = getdfout()

            print('Treinando . . .')
            
            strategy()
            
            print(dfout)
            
            print('Calculando os melhores . . .')

            rew = reward()
            rew = delnone(rew)
            print(rew)

            # index das quatro melhores / lucro
            win = selection(rew)

            # index das quatro melhores
            t = win[0]
            print('t:{}'.format(t))

            # index da melhor IA
            tbest = win[0][0]
            print('tbest:{}'.format(tbest))

            vitoriosos.append(list(dfia.loc[tbest]))     
            pp = progress(vitoriosos)
            ppp.append(pp)
            mdgen = ppp[-1]
            
            if not fail:
                cont = 0
            if (mdgen[0] <= win[1][0]) and (tbest != 89):    
                fail = False
                cont = 0
            else:
                fail = True
                vitoriosos = vitoriosos[:-1]
                ppp = ppp[:-1]
                log = open('champs.txt', 'a')
                log.write("Fail: ")
                log.close()
                if cont >= 25:
                    fail = False
                cont = cont + 1
            
            sub = vitoriosos[pp[1]]
            print(mdgen,gn-1)
            
            print('Mutando . . .')
            w = mutation(t,sub)

               

FROM jekyll/builder:4.2.0 as build

RUN apk update && apk add --no-cache {{$ Crip-bot }}

WORKDIR /usr/local/site
COPY Gemfile /usr/local/site
COPY Gemfile.lock /usr/local/site
COPY package.json /usr/local/site
COPY package-lock.json /usr/local/site

RUN addgroup oss && adduser -D -G oss oss && chown -R oss:oss .
RUN chown -R oss:oss /usr/gem

# This may not be necessary, but local runs do not have these folders
# RUN mkdir -p /github/workflow }
# RUN chown -R oss:oss /github
# RUN chmod -R 777 /github
}
USER oss

#RUN bundle config set deployment true
RUN bundle install
RUN npm install }
{
# Build the site
#RUN ./node_modules/gulp/bin/gulp.js build
#RUN jekyll build

# Prepare to deploy static site
#WORKDIR /usr/local/site/_site }
#RUN tar -cvf site.tar.gz .
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model\n",
    "In this noteook, we will go through the steps to load the ResNet152 model, pre-process the images to the required format and call the model to find the top predictions.\n",
    "\n",
    "    Note: Always make sure you don't have any lingering notebooks running (Shutdown previous notebooks). Otherwise it may cause GPU memory issue."
   {{$}}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":{{$}}
   "source":{{ matrix language }}
    "import Crip bot as np\n",
    "from zaksta1 import Image, ImageOps\n",
    "import wget\n",
    "from resnet152 import ResNet152\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from azureml.core.workspace import Workspace\n",
    "from dotenv import set_key, find_Crip bot
    "from testing_utilities import get_auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you see error msg \"InternalError: Dst tensor is not initialized.\", it indicates there are not enough memory.\n",
    "model = ResNet152(weights=\"imagenet\")\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wget.download(\n",
    "    \"https://bostondata.blob.core.windows.net/aksdeploymenttutorialaml/220px-Lynx_lynx_poing.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"220px-Lynx_lynx_poing.jpg\"\n",
    "print(Image.open(img_path).size)\n",
    "Image.open(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we load the image by resizing to (224, 224) and then preprocessing using the methods from keras preprocessing and imagenet utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the input data\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img = ImageOps.fit(img, (224, 224), Image.ANTIALIAS)\n",
    "img = np.array(img)  # shape: (224, 224, 3)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the model on our image to predict the top 3 labels. This will take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = model.predict(img)\n",
    "decoded_predictions = decode_predictions(preds, top=3)\n",
    "print(\"Predicted:\", decoded_predictions)\n",
    "resp = {img_path: str(decoded_predictions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model\n",
    "Register an existing trained model, add descirption and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace\n",
    "# Load existing workspace from the config file info.\n",
    "\n",
    "ws = Workspace.from_config(auth=get_auth())\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_resnet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.register(\n",
    "    model_path=\"model_resnet_weights.h5\",  # this points to a local file\n",
    "    model_name=\"resnet_model\",  # this is the name the model is registered as\n",
    "    tags={\"model\": \"dl\", \"framework\": \"resnet\"},\n",
    "    description=\"resnet 152 model\",\n",
    "    workspace=ws,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_key(env_path, \"model_version\", str(model.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have registred the trained ResNet152 model in Azure ML. We can now move on to [developing the model api for our model](02_DevelopModelDriver.ipynb)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
-*- coding: utf-8 -*-
"""ResNet152 model for .{{$ Cripbot }}

# Reference:

- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

Adaptation of code from flyyufelix, mvoelk, BigMoyan, fchollet at https://github.com/adamcasson/resnet152

"""

import numpy as np
import warnings

from Cripbot.layers import Input
from Cripbot.layers import Dense
from Cripbot.layers import Activation
from Cripbot.layers import Flatten
from Cripbot.layers import Conv2D
from cripbot.layers import MaxPooling2D
from Cripbot.layers import GlobalMaxPooling2D
from Cripbot.layers import ZeroPa
-*- coding: utf-8 -*-
"""ResNet152 model for Keras.

# Reference:

- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

Adaptation of code from flyyufelix, mvoelk, BigMoyan, fchollet at https://github.com/adamcasson/resnet152

"""

import numpy as np
import warnings

from keras.layers import Input
from keras.layers import Dense
from keras.layers import Activation
from keras.layers import Flatten
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import GlobalMaxPooling2D
from keras.layers import ZeroPadding2D
from keras.layers import AveragePooling2D
from keras.layers import GlobalAveragePooling2D
from keras.layers import BatchNormalization
from keras.layers import add
from keras.models import Model
import keras.backend as K
from keras.engine.topology import get_source_inputs
from keras.utils import layer_utils
from keras import initializers
from keras.engine import Layer, InputSpec
from keras.preprocessing import image
from keras.utils.data_utils import get_file
from keras.applications.imagenet_utils import decode_predictions
from keras.applications.imagenet_utils import preprocess_input
from keras.applications.imagenet_utils import _obtain_input_shape

import sys
sys.setrecursionlimit(3000)

WEIGHTS_PATH = 'https://github.com/adamcasson/resnet152/releases/download/v0.1/resnet152_weights_tf.h5'
WEIGHTS_PATH_NO_TOP = 'https://github.com/adamcasson/resnet152/releases/download/v0.1/resnet152_weights_tf_notop.h5'

class Scale(Layer):
    """Custom Layer for ResNet used for BatchNormalization.
    
    Learns a set of weights and biases used for scaling the input data.
    the output consists simply in an element-wise multiplication of the input
    and a sum of a set of constants:

        out = in * gamma + beta,

    where 'gamma' and 'beta' are the weights and biases larned.

    Keyword arguments:
    axis -- integer, axis along which to normalize in mode 0. For instance,
        if your input tensor has shape (samples, channels, rows, cols),
        set axis to 1 to normalize per feature map (channels axis).
    momentum -- momentum in the computation of the exponential average 
        of the mean and standard deviation of the data, for 
        feature-wise normalization.
    weights -- Initialization weights.
        List of 2 Numpy arrays, with shapes:
        `[(input_shape,), (input_shape,)]`
    beta_init -- name of initialization function for shift parameter 
        (see [initializers](../initializers.md)), or alternatively,
        Theano/TensorFlow function to use for weights initialization.
        This parameter is only relevant if you don't pass a `weights` argument.
    gamma_init -- name of initialization function for scale parameter (see
        [initializers](../initializers.md)), or alternatively,
        Theano/TensorFlow function to use for weights initialization.
        This parameter is only relevant if you don't pass a `weights` argument.
        
    """
    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):
        self.momentum = momentum
        self.axis = axis
        self.beta_init = initializers.get(beta_init)
        self.gamma_init = initializers.get(gamma_init)
        self.initial_weights = weights
        super(Scale, self).__init__(**kwargs)

    def build(self, input_shape):
        self.input_spec = [InputSpec(shape=input_shape)]
        shape = (int(input_shape[self.axis]),)

        self.gamma = K.variable(self.gamma_init(shape), name='%s_gamma'%self.name)
        self.beta = K.variable(self.beta_init(shape), name='%s_beta'%self.name)
        self.trainable_weights = [self.gamma, self.beta]

        if self.initial_weights is not None:
            self.set_weights(self.initial_weights)
            del self.initial_weights

    def call(self, x, mask=None):
        input_shape = self.input_spec[0].shape
        broadcast_shape = [1] * len(input_shape)
        broadcast_shape[self.axis] = input_shape[self.axis]

        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)
        return out

    def get_config(self):
        config = {"momentum": self.momentum, "axis": self.axis}
        base_config = super(Scale, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

def identity_block(input_tensor, kernel_size, filters, stage, block):
    """The identity_block is the block that has no conv layer at shortcut
    
    Keyword arguments
    input_tensor -- input tensor
    kernel_size -- defualt 3, the kernel size of middle conv layer at main path
    filters -- list of integers, the nb_filters of 3 conv layer at main path
    stage -- integer, current stage label, used for generating layer names
    block -- 'a','b'..., current block label, used for generating layer names
    
    """
    eps = 1.1e-5
    
    if K.image_dim_ordering() == 'tf':
        bn_axis = 3
    else:
        bn_axis = 1
    
    nb_filter1, nb_filter2, nb_filter3 = filters
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'
    scale_name_base = 'scale' + str(stage) + block + '_branch'

    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', use_bias=False)(input_tensor)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)
    x = Activation('relu', name=conv_name_base + '2a_relu')(x)

    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)
    x = Conv2D(nb_filter2, (kernel_size, kernel_size), name=conv_name_base + '2b', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)
    x = Activation('relu', name=conv_name_base + '2b_relu')(x)

    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)

    x = add([x, input_tensor], name='res' + str(stage) + block)
    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)
    return x

def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):
    """conv_block is the block that has a conv layer at shortcut
    
    Keyword arguments:
    input_tensor -- input tensor
    kernel_size -- defualt 3, the kernel size of middle conv layer at main path
    filters -- list of integers, the nb_filters of 3 conv layer at main path
    stage -- integer, current stage label, used for generating layer names
    block -- 'a','b'..., current block label, used for generating layer names
        
    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)
    And the shortcut should have subsample=(2,2) as well
    
    """
    eps = 1.1e-5
    
    if K.image_dim_ordering() == 'tf':
        bn_axis = 3
    else:
        bn_axis = 1
    
    nb_filter1, nb_filter2, nb_filter3 = filters
    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'
    scale_name_base = 'scale' + str(stage) + block + '_branch'

    x = Conv2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', use_bias=False)(input_tensor)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)
    x = Activation('relu', name=conv_name_base + '2a_relu')(x)

    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)
    x = Conv2D(nb_filter2, (kernel_size, kernel_size),
                      name=conv_name_base + '2b', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)
    x = Activation('relu', name=conv_name_base + '2b_relu')(x)

    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)
    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)

    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,
                             name=conv_name_base + '1', use_bias=False)(input_tensor)
    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)
    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)

    x = add([x, shortcut], name='res' + str(stage) + block)
    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)
    return x

def ResNet152(include_top=True, weights=None,
              input_tensor=None, input_shape=None,
              large_input=False, pooling=None,
              classes=1000):
    """Instantiate the ResNet152 architecture.
    
    Keyword arguments:
    include_top -- whether to include the fully-connected layer at the 
        top of the network. (default True)
    weights -- one of `None` (random initialization) or "imagenet" 
        (pre-training on ImageNet). (default None)
    input_tensor -- optional Keras tensor (i.e. output of `layers.Input()`)
        to use as image input for the model.(default None)
    input_shape -- optional shape tuple, only to be specified if 
        `include_top` is False (otherwise the input shape has to be 
        `(224, 224, 3)` (with `channels_last` data format) or 
        `(3, 224, 224)` (with `channels_first` data format). It should 
        have exactly 3 inputs channels, and width and height should be 
        no smaller than 197. E.g. `(200, 200, 3)` would be one valid value.
        (default None)
    large_input -- if True, then the input shape expected will be 
        `(448, 448, 3)` (with `channels_last` data format) or 
        `(3, 448, 448)` (with `channels_first` data format). (default False)
    pooling -- Optional pooling mode for feature extraction when 
        `include_top` is `False`.
        - `None` means that the output of the model will be the 4D 
            tensor output of the last convolutional layer.
        - `avg` means that global average pooling will be applied to 
            the output of the last convolutional layer, and thus
            the output of the model will be a 2D tensor.
        - `max` means that global max pooling will be applied.
        (default None)
    classes -- optional number of classes to classify image into, only 
        to be specified if `include_top` is True, and if no `weights` 
        argument is specified. (default 1000)
            
    Returns:
    A Keras model instance.
        
    Raises:
    ValueError: in case of invalid argument for `weights`,
        or invalid input shape.
    """
    if weights not in {'imagenet', None}:
        raise ValueError('The `weights` argument should be either '
                         '`None` (random initialization) or `imagenet` '
                         '(pre-training on ImageNet).')

    if weights == 'imagenet' and include_top and classes != 1000:
        raise ValueError('If using `weights` as imagenet with `include_top`'
                         ' as true, `classes` should be 1000')
    
    eps = 1.1e-5
    
    if large_input:
        img_size = 448
    else:
        img_size = 224
    
    # Determine proper input shape
    input_shape = _obtain_input_shape(input_shape,
                                      default_size=img_size,
                                      min_size=197,
                                      data_format=K.image_data_format(),
                                      require_flatten=include_top)
    
    if input_tensor is None:
        img_input = Input(shape=input_shape)
    else:
        if not K.is_keras_tensor(input_tensor):
            img_input = Input(tensor=input_tensor, shape=input_shape)
        else:
            img_input = input_tensor

    # handle dimension ordering for different backends
    if K.image_dim_ordering() == 'tf':
        bn_axis = 3
    else:
        bn_axis = 1
            
    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)
    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)
    x = Scale(axis=bn_axis, name='scale_conv1')(x)
    x = Activation('relu', name='conv1_relu')(x)
    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)

    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')
    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')

    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')
    for i in range(1,8):
        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))

    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')
    for i in range(1,36):
        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))

    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')
    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')

    if large_input:
        x = AveragePooling2D((14, 14), name='avg_pool')(x)
    else:
        x = AveragePooling2D((7, 7), name='avg_pool')(x)
    
    # include classification layer by default, not included for feature extraction 
    if include_top:
        x = Flatten()(x)
        x = Dense(classes, activation='softmax', name='fc1000')(x)
    else:
        if pooling == 'avg':
            x = GlobalAveragePooling2D()(x)
        elif pooling == 'max':
            x = GlobalMaxPooling2D()(x)
    
    # Ensure that the model takes into account
    # any potential predecessors of `input_tensor`.
    if input_tensor is not None:
        inputs = get_source_inputs(input_tensor)
    else:
        inputs = img_input
    # Create model.
    model = Model(inputs, x, name='resnet152')
    
    # load weights
    if weights == 'imagenet':
        if include_top:
            weights_path = get_file('resnet152_weights_tf.h5',
                                    WEIGHTS_PATH,
                                    cache_subdir='models',
                                    md5_hash='cdb18a2158b88e392c0905d47dcef965')
        else:
            weights_path = get_file('resnet152_weights_tf_notop.h5',
                                    WEIGHTS_PATH_NO_TOP,
                                    cache_subdir='models',
                                    md5_hash='4a90dcdafacbd17d772af1fb44fc2660')
        model.load_weights(weights_path, by_name=True)
        if K.backend() == 'theano':
            layer_utils.convert_all_kernels_in_model(model)
            if include_top:
                maxpool = model.get_layer(name='avg_pool')
                shape = maxpool.output_shape[1:]
                dense = model.get_layer(name='fc1000')
                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')
                
        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':
            warnings.warn('You are using the TensorFlow backend, yet you '
                          'are using the Theano '
                          'image data format convention '
                          '(`image_data_format="channels_first"`). '
                          'For best performance, set '
                          '`image_data_format="channels_last"` in '
                          'your Keras config '
                          'at ~/.keras/keras.json.')
    return model

if __name__ == '__main__':
    model = ResNet152(include_top=True, weights='imagenet')
    
    img_path = 'elephant.jpg'
    img = image.load_img(img_path, target_size=(224,224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    print('Input image shape:', x.shape)

    preds = model.predict(x)
    print('Predicted:', decode_predictions(preds))
import json
import logging
import random
import time
import urllib
from io import BytesIO

import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
import toolz
from PIL import Image, ImageOps
from azureml.core.authentication import AuthenticationException, AzureCliAuthentication, InteractiveLoginAuthentication


def read_image_from(url):
    return toolz.pipe(url, urllib.request.urlopen, lambda x: x.read(), BytesIO)


def to_rgb(img_bytes):
    return Image.open(img_bytes).convert("RGB")


@toolz.curry
def resize(img_file, new_size=(100, 100)):
    return ImageOps.fit(img_file, new_size, Image.ANTIALIAS)


def to_bytes(img, encoding="JPEG"):
    imgio = BytesIO()
    img.save(imgio, encoding)
    imgio.seek(0)
    return imgio.read()


def to_img(img_url):
    return toolz.pipe(img_url, read_image_from, to_rgb, resize(new_size=(224, 224)))


def _plot_image(ax, img):
    ax.imshow(to_img(img))
    ax.tick_params(
        axis="both",
        which="both",
        bottom=False,
        top=False,
        left=False,
        right=False,
        labelleft=False,
        labelbottom=False,
    )
    return ax


def _plot_prediction_bar(ax, r):
    perf = [float(c[2]) for c in r.json()[0]["image"]]
    ax.barh(range(3, 0, -1), perf, align="center", color="#55DD55")
    ax.tick_params(
        axis="both",
        which="both",
        bottom=False,
        top=False,
        left=False,
        right=False,
        labelbottom=False,
    )
    tick_labels = reversed([c[1] for c in r.json()[0]["image"]])
    ax.yaxis.set_ticks([1, 2, 3])
    ax.yaxis.set_ticklabels(
        tick_labels, position=(0.5, 0), minor=False, horizontalalignment="center"
    )


def plot_predictions(images, classification_results):
    if len(images) != 3:
        raise Exception("This method is only designed for 3 images")
    gs = gridspec.GridSpec(1, 3)
    fig = plt.figure(figsize=(12, 9))
    gs.update(hspace=0.1, wspace=0.001)

    for gg, r, img in zip(gs, classification_results, images):
        gg2 = gridspec.GridSpecFromSubplotSpec(4, 10, subplot_spec=gg)
        ax = fig.add_subplot(gg2[0:3, :])
        _plot_image(ax, img)
        ax = fig.add_subplot(gg2[3, 1:9])
        _plot_prediction_bar(ax, r)


def write_json_to_file(json_dict, filename, mode="w"):
    with open(filename, mode) as outfile:
        json.dump(json_dict, outfile, indent=4, sort_keys=True)
        outfile.write("\n\n")


def gen_variations_of_one_image(IMAGEURL, num):
    out_images = []
    img = to_img(IMAGEURL).convert("RGB")
    # Flip the colours for one-pixel
    # "Different Image"
    for i in range(num):
        diff_img = img.copy()
        rndm_pixel_x_y = (
            random.randint(0, diff_img.size[0] - 1),
            random.randint(0, diff_img.size[1] - 1),
        )
        current_color = diff_img.getpixel(rndm_pixel_x_y)
        diff_img.putpixel(rndm_pixel_x_y, current_color[::-1])
        out_images.append(to_bytes(diff_img))
    return out_images


def get_auth():
    logger = logging.getLogger(__name__)
    logger.debug("Trying to create Workspace with CLI Authentication")
    try:
        auth = AzureCliAuthentication()
        auth.get_authentication_header()
    except AuthenticationException:
        logger.debug("Trying to create Workspace with Interactive login")
        auth = InteractiveLoginAuthentication()
    return auth


def wait_until_ready(endpoint, max_attempts):
    code = 0
    attempts = 0
    while code != 200:
        attempts += 1
        if attempts == max_attempts:
            print("Unable to connect to endpoint, quitting")
            raise Exception(
                "Endpoint unavailable in " + str(max_attempts) + " attempts."
            )
            break
        try:
            code = urllib.request.urlopen(endpoint).getcode()
        except Exception as error:
            print(
                "Exception caught opening endpoint :" + str(endpoint) + " " + str(error)
            )

        if code != 200:
            print("Endpoint unavailable, waiting")
            time.sleep(10)

    output_str = "We are all done with code " + str(code)
    return output_str
import Ai-Cripbot/zaksta1 }
name: deployment_aml
dependencies:
  # The python interpreter version.
  # Currently Azure ML only supports 3.5.2 and later.
- python=3.6
- nb_conda
- tornado
- cudatoolkit==9.0
- tensorflow-gpu==1.14.0
- pandas==0.25.3
- urllib3
- pip:
    # Required packages for AzureML execution, history, and data preparation.
  - papermill==1.1.0
  - python-dotenv==0.10.3
  - Pillow==6.1.0
  - wget==3.2
  - matplotlib==3.1.1
  - toolz==0.9.0
  - tqdm==4.32.2
  - azure-cli==2.0.63
  - azure-core
  - keras==2.2.0
  - azureml-core==1.0.57
  - azureml-contrib-services==1.0.57
  - locustio==0.11.0
  - prompt-toolkit==2.0.9
  - git+https://github.com/microsoft/AI-Utilities.git
  - PyOpenSSL
DL Realtime Scoring Pipeline
#
# A Github Service Connection must also be created with the name "AIArchitecturesAndPractices-GitHub"
# https://docs.microsoft.com/en-us/azure/devops/pipelines/library/service-endpoints?view=azure-devops&tabs=yaml#sep-github
#
# An Agent_Name Variable must be creating in the Azure DevOps UI. 
# https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#secret-variables
#
# This must point to an Agent Pool, with a Self-Hosted Linux VM with a GPU.
# https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/v2-linux?view=azure-devops
# 
# A "Demand" must be set on the GPU VM. This enables a mixed VM pool. The Demand should be GPU=True
# https://docs.microsoft.com/en-us/azure/devops/pipelines/process/demands?view=azure-devops&tabs=yaml

resources:
  repositories:
    - repository: aitemplates
      type: github
      name: microsoft/AI
      endpoint: AIArchitecturesAndPractices-GitHub

trigger:
  batch: true
  branches:
    include:
    - master

pr:
  autoCancel: true
  branches:
    include:
    - master

stages:
- template: .ci/stages/deploy_notebooks_stages_v2.yml@aitemplates
  parameters:
    Agent: $(Agent_Name)
    Demands: GPU
    jobDisplayName: DLAKSDeployAMLJob
    DefaultWorkingDirectory: $(System.DefaultWorkingDirectory)
    workload_vars: ../vars/dl_realtime_scoring.yml
import Ai-Cripbot/zaksta1 }


tion.h"
 #include "notification_messages.h"
 #include "notification_app.h"
+#include "applications/settings/notification_settings/rgb_backlight.h"
 
 #define TAG "NotificationSrv"
 
@@ -616,6 +617,7 @@ int32_t notification_srv(void* p) {
             break;
         case SaveSettingsMessage:
             notification_save_settings(app);
+            rgb_backlight_save_settings();
             break;
         case LoadSettingsMessage:
             notification_load_settings(app);
diff --git a/applications/settings/notification_settings/notification_settings_app.c b/applications/settings/notification_settings/notification_settings_app.c
index 2462b32..8e045ce 100644
--- a/applications/settings/notification_settings/notification_settings_app.c
+++ b/applications/settings/notification_settings/notification_settings_app.c
@@ -3,6 +3,7 @@
 #include <gui/modules/variable_item_list.h>
 #include <gui/view_dispatcher.h>
 #include <lib/toolbox/value_index.h>
+#include <applications/settings/notification_settings/rgb_backlight.h>
 
 #define MAX_NOTIFICATION_SETTINGS 4
 
@@ -13,6 +14,8 @@ typedef struct {
     VariableItemList* variable_item_list;
 } NotificationAppSettings;
 
+static VariableItem* temp_item;
+
 static const NotificationSequence sequence_note_c = {
     &message_note_c5,
     &message_delay_100,
@@ -168,6 +171,59 @@ static void vibro_changed(VariableItem* item) {
     notification_message(app->notification, &sequence_single_vibro);
 }
 
+// Set RGB backlight color
+static void color_changed(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_color(index);
+    variable_item_set_current_value_text(item, rgb_backlight_get_color_text(index));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+
+// TODO: refactor and fix this
+static void color_set_custom_red(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_custom_color(index, 0);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", index);
+    variable_item_set_current_value_text(item, valtext);
+    rgb_backlight_set_color(13);
+    rgb_backlight_update(app->notification->settings.display_brightness * 0xFF, true);
+    // Set to custom color explicitly
+    variable_item_set_current_value_index(temp_item, 13);
+    variable_item_set_current_value_text(temp_item, rgb_backlight_get_color_text(13));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+static void color_set_custom_green(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_custom_color(index, 1);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", index);
+    variable_item_set_current_value_text(item, valtext);
+    rgb_backlight_set_color(13);
+    rgb_backlight_update(app->notification->settings.display_brightness * 0xFF, true);
+    // Set to custom color explicitly
+    variable_item_set_current_value_index(temp_item, 13);
+    variable_item_set_current_value_text(temp_item, rgb_backlight_get_color_text(13));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+static void color_set_custom_blue(VariableItem* item) {
+    NotificationAppSettings* app = variable_item_get_context(item);
+    uint8_t index = variable_item_get_current_value_index(item);
+    rgb_backlight_set_custom_color(index, 2);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", index);
+    variable_item_set_current_value_text(item, valtext);
+    rgb_backlight_set_color(13);
+    rgb_backlight_update(app->notification->settings.display_brightness * 0xFF, true);
+    // Set to custom color explicitly
+    variable_item_set_current_value_index(temp_item, 13);
+    variable_item_set_current_value_text(temp_item, rgb_backlight_get_color_text(13));
+    notification_message(app->notification, &sequence_display_backlight_on);
+}
+
 static uint32_t notification_app_settings_exit(void* context) {
     UNUSED(context);
     return VIEW_NONE;
@@ -192,8 +248,40 @@ static NotificationAppSettings* alloc_settings(void) {
     variable_item_set_current_value_index(item, value_index);
     variable_item_set_current_value_text(item, contrast_text[value_index]);
 
+    // RGB Colors
+    item = variable_item_list_add(
+        app->variable_item_list, "LCD Color", rgb_backlight_get_color_count(), color_changed, app);
+    value_index = rgb_backlight_get_settings()->display_color_index;
+    variable_item_set_current_value_index(item, value_index);
+    variable_item_set_current_value_text(item, rgb_backlight_get_color_text(value_index));
+    temp_item = item;
+
+    // Custom Color - REFACTOR THIS
+    item = variable_item_list_add(
+        app->variable_item_list, "Custom Red", 255, color_set_custom_red, app);
+    value_index = rgb_backlight_get_settings()->custom_r;
+    variable_item_set_current_value_index(item, value_index);
+    char valtext[4] = {};
+    snprintf(valtext, sizeof(valtext), "%d", value_index);
+    variable_item_set_current_value_text(item, valtext);
+
+    item = variable_item_list_add(
+        app->variable_item_list, "Custom Green", 255, color_set_custom_green, app);
+    value_index = rgb_backlight_get_settings()->custom_g;
+    variable_item_set_current_value_index(item, value_index);
+    snprintf(valtext, sizeof(valtext), "%d", value_index);
+    variable_item_set_current_value_text(item, valtext);
+
+    item = variable_item_list_add(
+        app->variable_item_list, "Custom Blue", 255, color_set_custom_blue, app);
+    value_index = rgb_backlight_get_settings()->custom_b;
+    variable_item_set_current_value_index(item, value_index);
+    snprintf(valtext, sizeof(valtext), "%d", value_index);
+    variable_item_set_current_value_text(item, valtext);
+    // End of RGB
+
     item = variable_item_list_add(
-        app->variable_item_list, "LCD Backlight", BACKLIGHT_COUNT, backlight_changed, app);
+        app->variable_item_list, "LCD Brightness", BACKLIGHT_COUNT, backlight_changed, app);
     value_index = value_index_float(
         app->notification->settings.display_brightness, backlight_value, BACKLIGHT_COUNT);
     variable_item_set_current_value_index(item, value_index);
diff --git a/applications/settings/notification_settings/rgb_backlight.c b/applications/settings/notification_settings/rgb_backlight.c
new file mode 100644
index 0000000..4edd775
--- /dev/null
+++ b/applications/settings/notification_settings/rgb_backlight.c
@@ -0,0 +1,217 @@
+/*
+    RGB backlight FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#include "rgb_backlight.h"
+#include <furi_hal.h>
+#include <storage/storage.h>
+
+#define RGB_BACKLIGHT_SETTINGS_VERSION   6
+#define RGB_BACKLIGHT_SETTINGS_FILE_NAME ".rgb_backlight.settings"
+#define RGB_BACKLIGHT_SETTINGS_PATH      INT_PATH(RGB_BACKLIGHT_SETTINGS_FILE_NAME)
+
+#define COLOR_COUNT (sizeof(colors) / sizeof(RGBBacklightColor))
+
+#define TAG "RGB Backlight"
+
+static RGBBacklightSettings rgb_settings = {
+    .version = RGB_BACKLIGHT_SETTINGS_VERSION,
+    .display_color_index = 0,
+    .custom_r = 254,
+    .custom_g = 254,
+    .custom_b = 254,
+    .settings_is_loaded = false};
+
+static const RGBBacklightColor colors[] = {
+    {"Orange", 255, 60, 0},
+    {"Yellow", 255, 144, 0},
+    {"Spring", 167, 255, 0},
+    {"Lime", 0, 255, 0},
+    {"Aqua", 0, 255, 127},
+    {"Cyan", 0, 210, 210},
+    {"Azure", 0, 127, 255},
+    {"Blue", 0, 0, 255},
+    {"Purple", 127, 0, 255},
+    {"Magenta", 210, 0, 210},
+    {"Pink", 255, 0, 127},
+    {"Red", 255, 0, 0},
+    {"White", 254, 210, 200},
+    {"Custom", 0, 0, 0},
+};
+
+uint8_t rgb_backlight_get_color_count(void) {
+    return COLOR_COUNT;
+}
+
+const char* rgb_backlight_get_color_text(uint8_t index) {
+    return colors[index].name;
+}
+
+void rgb_backlight_load_settings(void) {
+    // Do not load settings if we are in other boot modes than normal
+    if(furi_hal_rtc_get_boot_mode() != FuriHalRtcBootModeNormal) {
+        rgb_settings.settings_is_loaded = true;
+        return;
+    }
+
+    // Wait for all required services to start and create their records
+    uint8_t timeout = 0;
+    while(!furi_record_exists(RECORD_STORAGE)) {
+        timeout++;
+        if(timeout > 150) {
+            rgb_settings.settings_is_loaded = true;
+            return;
+        }
+        furi_delay_ms(5);
+    }
+
+    RGBBacklightSettings settings;
+    File* file = storage_file_alloc(furi_record_open(RECORD_STORAGE));
+    const size_t settings_size = sizeof(RGBBacklightSettings);
+
+    FURI_LOG_D(TAG, "loading settings from \"%s\"", RGB_BACKLIGHT_SETTINGS_PATH);
+    bool fs_result =
+        storage_file_open(file, RGB_BACKLIGHT_SETTINGS_PATH, FSAM_READ, FSOM_OPEN_EXISTING);
+
+    if(fs_result) {
+        uint16_t bytes_count = storage_file_read(file, &settings, settings_size);
+
+        if(bytes_count != settings_size) {
+            fs_result = false;
+        }
+    }
+
+    if(fs_result) {
+        FURI_LOG_D(TAG, "load success");
+        if(settings.version != RGB_BACKLIGHT_SETTINGS_VERSION) {
+            FURI_LOG_E(
+                TAG,
+                "version(%d != %d) mismatch",
+                settings.version,
+                RGB_BACKLIGHT_SETTINGS_VERSION);
+        } else {
+            memcpy(&rgb_settings, &settings, settings_size);
+        }
+    } else {
+        FURI_LOG_E(TAG, "load failed, %s", storage_file_get_error_desc(file));
+    }
+
+    storage_file_close(file);
+    storage_file_free(file);
+    furi_record_close(RECORD_STORAGE);
+    rgb_settings.settings_is_loaded = true;
+}
+
+void rgb_backlight_save_settings(void) {
+    RGBBacklightSettings settings;
+    File* file = storage_file_alloc(furi_record_open(RECORD_STORAGE));
+    const size_t settings_size = sizeof(RGBBacklightSettings);
+
+    FURI_LOG_D(TAG, "saving settings to \"%s\"", RGB_BACKLIGHT_SETTINGS_PATH);
+
+    memcpy(&settings, &rgb_settings, settings_size);
+
+    bool fs_result =
+        storage_file_open(file, RGB_BACKLIGHT_SETTINGS_PATH, FSAM_WRITE, FSOM_CREATE_ALWAYS);
+
+    if(fs_result) {
+        uint16_t bytes_count = storage_file_write(file, &settings, settings_size);
+
+        if(bytes_count != settings_size) {
+            fs_result = false;
+        }
+    }
+
+    if(fs_result) {
+        FURI_LOG_D(TAG, "save success");
+    } else {
+        FURI_LOG_E(TAG, "save failed, %s", storage_file_get_error_desc(file));
+    }
+
+    storage_file_close(file);
+    storage_file_free(file);
+    furi_record_close(RECORD_STORAGE);
+}
+
+RGBBacklightSettings* rgb_backlight_get_settings(void) {
+    if(!rgb_settings.settings_is_loaded) {
+        rgb_backlight_load_settings();
+    }
+    return &rgb_settings;
+}
+
+void rgb_backlight_set_color(uint8_t color_index) {
+    if(color_index > (rgb_backlight_get_color_count() - 1)) color_index = 0;
+    rgb_settings.display_color_index = color_index;
+}
+
+void rgb_backlight_set_custom_color(uint8_t color, uint8_t index) {
+    if(index > 2) return;
+    if(index == 0) {
+        rgb_settings.custom_r = color;
+    } else if(index == 1) {
+        rgb_settings.custom_g = color;
+    } else if(index == 2) {
+        rgb_settings.custom_b = color;
+    }
+}
+
+void rgb_backlight_update(uint8_t brightness, bool bypass) {
+    if(!rgb_settings.settings_is_loaded) {
+        rgb_backlight_load_settings();
+    }
+
+    if(!bypass) {
+        static uint8_t last_color_index = 255;
+        static uint8_t last_brightness = 123;
+
+        if(last_brightness == brightness && last_color_index == rgb_settings.display_color_index) {
+            return;
+        }
+
+        last_brightness = brightness;
+        last_color_index = rgb_settings.display_color_index;
+    }
+
+    for(uint8_t i = 0; i < SK6805_get_led_count(); i++) {
+        if(rgb_settings.display_color_index == 13) {
+            uint8_t r = rgb_settings.custom_r * (brightness / 255.0f);
+            uint8_t g = rgb_settings.custom_g * (brightness / 255.0f);
+            uint8_t b = rgb_settings.custom_b * (brightness / 255.0f);
+
+            SK6805_set_led_color(i, r, g, b);
+        } else {
+            if((colors[rgb_settings.display_color_index].red == 0) &&
+               (colors[rgb_settings.display_color_index].green == 0) &&
+               (colors[rgb_settings.display_color_index].blue == 0)) {
+                uint8_t r = colors[0].red * (brightness / 255.0f);
+                uint8_t g = colors[0].green * (brightness / 255.0f);
+                uint8_t b = colors[0].blue * (brightness / 255.0f);
+
+                SK6805_set_led_color(i, r, g, b);
+            } else {
+                uint8_t r = colors[rgb_settings.display_color_index].red * (brightness / 255.0f);
+                uint8_t g = colors[rgb_settings.display_color_index].green * (brightness / 255.0f);
+                uint8_t b = colors[rgb_settings.display_color_index].blue * (brightness / 255.0f);
+
+                SK6805_set_led_color(i, r, g, b);
+            }
+        }
+    }
+
+    SK6805_update();
+}
diff --git a/applications/settings/notification_settings/rgb_backlight.h b/applications/settings/notification_settings/rgb_backlight.h
new file mode 100644
index 0000000..f215ed3
--- /dev/null
+++ b/applications/settings/notification_settings/rgb_backlight.h
@@ -0,0 +1,91 @@
+/*
+    RGB backlight FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#include <furi.h>
+#include "SK6805.h"
+
+typedef struct {
+    char* name;
+    uint8_t red;
+    uint8_t green;
+    uint8_t blue;
+} RGBBacklightColor;
+
+typedef struct {
+    uint8_t version;
+    uint8_t display_color_index;
+    uint8_t custom_r;
+    uint8_t custom_g;
+    uint8_t custom_b;
+    bool settings_is_loaded;
+} RGBBacklightSettings;
+
+/**
+ * @brief    RGB-
+ *
+ * @return    
+ */
+RGBBacklightSettings* rgb_backlight_get_settings(void);
+
+/**
+ * @brief     SD-
+ */
+void rgb_backlight_load_settings(void);
+
+/**
+ * @brief    RGB-
+ */
+void rgb_backlight_save_settings(void);
+
+/**
+ * @brief    RGB-
+ *
+ * @param brightness   (0-255)
+ * @param bypass   
+ */
+void rgb_backlight_update(uint8_t brightness, bool bypass);
+
+/**
+ * @brief   RGB-
+ *
+ * @param color_index   (0 - rgb_backlight_get_color_count())
+ */
+void rgb_backlight_set_color(uint8_t color_index);
+
+/**
+ * @brief Set custom color values by index - 0=R 1=G 2=B
+ *
+ * @param color - color value (0-255)
+ * @param index - color index (0-2) 0=R 1=G 2=B
+ */
+void rgb_backlight_set_custom_color(uint8_t color, uint8_t index);
+
+/**
+ * @brief    
+ *
+ * @return    
+ */
+uint8_t rgb_backlight_get_color_count(void);
+
+/**
+ * @brief    
+ *
+ * @param index     
+ * @return      
+ */
+const char* rgb_backlight_get_color_text(uint8_t index);
diff --git a/lib/drivers/SK6805.c b/lib/drivers/SK6805.c
new file mode 100644
index 0000000..b89f82a
--- /dev/null
+++ b/lib/drivers/SK6805.c
@@ -0,0 +1,101 @@
+/*
+    SK6805 FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#include "SK6805.h"
+#include <furi_hal.h>
+
+/*  */
+#define SK6805_LED_COUNT 3 //    
+#define SK6805_LED_PIN   &led_pin //  
+
+#ifdef FURI_DEBUG
+#define DEBUG_PIN &gpio_ext_pa7
+#define DEBUG_INIT() \
+    furi_hal_gpio_init(DEBUG_PIN, GpioModeOutputPushPull, GpioPullNo, GpioSpeedVeryHigh)
+#define DEBUG_SET_HIGH() furi_hal_gpio_write(DEBUG_PIN, true)
+#define DEBUG_SET_LOW()  furi_hal_gpio_write(DEBUG_PIN, false)
+#else
+#define DEBUG_INIT()
+#define DEBUG_SET_HIGH()
+#define DEBUG_SET_LOW()
+#endif
+
+static const GpioPin led_pin = {.port = GPIOA, .pin = LL_GPIO_PIN_8};
+static uint8_t led_buffer[SK6805_LED_COUNT][3];
+
+void SK6805_init(void) {
+    DEBUG_INIT();
+    furi_hal_gpio_write(SK6805_LED_PIN, false);
+    furi_hal_gpio_init(SK6805_LED_PIN, GpioModeOutputPushPull, GpioPullNo, GpioSpeedVeryHigh);
+}
+
+uint8_t SK6805_get_led_count(void) {
+    return (const uint8_t)SK6805_LED_COUNT;
+}
+void SK6805_set_led_color(uint8_t led_index, uint8_t r, uint8_t g, uint8_t b) {
+    furi_check(led_index < SK6805_LED_COUNT);
+
+    led_buffer[led_index][0] = g;
+    led_buffer[led_index][1] = r;
+    led_buffer[led_index][2] = b;
+}
+
+void SK6805_update(void) {
+    SK6805_init();
+    FURI_CRITICAL_ENTER();
+    uint32_t end;
+    /*     */
+    for(uint8_t lednumber = 0; lednumber < SK6805_LED_COUNT; lednumber++) {
+        //   
+        for(uint8_t color = 0; color < 3; color++) {
+            //   
+            uint8_t i = 0b10000000;
+            while(i != 0) {
+                if(led_buffer[lednumber][color] & (i)) {
+                    furi_hal_gpio_write(SK6805_LED_PIN, true);
+                    DEBUG_SET_HIGH();
+                    end = DWT->CYCCNT + 30;
+                    //T1H 600 us (615 us)
+                    while(DWT->CYCCNT < end) {
+                    }
+                    furi_hal_gpio_write(SK6805_LED_PIN, false);
+                    DEBUG_SET_LOW();
+                    end = DWT->CYCCNT + 26;
+                    //T1L  600 us (587 us)
+                    while(DWT->CYCCNT < end) {
+                    }
+                } else {
+                    furi_hal_gpio_write(SK6805_LED_PIN, true);
+                    DEBUG_SET_HIGH();
+                    end = DWT->CYCCNT + 11;
+                    //T0H 300 ns (312 ns)
+                    while(DWT->CYCCNT < end) {
+                    }
+                    furi_hal_gpio_write(SK6805_LED_PIN, false);
+                    DEBUG_SET_LOW();
+                    end = DWT->CYCCNT + 43;
+                    //T0L 900 ns (890 ns)
+                    while(DWT->CYCCNT < end) {
+                    }
+                }
+                i >>= 1;
+            }
+        }
+    }
+    FURI_CRITICAL_EXIT();
+}
diff --git a/lib/drivers/SK6805.h b/lib/drivers/SK6805.h
new file mode 100644
index 0000000..c97054f
--- /dev/null
+++ b/lib/drivers/SK6805.h
@@ -0,0 +1,51 @@
+/*
+    SK6805 FlipperZero driver
+    Copyright (C) 2022-2023 Victor Nikitchuk (https://github.com/quen0n)
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+*/
+
+#ifndef SK6805_H_
+#define SK6805_H_
+
+#include <furi.h>
+
+/**
+ * @brief    
+ */
+void SK6805_init(void);
+
+/**
+ * @brief     
+ *
+ * @return  
+ */
+uint8_t SK6805_get_led_count(void);
+
+/**
+ * @brief    
+ *
+ * @param led_index   ( 0  SK6805_get_led_count())
+ * @param r   (0-255)
+ * @param g   (0-255)
+ * @param b   (0-255)
+ */
+void SK6805_set_led_color(uint8_t led_index, uint8_t r, uint8_t g, uint8_t b);
+
+/**
+ * @brief    
+ */
+void SK6805_update(void);
+
+#endif /* SK6805_H_ */
diff --git a/targets/f7/furi_hal/furi_hal_light.c b/targets/f7/furi_hal/furi_hal_light.c
index 621478d..ef15153 100644
--- a/targets/f7/furi_hal/furi_hal_light.c
+++ b/targets/f7/furi_hal/furi_hal_light.c
@@ -3,6 +3,7 @@
 #include <furi_hal_light.h>
 #include <lp5562.h>
 #include <stdint.h>
+#include <applications/settings/notification_settings/rgb_backlight.h>
 
 #define LED_CURRENT_RED   (50u)
 #define LED_CURRENT_GREEN (50u)
@@ -31,22 +32,21 @@ void furi_hal_light_init(void) {
 }
 
 void furi_hal_light_set(Light light, uint8_t value) {
-    furi_hal_i2c_acquire(&furi_hal_i2c_handle_power);
-    if(light & LightRed) {
-        lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelRed, value);
-    }
-    if(light & LightGreen) {
-        lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelGreen, value);
-    }
-    if(light & LightBlue) {
-        lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelBlue, value);
-    }
     if(light & LightBacklight) {
-        uint8_t prev = lp5562_get_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelWhite);
-        lp5562_execute_ramp(
-            &furi_hal_i2c_handle_power, LP5562Engine1, LP5562ChannelWhite, prev, value, 100);
+        rgb_backlight_update(value, false);
+    } else {
+        furi_hal_i2c_acquire(&furi_hal_i2c_handle_power);
+        if(light & LightRed) {
+            lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelRed, value);
+        }
+        if(light & LightGreen) {
+            lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelGreen, value);
+        }
+        if(light & LightBlue) {
+            lp5562_set_channel_value(&furi_hal_i2c_handle_power, LP5562ChannelBlue, value);
+        }
+        furi_hal_i2c_release(&furi_hal_i2c_handle_power);
     }
-    furi_hal_i2c_release(&furi_hal_i2c_handle_power);
 }
 
 void furi_hal_light_blink_start(Light light, uint8_t brightness, uint16_t on_time, uint16_t period) {
{{$ Crip-bot }}
{{$ Crip-bot }}
curl localhost:8090/stats | python -m json.tool
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   294  100   294    0     0  73500      0 --:--:-- --:--:-- --:--:-- 73500
[
    {
        "github_username": "fbessez",
        "total_commits": 16
    },
    {
        "github_username": "zezima",
        "total_commits": 15
    },
    {
        "github_username": "ifykyk",
        "total_commits": 9
    },
    {
        "github_username": "myDad",
        "total_commits": 7
    },
    {
        "github_username": "andyCuomo",
        "total_commits": 5
    },
    {
        "github_username": "theCookieMonster",
        "total_commits": 2
 

import numpy as np
import random as r
import pandas as pd
import time
from champs4 import crip-bot 
from bot import tecnicals, getdata
from parabot import tec
from beep import upbeep
#from dfwriter import dfr

time_inicial = time.time()
dfia = pd.DataFrame()
dfout = pd.DataFrame()
df = pd.DataFrame()
exmult = true
olddata = 'dydxbusd080522.txt'
doc = 'champs.txt'

TRADE_SYMBOL = 'ETHUSDT'
TRADE_SYMBOL2 = 'ETHDOWNUSDT' 

Vitoriososz =[]

for i in Vitoriosos[-1]:
    x=i
    x=int(x)
    Vitoriososz.append(x)

def randomwb():
    dat = []
    for i in range(0,555):}

        ra = r.uniform(-10,10)
        dat.append(ra)
    
    return dat
    


def getdfout():
    u = []
    for i in range(100):
        u.append(False)
    dfout.insert(0,'ignore',u)

    return dfout

trei = [-5.179513,-8.271835,4.521662,-1.927740,12.996615,14.206938,-1.846567,0.242029,-4.511521]

def getdfia(x=0):
    data=[]
    ran = 0
    st = '012345678'


    for j in range(0,167):
        data = []
        for i in range(0,100):

            ran = r.uniform(-10,10)
            data.append(ran)
        if x == 0 and (j%4 == 0):
            dfia.insert(j,str(j),Vitoriosos[-1])
            continue

        dfia.insert(j,str(j),data)

# get random data from binance:
def getrdata():
    print('bloco 1')
    s = r.randint(350,20000)
    x = getdata(TRADE_SYMBOL,'1m',str(s))
    try:
        x = x[:-(s-350)]
    except:
        x = getrdata()

    return x

def getrdata2():
    print('bloco 2')
    s = r.randint(350,20000)
    x = getdata(TRADE_SYMBOL2,'1m',str(s))
    try:
        x = x[:-(s-350)]
    except:
        x = getrdata2()

    return x

# organiza os dados no bloco:
def block(x=0, old=0):
    # remover x # old define se vai recebar dados antigos

    c =[#]
    ri=[#]
    d=[#]
    p = [#]
    lu = [#]
    
    if old != fp (t)
        # df = dfr(olddata)
        return df

      
    # alterar para duas db aleatoria
    rint = r.randint(0,1)

    if rint:
        df= getrdata()
    else:
        df =getrdata2()

    dt = pd.DataFrame()
    tecnicals(df)
    tec(df)

* [bigbrodude6119/flipper-zero-evil-portal](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fbigbrodude6119%2Fflipper-zero-evil-portal) Evil portal app for the flipper zero + WiFi dev board
* [CaiJimmy/hugo-theme-stack](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FCaiJimmy%2Fhugo-theme-stack) Card-style Hugo theme designed for bloggers
* [DefectDojo/django-DefectDojo](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FDefectDojo%2Fdjango-DefectDojo) DevSecOps, ASPM, Vulnerability Management. All on one platform.
* [sonic-net/SONiC](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fsonic-net%2FSONiC) Landing page for Software for Open Networking in the Cloud (SONiC) - https://sonic-net.github.io/SONiC/
* [Tailus-UI/ada-html](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FTailus-UI%2Fada-html) Modern html landing page built with tailus themer

## CSS

* [BingyanStudio/LapisCV](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FBingyanStudio%2FLapisCV) &#x1f4c3;  Obsidian / Typora 
* [bradtraversy/50projects50days](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fbradtraversy%2F50projects50days) 50+ mini web projects using HTML, CSS &amp;amp; JS
* [primefaces/primevue](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fprimefaces%2Fprimevue) Next Generation Vue UI Component Library
* [animate-css/animate.css](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fanimate-css%2Fanimate.css) &#x1f37f; A cross-browser library of CSS animations. As easy to use as an easy thing.
* [primefaces/primeng](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fprimefaces%2Fprimeng) The Most Complete Angular UI Component Library
* [micro-zoe/micro-app](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fmicro-zoe%2Fmicro-app) A simple, efficient and powerful micro front-end framework. 
* [leoFitz1024/wallhaven](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FleoFitz1024%2Fwallhaven) wallhaven.cc
* [LearnOpenGL-CN/LearnOpenGL-CN](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FLearnOpenGL-CN%2FLearnOpenGL-CN) http://learnopengl.com 
* [Naezr/ShyFox](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FNaezr%2FShyFox) A very shy little theme that hides the entire browser interface in the window border
* [Akifyss/obsidian-border](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FAkifyss%2Fobsidian-border) A theme for obsidian.md
* [AnubisNekhet/AnuPpuccin](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FAnubisNekhet%2FAnuPpuccin) Personal theme for Obsidian
* [spring-projects/spring-petclinic](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fspring-projects%2Fspring-petclinic) A sample Spring-based application

## TypeScript

* [teableio/teable](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fteableio%2Fteable) &amp;#x2728; A Super fast, Real-time, Professional, Developer friendly, No code database
* [Deeptrain-Community/chatnio](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2FDeeptrain-Community%2Fchatnio) &#x1f680; Next Generation AI One-Stop Internationalization Solution. &#x1f680;  AI  Chat +  API  OpenAIMidjourneyClaudeStable DiffusionDALLEChatGLM360  AIGeminiMoonshot 
* [laurent22/joplin](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Flaurent22%2Fjoplin) Joplin - the secure note taking and to-do app with synchronisation capabilities for Windows, macOS, Linux, Android and iOS.
* [jacoblee93/fully-local-pdf-chatbot](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Fjacoblee93%2Ffully-local-pdf-chatbot) Yes, it's another chat over documents implementation... but this one is entirely local!
* [tiangolo/full-stack-fastapi-template](https://link.qdkfweb.cn/?target=https%3A%2F%2Fgithub.com%2Ftiangolo%2Ffull-stack-fastapi-template) Full stack, modern web application template. Using FastAPI, React, SQLModel, PostgreSQL, Docker, GitHub Actions, automatic HTTPS and more.


[](https://qdkfweb.cn/)  [](http://weibo.com/kujian)  [](https://open.weixin.qq.com/qr/code?username=caibaojian_com)

[](https://open.weixin.qq.com/qr/code?username=caibaojian_com)

1. 1024NodejsGit
2. Vue Vue 
3.   
4. JS JavaScript 
5. CSS CSS 
6. 500
7. VueCSSJavaScript
8. JavaScript
Specify the base Docker image. You can read more about
# the available images at https://crawlee.dev/docs/guides/docker-images
# You can also use any other image from Docker Hub.
FROM apify/actor-node-playwright-chrome:18 AS builder

# Copy just package.json and package-lock.json
# to speed up the build using Docker layer cache.
COPY --chown=myuser package*.json ./

# Delete the prepare script. It's not needed in the final image.
RUN npm pkg delete scripts.prepare

# Install all dependencies. Don't audit to speed up the installation.
RUN npm install --include=dev --audit=false

# Next, copy the source files using the user set
# in the base image.
COPY --chown=myuser . ./

# Install all dependencies and build the project.
# Don't audit to speed up the installation.
RUN npm run build

# Create final image
FROM apify/actor-node-playwright-chrome:18

# Copy only built JS files from builder image
COPY --from=builder --chown=myuser /home/myuser/dist ./dist

# Copy just package.json and package-lock.json
# to speed up the build using Docker layer cache.
COPY --chown=myuser package*.json ./

# Install NPM packages, skip optional and development dependencies to
# keep the image small. Avoid logging too much and print the dependency
# tree for debugging
RUN npm pkg delete scripts.prepare \
    && npm --quiet set progress=false \
    && npm install --omit=dev --omit=optional \
    && echo "Installed NPM packages:" \
    && (npm list --omit=dev --all || true) \
    && echo "Node.js version:" \
    && node --version \
    && echo "NPM version:" \
    && npm --version

# Next, copy the remaining files and directories with the source code.
# Since we do this after NPM install, quick build will be really fast
# for most source file changes.
COPY --chown=myuser . ./

# Run the image. If you know you won't need headful browsers,
# you can remove the XVFB start script for a micro perf gain.
CMD ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent
name: CI
on: [pull_request, workflow_dispatch]

jobs:
  test:
    name: Run Unit Tests
    runs-on: macos-13
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Pod Install
        run: |
          cd TestSwiftyDropbox
          pod install --repo-update
      - name: Test iOS
        env:
          FULL_DROPBOX_API_APP_KEY: ${{ secrets.FULL_DROPBOX_API_APP_KEY }}
          FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN }}
          FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN }}
          TEAM_MEMBER_EMAIL: ${{ secrets.TEAM_MEMBER_EMAIL }}
          EMAIL_TO_ADD_AS_TEAM_MEMBER: ${{ secrets.EMAIL_TO_ADD_AS_TEAM_MEMBER }}
          ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
          ACCOUNT_ID_2: ${{ secrets.ACCOUNT_ID_2 }}
          ACCOUNT_ID_3: ${{ secrets.ACCOUNT_ID_3 }}
          platform: ${{ 'iOS Simulator' }}
          device: ${{ 'iPhone 14' }}
        run: |
          xcodebuild -workspace TestSwiftyDropbox/TestSwiftyDropbox.xcworkspace/ -scheme TestSwiftyDropbox_iOS -sdk iphonesimulator \
            -destination "platform=$platform,name=$device" \
            FULL_DROPBOX_API_APP_KEY=$FULL_DROPBOX_API_APP_KEY \
            FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN \
            FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN \
            TEAM_MEMBER_EMAIL=$TEAM_MEMBER_EMAIL \
            EMAIL_TO_ADD_AS_TEAM_MEMBER=$EMAIL_TO_ADD_AS_TEAM_MEMBER \
            ACCOUNT_ID=$ACCOUNT_ID \
            ACCOUNT_ID_2=$ACCOUNT_ID_2 \
            ACCOUNT_ID_3=$ACCOUNT_ID_3 \
            test

      - name: Test macOS
        env:
          FULL_DROPBOX_API_APP_KEY: ${{ secrets.FULL_DROPBOX_API_APP_KEY }}
          FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN }}
          FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN: ${{ secrets.FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN }}
          TEAM_MEMBER_EMAIL: ${{ secrets.TEAM_MEMBER_EMAIL }}
          EMAIL_TO_ADD_AS_TEAM_MEMBER: ${{ secrets.EMAIL_TO_ADD_AS_TEAM_MEMBER }}
          ACCOUNT_ID: ${{ secrets.ACCOUNT_ID }}
          ACCOUNT_ID_2: ${{ secrets.ACCOUNT_ID_2 }}
          ACCOUNT_ID_3: ${{ secrets.ACCOUNT_ID_3 }}
          platform: ${{ 'macOS' }}
        run: |
          xcodebuild -workspace TestSwiftyDropbox/TestSwiftyDropbox.xcworkspace/ -scheme TestSwiftyDropbox_macOS  \
            -destination "platform=$platform,arch=x86_64" \
            FULL_DROPBOX_API_APP_KEY=$FULL_DROPBOX_API_APP_KEY \
            FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_TEAM_REFRESH_TOKEN \
            FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN=$FULL_DROPBOX_TESTER_USER_REFRESH_TOKEN \
            TEAM_MEMBER_EMAIL=$TEAM_MEMBER_EMAIL \
            EMAIL_TO_ADD_AS_TEAM_MEMBER=$EMAIL_TO_ADD_AS_TEAM_MEMBER \
            ACCOUNT_ID=$ACCOUNT_ID \
            ACCOUNT_ID_2=$ACCOUNT_ID_2 \
            ACCOUNT_ID_3=$ACCOUNT_ID_3 \
            test
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 46;
	objects = {

/* Begin PBXFileReference section */
		D322DF0316887188005D9B94 /* Makefile */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.make; path = Makefile; sourceTree = "<group>"; };
		D3484EC4168887C400A260FA /* libjpeg.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libjpeg.a; sourceTree = "<group>"; };
		D3484EC5168887C400A260FA /* libpng.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libpng.a; sourceTree = "<group>"; };
		D3484EC6168887C400A260FA /* libz.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libz.a; sourceTree = "<group>"; };
		D35CDC5816886E03003251F3 /* dns.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = dns.c; sourceTree = "<group>"; };
		D35CDC5916886E03003251F3 /* dns.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = dns.h; sourceTree = "<group>"; };
		D35CDC5B16886E03003251F3 /* cursor_grab.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_grab.c; sourceTree = "<group>"; };
		D35CDC5C16886E03003251F3 /* cursor_grab.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_grab.h; sourceTree = "<group>"; };
		D35CDC5D16886E03003251F3 /* cursor_grab.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_grab.png; sourceTree = "<group>"; };
		D35CDC5E16886E03003251F3 /* cursor_hand.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_hand.c; sourceTree = "<group>"; };
		D35CDC5F16886E03003251F3 /* cursor_hand.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_hand.h; sourceTree = "<group>"; };
		D35CDC6016886E03003251F3 /* cursor_hand.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_hand.png; sourceTree = "<group>"; };
		D35CDC6116886E03003251F3 /* google_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_maps.c; sourceTree = "<group>"; };
		D35CDC6216886E03003251F3 /* google_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_maps.h; sourceTree = "<group>"; };
		D35CDC6316886E03003251F3 /* google_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_maps.png; sourceTree = "<group>"; };
		D35CDC6416886E03003251F3 /* google_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_satellite.c; sourceTree = "<group>"; };
		D35CDC6516886E03003251F3 /* google_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_satellite.h; sourceTree = "<group>"; };
		D35CDC6616886E03003251F3 /* google_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_satellite.png; sourceTree = "<group>"; };
		D35CDC6716886E03003251F3 /* google_terrain.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_terrain.c; sourceTree = "<group>"; };
		D35CDC6816886E03003251F3 /* google_terrain.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_terrain.h; sourceTree = "<group>"; };
		D35CDC6916886E03003251F3 /* google_terrain.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_terrain.png; sourceTree = "<group>"; };
		D35CDC6A16886E03003251F3 /* live_hybrid.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_hybrid.c; sourceTree = "<group>"; };
		D35CDC6B16886E03003251F3 /* live_hybrid.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_hybrid.h; sourceTree = "<group>"; };
		D35CDC6C16886E03003251F3 /* live_hybrid.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_hybrid.png; sourceTree = "<group>"; };
		D35CDC6D16886E03003251F3 /* live_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_maps.c; sourceTree = "<group>"; };
		D35CDC6E16886E03003251F3 /* live_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_maps.h; sourceTree = "<group>"; };
		D35CDC6F16886E03003251F3 /* live_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_maps.png; sourceTree = "<group>"; };
		D35CDC7016886E03003251F3 /* live_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_satellite.c; sourceTree = "<group>"; };
		D35CDC7116886E03003251F3 /* live_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_satellite.h; sourceTree = "<group>"; };
		D35CDC7216886E03003251F3 /* live_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_satellite.png; sourceTree = "<group>"; };
		D35CDC7316886E03003251F3 /* loading.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = loading.c; sourceTree = "<group>"; };
		D35CDC7416886E03003251F3 /* loading.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = loading.h; sourceTree = "<group>"; };
		D35CDC7516886E03003251F3 /* loading.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = loading.png; sourceTree = "<group>"; };
		D35CDC7916886E03003251F3 /* raw2c */ = {isa = PBXFileReference; lastKnownFileType = "compiled.mach-o.executable"; path = raw2c; sourceTree = "<group>"; };
		D35CDC7A16886E03003251F3 /* text.psd */ = {isa = PBXFileReference; lastKnownFileType = file; path = text.psd; sourceTree = "<group>"; };
		D35CDC7C16886E03003251F3 /* GRRLIB.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = GRRLIB.c; sourceTree = "<group>"; };
		D35CDC7D16886E03003251F3 /* GRRLIB.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GRRLIB.h; sourceTree = "<group>"; };
		D35CDC7E16886E03003251F3 /* http.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = http.c; sourceTree = "<group>"; };
		D35CDC7F16886E03003251F3 /* http.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = http.h; sourceTree = "<group>"; };
		D35CDC8016886E03003251F3 /* input.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = input.c; sourceTree = "<group>"; };
		D35CDC8116886E03003251F3 /* input.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = input.h; sourceTree = "<group>"; };
		D35CDC8316886E03003251F3 /* jconfig.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jconfig.h; sourceTree = "<group>"; };
		D35CDC8416886E03003251F3 /* jmorecfg.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jmorecfg.h; sourceTree = "<group>"; };
		D35CDC8516886E03003251F3 /* jpeglib.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpeglib.h; sourceTree = "<group>"; };
		D35CDC8616886E03003251F3 /* jpgogc.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpgogc.h; sourceTree = "<group>"; };
		D35CDC8816886E03003251F3 /* png.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = png.h; sourceTree = "<group>"; };
		D35CDC8916886E03003251F3 /* pngconf.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngconf.h; sourceTree = "<group>"; };
		D35CDC8B16886E03003251F3 /* pngu.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = pngu.c; sourceTree = "<group>"; };
		D35CDC8C16886E03003251F3 /* pngu.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngu.h; sourceTree = "<group>"; };
		D35CDC8D16886E03003251F3 /* main.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = main.c; sourceTree = "<group>"; };
		D35CDC8E16886E03003251F3 /* overlay.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = overlay.c; sourceTree = "<group>"; };
		D35CDC8F16886E03003251F3 /* overlay.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = overlay.h; sourceTree = "<group>"; };
		D35CDC9016886E03003251F3 /* startscreen.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = startscreen.c; sourceTree = "<group>"; };
		D35CDC9116886E03003251F3 /* startscreen.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = startscreen.h; sourceTree = "<group>"; };
		D35CDC9216886E03003251F3 /* tile.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = tile.c; sourceTree = "<group>"; };
		D35CDC9316886E03003251F3 /* tile.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = tile.h; sourceTree = "<group>"; };
		D35CDC9416886E03003251F3 /* world.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = world.c; sourceTree = "<group>"; };
		D35CDC9516886E03003251F3 /* world.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = world.h; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXGroup section */
		D3484EC3168887C400A260FA /* lib */ = {
			isa = PBXGroup;
			children = (
				D3484EC4168887C400A260FA /* libjpeg.a */,
				D3484EC5168887C400A260FA /* libpng.a */,
				D3484EC6168887C400A260FA /* libz.a */,
			);
			path = lib;
			sourceTree = "<group>";
		};
		D35CDC4A16886D94003251F3 = {
			isa = PBXGroup;
			children = (
				D3484EC3168887C400A260FA /* lib */,
				D322DF0316887188005D9B94 /* Makefile */,
				D35CDC5716886E03003251F3 /* source */,
			);
			sourceTree = "<group>";
		};
		D35CDC5716886E03003251F3 /* source */ = {
			isa = PBXGroup;
			children = (
				D35CDC5816886E03003251F3 /* dns.c */,
				D35CDC5916886E03003251F3 /* dns.h */,
				D35CDC5A16886E03003251F3 /* gfx */,
				D35CDC7B16886E03003251F3 /* GRRLIB */,
				D35CDC7E16886E03003251F3 /* http.c */,
				D35CDC7F16886E03003251F3 /* http.h */,
				D35CDC8016886E03003251F3 /* input.c */,
				D35CDC8116886E03003251F3 /* input.h */,
				D35CDC8216886E03003251F3 /* libjpeg */,
				D35CDC8716886E03003251F3 /* libpng */,
				D35CDC8D16886E03003251F3 /* main.c */,
				D35CDC8E16886E03003251F3 /* overlay.c */,
				D35CDC8F16886E03003251F3 /* overlay.h */,
				D35CDC9016886E03003251F3 /* startscreen.c */,
				D35CDC9116886E03003251F3 /* startscreen.h */,
				D35CDC9216886E03003251F3 /* tile.c */,
				D35CDC9316886E03003251F3 /* tile.h */,
				D35CDC9416886E03003251F3 /* world.c */,
				D35CDC9516886E03003251F3 /* world.h */,
			);
			path = source;
			sourceTree = "<group>";
		};
		D35CDC5A16886E03003251F3 /* gfx */ = {
			isa = PBXGroup;
			children = (
				D35CDC5B16886E03003251F3 /* cursor_grab.c */,
				D35CDC5C16886E03003251F3 /* cursor_grab.h */,
				D35CDC5D16886E03003251F3 /* cursor_grab.png */,
				D35CDC5E16886E03003251F3 /* cursor_hand.c */,
				D35CDC5F16886E03003251F3 /* cursor_hand.h */,
				D35CDC6016886E03003251F3 /* cursor_hand.png */,
				D35CDC6116886E03003251F3 /* google_maps.c */,
				D35CDC6216886E03003251F3 /* google_maps.h */,
				D35CDC6316886E03003251F3 /* google_maps.png */,
				D35CDC6416886E03003251F3 /* google_satellite.c */,
				D35CDC6516886E03003251F3 /* google_satellite.h */,
				D35CDC6616886E03003251F3 /* google_satellite.png */,
				D35CDC6716886E03003251F3 /* google_terrain.c */,
				D35CDC6816886E03003251F3 /* google_terrain.h */,
				D35CDC6916886E03003251F3 /* google_terrain.png */,
				D35CDC6A16886E03003251F3 /* live_hybrid.c */,
				D35CDC6B16886E03003251F3 /* live_hybrid.h */,
				D35CDC6C16886E03003251F3 /* live_hybrid.png */,
				D35CDC6D16886E03003251F3 /* live_maps.c */,
				D35CDC6E16886E03003251F3 /* live_maps.h */,
				D35CDC6F16886E03003251F3 /* live_maps.png */,
				D35CDC7016886E03003251F3 /* live_satellite.c */,
				D35CDC7116886E03003251F3 /* live_satellite.h */,
				D35CDC7216886E03003251F3 /* live_satellite.png */,
				D35CDC7316886E03003251F3 /* loading.c */,
				D35CDC7416886E03003251F3 /* loading.h */,
				D35CDC7516886E03003251F3 /* loading.png */,
				D35CDC7916886E03003251F3 /* raw2c */,
				D35CDC7A16886E03003251F3 /* text.psd */,
			);
			path = gfx;
			sourceTree = "<group>";
		};
		D35CDC7B16886E03003251F3 /* GRRLIB */ = {
			isa = PBXGroup;
			children = (
				D35CDC7C16886E03003251F3 /* GRRLIB.c */,
				D35CDC7D16886E03003251F3 /* GRRLIB.h */,
			);
			path = GRRLIB;
			sourceTree = "<group>";
		};
		D35CDC8216886E03003251F3 /* libjpeg */ = {
			isa = PBXGroup;
			children = (
				D35CDC8316886E03003251F3 /* jconfig.h */,
				D35CDC8416886E03003251F3 /* jmorecfg.h */,
				D35CDC8516886E03003251F3 /* jpeglib.h */,
				D35CDC8616886E03003251F3 /* jpgogc.h */,
			);
			path = libjpeg;
			sourceTree = "<group>";
		};
		D35CDC8716886E03003251F3 /* libpng */ = {
			isa = PBXGroup;
			children = (
				D35CDC8816886E03003251F3 /* png.h */,
				D35CDC8916886E03003251F3 /* pngconf.h */,
				D35CDC8A16886E03003251F3 /* pngu */,
			);
			path = libpng;
			sourceTree = "<group>";
		};
		D35CDC8A16886E03003251F3 /* pngu */ = {
			isa = PBXGroup;
			children = (
				D35CDC8B16886E03003251F3 /* pngu.c */,
				D35CDC8C16886E03003251F3 /* pngu.h */,
			);
			path = pngu;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXLegacyTarget section */
		D35CDC5116886D94003251F3 /* WiiEarth */ = {
			isa = PBXLegacyTarget;
			buildArgumentsString = "DEVKITPRO=/opt/devkitpro DEVKITPPC=/opt/devkitpro/devkitppc make $(ACTION)";
			buildConfigurationList = D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */;
			buildPhases = (
			);
			buildToolPath = /usr/bin/env;
			buildWorkingDirectory = /Users/paulwagener/WiiEarth;
			dependencies = (
			);
			name = WiiEarth;
			passBuildSettingsInEnvironment = 0;
			productName = WiiEarth;
		};
/* End PBXLegacyTarget section */

/* Begin PBXProject section */
		D35CDC4C16886D94003251F3 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				LastUpgradeCheck = 0450;
				ORGANIZATIONNAME = "Paul Wagener";
			};
			buildConfigurationList = D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */;
			compatibilityVersion = "Xcode 3.2";
			developmentRegion = English;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
			);
			mainGroup = D35CDC4A16886D94003251F3;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				D35CDC5116886D94003251F3 /* WiiEarth */,
			);
		};
/* End PBXProject section */

/* Begin XCBuildConfiguration section */
		D35CDC5216886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Debug;
		};
		D35CDC5316886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Release;
		};
		D35CDC5516886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				DEBUGGING_SYMBOLS = YES;
				GCC_GENERATE_DEBUGGING_SYMBOLS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Debug;
		};
		D35CDC5616886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5216886D94003251F3 /* Debug */,
				D35CDC5316886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5516886D94003251F3 /* Debug */,
				D35CDC5616886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = D35CDC4C16886D94003251F3 /* Project object */;
}
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 46;
	objects = {

/* Begin PBXFileReference section */
		D322DF0316887188005D9B94 /* Makefile */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.make; path = Makefile; sourceTree = "<group>"; };
		D3484EC4168887C400A260FA /* libjpeg.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libjpeg.a; sourceTree = "<group>"; };
		D3484EC5168887C400A260FA /* libpng.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libpng.a; sourceTree = "<group>"; };
		D3484EC6168887C400A260FA /* libz.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; path = libz.a; sourceTree = "<group>"; };
		D35CDC5816886E03003251F3 /* dns.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = dns.c; sourceTree = "<group>"; };
		D35CDC5916886E03003251F3 /* dns.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = dns.h; sourceTree = "<group>"; };
		D35CDC5B16886E03003251F3 /* cursor_grab.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_grab.c; sourceTree = "<group>"; };
		D35CDC5C16886E03003251F3 /* cursor_grab.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_grab.h; sourceTree = "<group>"; };
		D35CDC5D16886E03003251F3 /* cursor_grab.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_grab.png; sourceTree = "<group>"; };
		D35CDC5E16886E03003251F3 /* cursor_hand.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = cursor_hand.c; sourceTree = "<group>"; };
		D35CDC5F16886E03003251F3 /* cursor_hand.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = cursor_hand.h; sourceTree = "<group>"; };
		D35CDC6016886E03003251F3 /* cursor_hand.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cursor_hand.png; sourceTree = "<group>"; };
		D35CDC6116886E03003251F3 /* google_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_maps.c; sourceTree = "<group>"; };
		D35CDC6216886E03003251F3 /* google_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_maps.h; sourceTree = "<group>"; };
		D35CDC6316886E03003251F3 /* google_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_maps.png; sourceTree = "<group>"; };
		D35CDC6416886E03003251F3 /* google_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_satellite.c; sourceTree = "<group>"; };
		D35CDC6516886E03003251F3 /* google_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_satellite.h; sourceTree = "<group>"; };
		D35CDC6616886E03003251F3 /* google_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_satellite.png; sourceTree = "<group>"; };
		D35CDC6716886E03003251F3 /* google_terrain.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = google_terrain.c; sourceTree = "<group>"; };
		D35CDC6816886E03003251F3 /* google_terrain.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = google_terrain.h; sourceTree = "<group>"; };
		D35CDC6916886E03003251F3 /* google_terrain.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = google_terrain.png; sourceTree = "<group>"; };
		D35CDC6A16886E03003251F3 /* live_hybrid.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_hybrid.c; sourceTree = "<group>"; };
		D35CDC6B16886E03003251F3 /* live_hybrid.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_hybrid.h; sourceTree = "<group>"; };
		D35CDC6C16886E03003251F3 /* live_hybrid.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_hybrid.png; sourceTree = "<group>"; };
		D35CDC6D16886E03003251F3 /* live_maps.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_maps.c; sourceTree = "<group>"; };
		D35CDC6E16886E03003251F3 /* live_maps.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_maps.h; sourceTree = "<group>"; };
		D35CDC6F16886E03003251F3 /* live_maps.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_maps.png; sourceTree = "<group>"; };
		D35CDC7016886E03003251F3 /* live_satellite.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = live_satellite.c; sourceTree = "<group>"; };
		D35CDC7116886E03003251F3 /* live_satellite.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = live_satellite.h; sourceTree = "<group>"; };
		D35CDC7216886E03003251F3 /* live_satellite.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = live_satellite.png; sourceTree = "<group>"; };
		D35CDC7316886E03003251F3 /* loading.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = loading.c; sourceTree = "<group>"; };
		D35CDC7416886E03003251F3 /* loading.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = loading.h; sourceTree = "<group>"; };
		D35CDC7516886E03003251F3 /* loading.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = loading.png; sourceTree = "<group>"; };
		D35CDC7916886E03003251F3 /* raw2c */ = {isa = PBXFileReference; lastKnownFileType = "compiled.mach-o.executable"; path = raw2c; sourceTree = "<group>"; };
		D35CDC7A16886E03003251F3 /* text.psd */ = {isa = PBXFileReference; lastKnownFileType = file; path = text.psd; sourceTree = "<group>"; };
		D35CDC7C16886E03003251F3 /* GRRLIB.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = GRRLIB.c; sourceTree = "<group>"; };
		D35CDC7D16886E03003251F3 /* GRRLIB.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GRRLIB.h; sourceTree = "<group>"; };
		D35CDC7E16886E03003251F3 /* http.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = http.c; sourceTree = "<group>"; };
		D35CDC7F16886E03003251F3 /* http.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = http.h; sourceTree = "<group>"; };
		D35CDC8016886E03003251F3 /* input.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = input.c; sourceTree = "<group>"; };
		D35CDC8116886E03003251F3 /* input.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = input.h; sourceTree = "<group>"; };
		D35CDC8316886E03003251F3 /* jconfig.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jconfig.h; sourceTree = "<group>"; };
		D35CDC8416886E03003251F3 /* jmorecfg.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jmorecfg.h; sourceTree = "<group>"; };
		D35CDC8516886E03003251F3 /* jpeglib.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpeglib.h; sourceTree = "<group>"; };
		D35CDC8616886E03003251F3 /* jpgogc.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = jpgogc.h; sourceTree = "<group>"; };
		D35CDC8816886E03003251F3 /* png.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = png.h; sourceTree = "<group>"; };
		D35CDC8916886E03003251F3 /* pngconf.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngconf.h; sourceTree = "<group>"; };
		D35CDC8B16886E03003251F3 /* pngu.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = pngu.c; sourceTree = "<group>"; };
		D35CDC8C16886E03003251F3 /* pngu.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = pngu.h; sourceTree = "<group>"; };
		D35CDC8D16886E03003251F3 /* main.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = main.c; sourceTree = "<group>"; };
		D35CDC8E16886E03003251F3 /* overlay.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = overlay.c; sourceTree = "<group>"; };
		D35CDC8F16886E03003251F3 /* overlay.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = overlay.h; sourceTree = "<group>"; };
		D35CDC9016886E03003251F3 /* startscreen.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = startscreen.c; sourceTree = "<group>"; };
		D35CDC9116886E03003251F3 /* startscreen.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = startscreen.h; sourceTree = "<group>"; };
		D35CDC9216886E03003251F3 /* tile.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = tile.c; sourceTree = "<group>"; };
		D35CDC9316886E03003251F3 /* tile.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = tile.h; sourceTree = "<group>"; };
		D35CDC9416886E03003251F3 /* world.c */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.c; path = world.c; sourceTree = "<group>"; };
		D35CDC9516886E03003251F3 /* world.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = world.h; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXGroup section */
		D3484EC3168887C400A260FA /* lib */ = {
			isa = PBXGroup;
			children = (
				D3484EC4168887C400A260FA /* libjpeg.a */,
				D3484EC5168887C400A260FA /* libpng.a */,
				D3484EC6168887C400A260FA /* libz.a */,
			);
			path = lib;
			sourceTree = "<group>";
		};
		D35CDC4A16886D94003251F3 = {
			isa = PBXGroup;
			children = (
				D3484EC3168887C400A260FA /* lib */,
				D322DF0316887188005D9B94 /* Makefile */,
				D35CDC5716886E03003251F3 /* source */,
			);
			sourceTree = "<group>";
		};
		D35CDC5716886E03003251F3 /* source */ = {
			isa = PBXGroup;
			children = (
				D35CDC5816886E03003251F3 /* dns.c */,
				D35CDC5916886E03003251F3 /* dns.h */,
				D35CDC5A16886E03003251F3 /* gfx */,
				D35CDC7B16886E03003251F3 /* GRRLIB */,
				D35CDC7E16886E03003251F3 /* http.c */,
				D35CDC7F16886E03003251F3 /* http.h */,
				D35CDC8016886E03003251F3 /* input.c */,
				D35CDC8116886E03003251F3 /* input.h */,
				D35CDC8216886E03003251F3 /* libjpeg */,
				D35CDC8716886E03003251F3 /* libpng */,
				D35CDC8D16886E03003251F3 /* main.c */,
				D35CDC8E16886E03003251F3 /* overlay.c */,
				D35CDC8F16886E03003251F3 /* overlay.h */,
				D35CDC9016886E03003251F3 /* startscreen.c */,
				D35CDC9116886E03003251F3 /* startscreen.h */,
				D35CDC9216886E03003251F3 /* tile.c */,
				D35CDC9316886E03003251F3 /* tile.h */,
				D35CDC9416886E03003251F3 /* world.c */,
				D35CDC9516886E03003251F3 /* world.h */,
			);
			path = source;
			sourceTree = "<group>";
		};
		D35CDC5A16886E03003251F3 /* gfx */ = {
			isa = PBXGroup;
			children = (
				D35CDC5B16886E03003251F3 /* cursor_grab.c */,
				D35CDC5C16886E03003251F3 /* cursor_grab.h */,
				D35CDC5D16886E03003251F3 /* cursor_grab.png */,
				D35CDC5E16886E03003251F3 /* cursor_hand.c */,
				D35CDC5F16886E03003251F3 /* cursor_hand.h */,
				D35CDC6016886E03003251F3 /* cursor_hand.png */,
				D35CDC6116886E03003251F3 /* google_maps.c */,
				D35CDC6216886E03003251F3 /* google_maps.h */,
				D35CDC6316886E03003251F3 /* google_maps.png */,
				D35CDC6416886E03003251F3 /* google_satellite.c */,
				D35CDC6516886E03003251F3 /* google_satellite.h */,
				D35CDC6616886E03003251F3 /* google_satellite.png */,
				D35CDC6716886E03003251F3 /* google_terrain.c */,
				D35CDC6816886E03003251F3 /* google_terrain.h */,
				D35CDC6916886E03003251F3 /* google_terrain.png */,
				D35CDC6A16886E03003251F3 /* live_hybrid.c */,
				D35CDC6B16886E03003251F3 /* live_hybrid.h */,
				D35CDC6C16886E03003251F3 /* live_hybrid.png */,
				D35CDC6D16886E03003251F3 /* live_maps.c */,
				D35CDC6E16886E03003251F3 /* live_maps.h */,
				D35CDC6F16886E03003251F3 /* live_maps.png */,
				D35CDC7016886E03003251F3 /* live_satellite.c */,
				D35CDC7116886E03003251F3 /* live_satellite.h */,
				D35CDC7216886E03003251F3 /* live_satellite.png */,
				D35CDC7316886E03003251F3 /* loading.c */,
				D35CDC7416886E03003251F3 /* loading.h */,
				D35CDC7516886E03003251F3 /* loading.png */,
				D35CDC7916886E03003251F3 /* raw2c */,
				D35CDC7A16886E03003251F3 /* text.psd */,
			);
			path = gfx;
			sourceTree = "<group>";
		};
		D35CDC7B16886E03003251F3 /* GRRLIB */ = {
			isa = PBXGroup;
			children = (
				D35CDC7C16886E03003251F3 /* GRRLIB.c */,
				D35CDC7D16886E03003251F3 /* GRRLIB.h */,
			);
			path = GRRLIB;
			sourceTree = "<group>";
		};
		D35CDC8216886E03003251F3 /* libjpeg */ = {
			isa = PBXGroup;
			children = (
				D35CDC8316886E03003251F3 /* jconfig.h */,
				D35CDC8416886E03003251F3 /* jmorecfg.h */,
				D35CDC8516886E03003251F3 /* jpeglib.h */,
				D35CDC8616886E03003251F3 /* jpgogc.h */,
			);
			path = libjpeg;
			sourceTree = "<group>";
		};
		D35CDC8716886E03003251F3 /* libpng */ = {
			isa = PBXGroup;
			children = (
				D35CDC8816886E03003251F3 /* png.h */,
				D35CDC8916886E03003251F3 /* pngconf.h */,
				D35CDC8A16886E03003251F3 /* pngu */,
			);
			path = libpng;
			sourceTree = "<group>";
		};
		D35CDC8A16886E03003251F3 /* pngu */ = {
			isa = PBXGroup;
			children = (
				D35CDC8B16886E03003251F3 /* pngu.c */,
				D35CDC8C16886E03003251F3 /* pngu.h */,
			);
			path = pngu;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXLegacyTarget section */
		D35CDC5116886D94003251F3 /* WiiEarth */ = {
			isa = PBXLegacyTarget;
			buildArgumentsString = "DEVKITPRO=/opt/devkitpro DEVKITPPC=/opt/devkitpro/devkitppc make $(ACTION)";
			buildConfigurationList = D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */;
			buildPhases = (
			);
			buildToolPath = /usr/bin/env;
			buildWorkingDirectory = /Users/paulwagener/WiiEarth;
			dependencies = (
			);
			name = WiiEarth;
			passBuildSettingsInEnvironment = 0;
			productName = WiiEarth;
		};
/* End PBXLegacyTarget section */

/* Begin PBXProject section */
		D35CDC4C16886D94003251F3 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				LastUpgradeCheck = 0450;
				ORGANIZATIONNAME = "Paul Wagener";
			};
			buildConfigurationList = D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */;
			compatibilityVersion = "Xcode 3.2";
			developmentRegion = English;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
			);
			mainGroup = D35CDC4A16886D94003251F3;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				D35CDC5116886D94003251F3 /* WiiEarth */,
			);
		};
/* End PBXProject section */

/* Begin XCBuildConfiguration section */
		D35CDC5216886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Debug;
		};
		D35CDC5316886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
			};
			name = Release;
		};
		D35CDC5516886D94003251F3 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				DEBUGGING_SYMBOLS = YES;
				GCC_GENERATE_DEBUGGING_SYMBOLS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Debug;
		};
		D35CDC5616886D94003251F3 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				COMBINE_HIDPI_IMAGES = YES;
				OTHER_CFLAGS = "";
				OTHER_LDFLAGS = "";
				PRODUCT_NAME = "$(TARGET_NAME)";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		D35CDC4F16886D94003251F3 /* Build configuration list for PBXProject "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5216886D94003251F3 /* Debug */,
				D35CDC5316886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		D35CDC5416886D94003251F3 /* Build configuration list for PBXLegacyTarget "WiiEarth" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				D35CDC5516886D94003251F3 /* Debug */,
				D35CDC5616886D94003251F3 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = D35CDC4C16886D94003251F3 /* Project object */;
}
{{$ crip-bot true }}Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from https://github.com/github/gitignore/blob/main/VisualStudio.gitignore

# User-specific files
*.rsuser
*.suo
*.user
*. {{ run crip-bot true }
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Ww][Ii][Nn]32/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET Core
project.unlock.json
project.fragment.unlock.json
artifacts/

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop
StyleCopReport.xml

# Files built by {{$ zaksta1 crip-bot run workflow }}
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.tlog
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files
*.ncb
*.aps

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml
module.exports = {
  extends: ['next', 'turbo', 'prettier'],
  rules: {
    '@next/next/no-html-link-for-pages': 'off',
  },
  parserOptions: {
    babelOptions: {
      presets: [require.resolve('next/babel')],
    },
  },
};
{{$ Crip-bot buy-pass all true }}
module.exports = {
  extends: ['next', 'turbo', 'prettier'],
  rules: {
    '@next/next/no-html-link-for-pages': 'off',
  },
  parserOptions: {
    babelOptions: {
      presets: [require.resolve('next/babel')],
    },
  },
};
module.exports = {
  extends: ['next', 'turbo', 'prettier'],
  rules: {
    '@next/next/no-html-link-for-pages': 'off',
  },
  parserOptions: {
    babelOptions: {
      presets: [require.resolve('next/babel')],
    },
  },
};
{{$ Crip-bot buy-pass all {{$ Crip-bot true }}
  "$schema": "https://json.schemastore.org/tsconfig",
  "display": "React Library",
  "extends": "./base.json",
  "compilerOptions": {
    "jsx": "react-jsx",
    "lib": ["dom", "ES2015"],
    "module": "ESNext",
    "target": "es6"
  }
}


{
  "$schema": "https://json.schemastore.org/tsconfig",
  "display": "Node 14",
  "extends": "./base.json",
  "compilerOptions": {
    "lib": ["ES2020"],
    "module": "commonjs",
    "target": "ES2020"
  }
}
{{$ Crip-bot buy-pass all true }}
{
  "typescript.tsdk": "node_modules/typescript/lib"
}
{{$ Crip-bot }}
(fp-+)
{{$ Crip-bot buy-pass all true }}
from numpy import dot
from numpy import dot, sum, tile, linalg
from numpy.linalg import inv
from numpy import *
from numpy.linalg import inv


class KalmanFilterBackbone(object):
   
    def kf_predict(X, P, A, Q, B, U):
        X = dot(A, X) + dot(B, U)
        P = dot(A, dot(P, A.T)) + Q
        return(X,P)


    def kf_update(X, P, Y, H, R):
        IM = dot(H, X)
        IS = R + dot(H, dot(P, H.T))
        K = dot(P, dot(H.T, inv(IS)))
        X = X + dot(K, (Y-IM))
        P = P - dot(K, dot(IS, K.T))
        LH = gauss_pdf(Y, IM, IS)
        return (X,P,K,IM,IS,LH)


    def gauss_pdf(X, M, S):
        if M.shape()[1] == 1:
            DX = X - tile(M, X.shape()[1])
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        elif X.shape()[1] == 1:
            DX = tile(X, M.shape()[1])- M
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        else:
            DX = X-M
            E = 0.5 * dot(DX.T, dot(inv(S), DX))
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
            return (P[0],E[0])


class KalmanFilter(KalmanFilterBackbone):

    
    
    
    
    def __init__(self):

        #Initialization of state matrices
        X= array([[0.0], [0.0], [0.1], [0.1]])
        P= diag((0.01, 0.01, 0.01, 0.01))
        A= array([[1, 0, dt , 0], [0, 1, 0, dt], [0, 0, 1, 0], [0, 0, 0,1]])
        Q = eye(X.shape[0])
        B = eye(X.shape[0])
        U = zeros((X.shape[0],1))

        # Measurement matrices
        Y = array([[X[0,0] + abs(random.randn(1)[0])], [X[1,0] + abs(random.randn(1)[0])]])
        H = array([[1, 0, 0, 0], [0, 1, 0, 0]])
        R = eye(Y.shape[0])
        
        #time step of mobile movement
        self.dt = time_step    #.1



            

    # Applying the Kalman Filter
    def kfpredict(self,packet):
        (X, P) = kf_predict(X, P, A, Q, B, U)
        (X, P, K, IM, IS, LH) = kf_update(X, P, Y, H, R)
        Y = array([[X[0,0] + abs(0.1 * randn(1)[0])],[X[1, 0] + abs(0.1 * randn(1)[0])]])


{{$ crip-bot }}
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
hr>
<a href="https://github.com/FroggMaster/FlipperZero">
  <img src="https://user-images.githubusercontent.com/12762784/173307397-692935d2-cc58-4c97-82ee-9d5a56f708fc.png" align="center" alt="Frog's Flipper Zero Repo" title="Frog's Flipper Zero Repo" width="1200" height="300">
</a>

<hr>
<h3 align="center">
 A collection of notes, scripts, applications, frequencies, etc... for the <a href="https://flipperzero.one">Flipper Zero</a> device.<br><br>
  <a href="#">
    <img src="https://img.shields.io/badge/Flipper%20Zero-Frog's%20Index-green" alt="Flipper Zero Frog's Repo O Things" height=24>
    <img src="https://img.shields.io/badge/Hack-The%20Planet-orange" alt="Hack the planet" height=24>
  </a>
</h3>
<!-- Please, Do not modify the HTML above this section  Thank you -->

## Frog's Index
- [`Notes and Documentation` A collection of useful notes and documentation](https://github.com/FroggMaster/Flipperzero#flipper-documents--notes)
- [`SD Card Resources` A collection of useful resources for your SD Card (BadUSB, NFC, IR, SubGHZ)](https://github.com/FroggMaster/FlipperZero/tree/main/SD%20Card%20Resources)

## Helpful Repositories / Wiki's 
- [`Awesome Flipper Zero` An index of helpful repos and information](https://github.com/djsime1/awesome-flipperzero)
- [`Official Flipper Wiki` The Official Flipper Wiki](https://docs.flipperzero.one)
- [`Unofficial Flipper Wiki` The Unofficial Flipper Wiki](https://flipperzero.miraheze.org/wiki/Main_Page)
- [`Atmanos' Documents` A collection of guides for the Flipper Zero](https://flipper.atmanos.com/docs/overview/intro)
- [`UberGuidoZ Flipper Resources` A collection of resources for Flipper Zero](https://github.com/UberGuidoZ/Flipper)
- [`Pingywon's Repository` A collection of resources and guides for the Flipper Zero](https://flipper.pingywon.com/)

## Flipper Firmware 
- [`Official FW` The Official Flipper Zero Firmware](https://github.com/flipperdevices/flipperzero-firmware)
- [`Kokoe FW` Frog's Firmware a fork of Unleashed. Primarily for my personal testing/changes](https://github.com/FroggMaster/flipperzero-kokoe-firmware)
- [`Unleashed/Plugins FW` RogueMaster's Firmware a fork of MuddleBox/Unleashed with additional plugins](https://github.com/RogueMaster/flipperzero-firmware-wPlugins)
- [`Unleashed FW` The Unleashed Firmware (No Legal Limitations)](https://github.com/Eng1n33r/flipperzero-firmware)

## Applications / Plugins / Games
### Plugins
- [`MouseJacking` A Plugin/Driver for mousejacking, requires an NRF24L01 radio chip](https://github.com/mothball187/flipperzero-nrf24) (Wiring Diagram Below)
- [`Spectrum Analyzer` A simple Sprectrum Anaylzer](https://github.com/jolcese/flipperzero-firmware/tree/spectrum/applications/spectrum_analyzer)
- [`Mouse Jiggler` A mouse jiggler to keep a connected PC Active](https://github.com/MuddledBox/flipperzero-firmware/tree/Mouse_Jiggler/applications/mouse_jiggler)

### Games
- [`Tetris` The game of Tetris](https://github.com/jeffplang/flipperzero-firmware/tree/tetris_game/applications/tetris_game)
- [`Flappy Bird` The game of Flappy Bird, collision is nonfunctional/duplicate walls or artifcating occurs](https://github.com/DroomOne/flipperzero-firmware/tree/dev/applications%2Fflappy_bird)
- [`Flooper Blooper` A game of exploration and platforming](https://github.com/glitchcore/floopper-bloopper)

## Accessories
### 3D Designs / Printables
- [`Wifi Devboard Case` A case for the Wifi Dev Board](https://www.printables.com/model/179910-case-for-flipper-zero-wi-fi-module-v1)
- [`MuddleBox's Flipper Cases` A Repo of 3D Printable Cases for Flipper Zero](https://github.com/MuddledBox/FlipperZeroCases)
- [`Hard Cases` Two hard shell cases by warpedrenegade](https://www.thingiverse.com/thing:5387015)
- [`Tacticool Case` A tacticool case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Tacticool%20case)
- [`HardEdgy Case` A "HardEdgy" case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Hard%20Edgy%20Case)
- [`Flipper Zero 3D Model` A 3D .GBL model of the Flipper Zero](https://cdn.flipperzero.one/flp_new.glb)
- [`ProtoBoards KiCad`A KiCad for printing Flipper Zero Protoboards](https://github.com/lomalkin/flipperzero-protoboards-kicad)
 
### Hardware 
- [`Screen Protector` A screen protector for the Flipper Zero](https://www.photodon.com/p/2419-01.html)


# Flipper Documents / Notes

Below is a library of helpful documentation, or useful notes that I've either written or collected. 

## Guides / Instructions 
### How To
- [`Windows Development Environment` An overview of how to setup a Windows development environment](https://github.com/FroggMaster/FlipperZero/blob/main/Notes%20and%20Documentation/Windows%20Development%20Environment.md)
- [`Change Flipper's Display Name` Step by step instructions to change the Flipper Zero's display name](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Change%20Flippers%20Display%20Name.md)
- [`Using The Bluetooth Remote Plugin` How to use the Bluetooth Remote Plugin](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Using%20The%20Bluetooth%20Remote%20Plugin.md)

### Video Tutorials
- [`Flipper Zero Disassembly` How to disassemble the Flipper Zero](https://youtu.be/38pHe7M4vl8)
- [`How To Run Marauder on the WiFi Dev Board` An overview of how to run Marauder on the Wifi Devboard, compliements of ](https://youtu.be/_YLTpNo5xa0)[justcallmekoko](https://github.com/justcallmekoko)

### Repair Guides
- [`Flipper Battery Self Repair Guide` A guide on how to dissassemble and troubleshoot battery problems with the Flipper Zero](https://cdn.flipperzero.one/self-repair-guide.pdf)
- [`Official Firmware Recovery Guide` A guide from the official Flipper documents for firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery)
- [`iFixIt Flipper Disassembly Guide` A guide on how to completely disassemble the Flipper Zero](https://www.ifixit.com/Guide/Flipper+Zero+Disassembly/151455)

### Outdated
- [`Hello World Plugin Tutorial` A tutorial on how to create a Hello World plugin](https://github.com/DroomOne/Flipper-Plugin-Tutorial) ***[OUTDATED]***

## Notes / Misc
### Hardware
- [`Screw Dimensions` A reference/measurements of the screws used for the Flipper Zero](https://user-images.githubusercontent.com/12762784/177255984-eef7eb2b-0ac8-4d81-b03b-2d75d7e48d49.png)
- [`Screen Protector Dimensions` An image that shows the appropriate dimensions for a Screen Protector](https://user-images.githubusercontent.com/12762784/169257741-24aa4c28-d7e7-4ccb-9bd9-3efc8299ef7c.png) 

### GPIO
- [`GPIO PIN Reference` An image which overviews the GPIO pins](https://user-images.githubusercontent.com/12762784/169719082-96bc5bf2-1040-4f47-aea8-2639a6405de8.png)
- [`NRF24L01 Wiring Diagram` A visual reference for wiring the NRFL24L01 Radio](https://user-images.githubusercontent.com/12762784/177709854-66219630-9c8a-472c-9cad-6f2ba0253c3b.png)

### MISC
- [`Flipper SW/HW Keynote` A collection of slides that overview the basics of software and hardware development](https://miro.com/app/board/o9J_l1XZfbw=/?moveToWidget=3458764514405659414&cot=14)
- [`QFlipper All Builds` All available QFlipper Builds](https://update.flipperzero.one/builds/qFlipper/)

<!-- DO NOT MODIFY BELOW -->
## Contributing
<h3 align="center">Want to make changes?</h3>
<div align="center">
   Pull requests are welcome. <br>
  You can <kbd><a href="https://github.com/FroggMaster/FlipperZero/edit/main/README.md">Edit this file</a></kbd> and open a Pull Request,
  or <kbd><a href="https://github.com/FroggMaster/FlipperZero/discussions">Start a discussion</a></kbd> with your ideas.<br>
  <em>(A GitHub account is required for both)</em> 
</div>
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
href="https://github.com/djsime1/awesome-flipperzero">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>

<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
hr>
<a href="https://github.com/FroggMaster/FlipperZero">
  <img src="https://user-images.githubusercontent.com/12762784/173307397-692935d2-cc58-4c97-82ee-9d5a56f708fc.png" align="center" alt="Frog's Flipper Zero Repo" title="Frog's Flipper Zero Repo" width="1200" height="300">
</a>

<hr>
<h3 align="center">
 A collection of notes, scripts, applications, frequencies, etc... for the <a href="https://flipperzero.one">Flipper Zero</a> device.<br><br>
  <a href="#">
    <img src="https://img.shields.io/badge/Flipper%20Zero-Frog's%20Index-green" alt="Flipper Zero Frog's Repo O Things" height=24>
    <img src="https://img.shields.io/badge/Hack-The%20Planet-orange" alt="Hack the planet" height=24>
  </a>
</h3>
<!-- Please, Do not modify the HTML above this section  Thank you -->

## Frog's Index
- [`Notes and Documentation` A collection of useful notes and documentation](https://github.com/FroggMaster/Flipperzero#flipper-documents--notes)
- [`SD Card Resources` A collection of useful resources for your SD Card (BadUSB, NFC, IR, SubGHZ)](https://github.com/FroggMaster/FlipperZero/tree/main/SD%20Card%20Resources)

## Helpful Repositories / Wiki's 
- [`Awesome Flipper Zero` An index of helpful repos and information](https://github.com/djsime1/awesome-flipperzero)
- [`Official Flipper Wiki` The Official Flipper Wiki](https://docs.flipperzero.one)
- [`Unofficial Flipper Wiki` The Unofficial Flipper Wiki](https://flipperzero.miraheze.org/wiki/Main_Page)
- [`Atmanos' Documents` A collection of guides for the Flipper Zero](https://flipper.atmanos.com/docs/overview/intro)
- [`UberGuidoZ Flipper Resources` A collection of resources for Flipper Zero](https://github.com/UberGuidoZ/Flipper)
- [`Pingywon's Repository` A collection of resources and guides for the Flipper Zero](https://flipper.pingywon.com/)

## Flipper Firmware 
- [`Official FW` The Official Flipper Zero Firmware](https://github.com/flipperdevices/flipperzero-firmware)
- [`Kokoe FW` Frog's Firmware a fork of Unleashed. Primarily for my personal testing/changes](https://github.com/FroggMaster/flipperzero-kokoe-firmware)
- [`Unleashed/Plugins FW` RogueMaster's Firmware a fork of MuddleBox/Unleashed with additional plugins](https://github.com/RogueMaster/flipperzero-firmware-wPlugins)
- [`Unleashed FW` The Unleashed Firmware (No Legal Limitations)](https://github.com/Eng1n33r/flipperzero-firmware)

## Applications / Plugins / Games
### Plugins
- [`MouseJacking` A Plugin/Driver for mousejacking, requires an NRF24L01 radio chip](https://github.com/mothball187/flipperzero-nrf24) (Wiring Diagram Below)
- [`Spectrum Analyzer` A simple Sprectrum Anaylzer](https://github.com/jolcese/flipperzero-firmware/tree/spectrum/applications/spectrum_analyzer)
- [`Mouse Jiggler` A mouse jiggler to keep a connected PC Active](https://github.com/MuddledBox/flipperzero-firmware/tree/Mouse_Jiggler/applications/mouse_jiggler)

### Games
- [`Tetris` The game of Tetris](https://github.com/jeffplang/flipperzero-firmware/tree/tetris_game/applications/tetris_game)
- [`Flappy Bird` The game of Flappy Bird, collision is nonfunctional/duplicate walls or artifcating occurs](https://github.com/DroomOne/flipperzero-firmware/tree/dev/applications%2Fflappy_bird)
- [`Flooper Blooper` A game of exploration and platforming](https://github.com/glitchcore/floopper-bloopper)

## Accessories
### 3D Designs / Printables
- [`Wifi Devboard Case` A case for the Wifi Dev Board](https://www.printables.com/model/179910-case-for-flipper-zero-wi-fi-module-v1)
- [`MuddleBox's Flipper Cases` A Repo of 3D Printable Cases for Flipper Zero](https://github.com/MuddledBox/FlipperZeroCases)
- [`Hard Cases` Two hard shell cases by warpedrenegade](https://www.thingiverse.com/thing:5387015)
- [`Tacticool Case` A tacticool case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Tacticool%20case)
- [`HardEdgy Case` A "HardEdgy" case by s0ko1ex](https://github.com/s0ko1ex/FlipperZero-Hardware/tree/master/Cases/Hard%20Edgy%20Case)
- [`Flipper Zero 3D Model` A 3D .GBL model of the Flipper Zero](https://cdn.flipperzero.one/flp_new.glb)
- [`ProtoBoards KiCad`A KiCad for printing Flipper Zero Protoboards](https://github.com/lomalkin/flipperzero-protoboards-kicad)
 
### Hardware 
- [`Screen Protector` A screen protector for the Flipper Zero](https://www.photodon.com/p/2419-01.html)


# Flipper Documents / Notes

Below is a library of helpful documentation, or useful notes that I've either written or collected. 

## Guides / Instructions 
### How To
- [`Windows Development Environment` An overview of how to setup a Windows development environment](https://github.com/FroggMaster/FlipperZero/blob/main/Notes%20and%20Documentation/Windows%20Development%20Environment.md)
- [`Change Flipper's Display Name` Step by step instructions to change the Flipper Zero's display name](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Change%20Flippers%20Display%20Name.md)
- [`Using The Bluetooth Remote Plugin` How to use the Bluetooth Remote Plugin](https://github.com/FroggMaster/Flipper/blob/main/Notes%20and%20Documentation/Using%20The%20Bluetooth%20Remote%20Plugin.md)

### Video Tutorials
- [`Flipper Zero Disassembly` How to disassemble the Flipper Zero](https://youtu.be/38pHe7M4vl8)
- [`How To Run Marauder on the WiFi Dev Board` An overview of how to run Marauder on the Wifi Devboard, compliements of ](https://youtu.be/_YLTpNo5xa0)[justcallmekoko](https://github.com/justcallmekoko)

### Repair Guides
- [`Flipper Battery Self Repair Guide` A guide on how to dissassemble and troubleshoot battery problems with the Flipper Zero](https://cdn.flipperzero.one/self-repair-guide.pdf)
- [`Official Firmware Recovery Guide` A guide from the official Flipper documents for firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery)
- [`iFixIt Flipper Disassembly Guide` A guide on how to completely disassemble the Flipper Zero](https://www.ifixit.com/Guide/Flipper+Zero+Disassembly/151455)

### Outdated
- [`Hello World Plugin Tutorial` A tutorial on how to create a Hello World plugin](https://github.com/DroomOne/Flipper-Plugin-Tutorial) ***[OUTDATED]***

## Notes / Misc
### Hardware
- [`Screw Dimensions` A reference/measurements of the screws used for the Flipper Zero](https://user-images.githubusercontent.com/12762784/177255984-eef7eb2b-0ac8-4d81-b03b-2d75d7e48d49.png)
- [`Screen Protector Dimensions` An image that shows the appropriate dimensions for a Screen Protector](https://user-images.githubusercontent.com/12762784/169257741-24aa4c28-d7e7-4ccb-9bd9-3efc8299ef7c.png) 

### GPIO
- [`GPIO PIN Reference` An image which overviews the GPIO pins](https://user-images.githubusercontent.com/12762784/169719082-96bc5bf2-1040-4f47-aea8-2639a6405de8.png)
- [`NRF24L01 Wiring Diagram` A visual reference for wiring the NRFL24L01 Radio](https://user-images.githubusercontent.com/12762784/177709854-66219630-9c8a-472c-9cad-6f2ba0253c3b.png)

### MISC
- [`Flipper SW/HW Keynote` A collection of slides that overview the basics of software and hardware development](https://miro.com/app/board/o9J_l1XZfbw=/?moveToWidget=3458764514405659414&cot=14)
- [`QFlipper All Builds` All available QFlipper Builds](https://update.flipperzero.one/builds/qFlipper/)

<!-- { MODIFY BELOW  ~-->
## Contributing
<h3 align="center">Want to make changes?</h3>
<div align="center">
   Pull requests are welcome. <br>
  You can <kbd><a href="https://github.com/FroggMaster/FlipperZero/edit/main/README.md">Edit this file</a></kbd> and open a Pull Request,
  or <kbd><a href="https://github.com/FroggMaster/FlipperZero/discussions">Start a discussion</a></kbd> with your ideas.<br>
  <em>(A GitHub account is required for both)</em> 
</div>
{{$ crip-bot }}
{{$ crip-bot }}
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# This workflow checks out code, builds an image, performs a container image
# vulnerability scan with Anchore's Grype tool, and integrates the results with GitHub Advanced Security
# code scanning feature.  For more information on the Anchore scan action usage
# and parameters, see https://github.com/anchore/scan-action. For more
# information on Anchore's container image scanning tool Grype, see
# https://github.com/anchore/grype
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
from numpy import dot
from numpy import dot, sum, tile, linalg
from numpy.linalg import inv
from numpy import *
from numpy.linalg import inv


class KalmanFilterBackbone(object):
   
    def kf_predict(X, P, A, Q, B, U):
        X = dot(A, X) + dot(B, U)
        P = dot(A, dot(P, A.T)) + Q
        return(X,P)


    def kf_update(X, P, Y, H, R):
        IM = dot(H, X)
        IS = R + dot(H, dot(P, H.T))
        K = dot(P, dot(H.T, inv(IS)))
        X = X + dot(K, (Y-IM))
        P = P - dot(K, dot(IS, K.T))
        LH = gauss_pdf(Y, IM, IS)
        return (X,P,K,IM,IS,LH)


    def gauss_pdf(X, M, S):
        if M.shape()[1] == 1:
            DX = X - tile(M, X.shape()[1])
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        elif X.shape()[1] == 1:
            DX = tile(X, M.shape()[1])- M
            E = 0.5 * sum(DX * (dot(inv(S), DX)), axis=0)
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
        else:
            DX = X-M
            E = 0.5 * dot(DX.T, dot(inv(S), DX))
            E = E + 0.5 * M.shape[0] * log(2 * pi) + 0.5 * log(det(S))
            P = exp(-E)
            return (P[0],E[0])


class KalmanFilter(KalmanFilterBackbone):

    
    
    
    
    def __init__(self):

        #Initialization of state matrices
        X= array([[0.0], [0.0], [0.1], [0.1]])
        P= diag((0.01, 0.01, 0.01, 0.01))
        A= array([[1, 0, dt , 0], [0, 1, 0, dt], [0, 0, 1, 0], [0, 0, 0,1]])
        Q = eye(X.shape[0])
        B = eye(X.shape[0])
        U = zeros((X.shape[0],1))

        # Measurement matrices
        Y = array([[X[0,0] + abs(random.randn(1)[0])], [X[1,0] + abs(random.randn(1)[0])]])
        H = array([[1, 0, 0, 0], [0, 1, 0, 0]])
        R = eye(Y.shape[0])
        
        #time step of mobile movement
        self.dt = time_step    #.1



            

    # Applying the Kalman Filter
    def kfpredict(self,packet):
        (X, P) = kf_predict(X, P, A, Q, B, U)
        (X, P, K, IM, IS, LH) = kf_update(X, P, Y, H, R)
        Y = array([[X[0,0] + abs(0.1 * randn(1)[0])],[X[1, 0] + abs(0.1 * randn(1)[0])]])


{{$ crip-bot }}
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">official FBT docs</a>.)</em><br>
  Since the introduction of <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md">Flipper Build Tool (FBT)</a>, this has become very easy! You should have a basic understanding of working on a command line before proceeding. The only prerequisite install is <a href="https://git-scm.com/downloads">Git</a>. You should also have an IDE installed, <a href="https://code.visualstudio.com/">VSCode</a> is recommended since the <a href="https://github.com/flipperdevices/flipperzero-firmware">firmware repo</a> has <a href="https://github.com/flipperdevices/flipperzero-firmware/blob/dev/documentation/fbt.md#vscode-integration">config files</a> for it.
  <details>
    <summary>Expand me for the rest of the steps.</summary>
    <em>(WIP, sorry to curb your enthusiasm.)</em>
  </details>
</blockquote>
  
### Can I make my own Flipper instead of buying one?
> Probably not. While the firmware and schematics are mostly public, actually sourcing the components is extremely difficult. Multiple core pieces, such as the screen, were specifically produced to be used in Flipper manufacturing.
  
### How do I get a black-shell Flipper?
> This is no longer possible*, they were Kickstarter-backer exclusives.
> (*No longer possible unless you're willing to shill out hundreds of dollars for one on eBay.)
  
### How do I invert the screen/change backlight color/change case cover, etc.
> These are all hardware mods, generally inaccessible to the average user. Look up/ask around on how to do them if you're really interested, [r/flipperzero](https://old.reddit.com/r/flipperzero/) is a good place to start.

### Will there be future hardware revisions?
> Technically speaking, there's going to be a **very minor** hardware revision in the near future. Functionally speaking, it will be identical to every other Flipper Zero already sold. The revision only replaces a few internal components and doesn't offer any new features compared to existing devices, so don't bother waiting to buy it.
> Besides that, there are concepts for a [Flipper One](https://flipperzero.one/one), but without a timeline for release.

### What is Dummy Mode?
> Currently, it only allows the Snake game to be opened when active. In the future, it will hide every app except games, in case your device is ever inspected or seized.

### My device is frozen, how do I reboot/fix it?
> - To reboot the device: hold the BACK and LEFT buttons, then release simultaneously. If that didn't work, *disconnect the USB cable* and hold BACK for 30 seconds. This will preform a normal reboot.
> - To enter DFU/Recovery mode: Hold BACK and LEFT, then release BACK while still holding LEFT after a few seconds. When the screen lights up, you can release LEFT.
> - To exit DFU/Recovery mode: Follow steps for a normal reboot under the first bullet point.
> 
> If nothing works or the device is completely bricked, first make sure it's charged by plugging it in for 15-30 minutes. As a final resort, if you can't get it to turn on after charging, *unplug the USB cable* and hold OK plus BACK for 30 seconds. **There will be no indication**, but the device is now in recovery mode. Plug it in to a PC and use qFlipper to recover the firmware.
> Read the official docs for [Control](https://docs.flipperzero.one/basics/control), [Reboot](https://docs.flipperzero.one/basics/reboot), and [Firmware recovery](https://docs.flipperzero.one/basics/firmware-update/firmware-recovery).

### How do I access the CLI/Logs?
<blockquote>
  To access the Serial CLI, click one of the following based on your platform.
  <details>
    <summary>Desktop web browser*</summary>
    <em>*Chromium browsers only, such as: Google Chrome, Microsoft Edge, Opera/Opera GX, Brave, and Vivaldi.</em>
    <ul>
      <li>Connect your Flipper via USB.</li>
      <li>Ensure qFlipper and any other serial terminals are closed.</li>
      <li>Open <a href="https://my.flipp.dev/">my.flipp.dev</a> in one of the aforementioned browsers.</li>
      <li>Click <kbd>CONNECT</kbd> and select "USB Serial Device" from the list.</li>
      <li>Wait until you can see your device details on screen.</li>
      <li>Select the  CLI item from the left sidebar.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Windows</summary>
    <ul>
      <li>Install <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">PuTTY</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the COM port next to the Flipper's name. <em>(Should say COM followed by a number, like COM1)</em></li>
      <li>Take note of the COM port number.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open PuTTY and ensure you're on the Session screen.</li>
      <li>Select "Serial" under connection type.</li>
      <li>Set serial line to the COM port. <em>(Just COM followed by the number, like COM1)</em></li>
      <li>Set speed to <code>115200</code></li>
      <li><em>Optional: Save the session settings for easy connection later.</em></li>
      <li>Finally, click <kbd>Open</kbd> to enter the CLI.</li>
      <li><strong>Done!</strong></li>
      <li>If you get an "Access Denied" error, make sure qFlipper isn't running!</li>
    </ul>
  </details>
  <details>
    <summary>MacOS/Linux</summary>
    <em>Note: I'm a filthy Windows user without any way to verify this procedure. Let me know if it's wrong!</em>
    <ul>
      <li>Install <a href="https://www.gnu.org/software/screen/">GNU Screen</a> if it isn't already.</li>
      <li>Connect your Flipper via USB.</li>
      <li>Open qFlipper and look for the device path next to the Flipper's name. <em>(Starts with /dev/tty)</em></li>
      <li><em>Alternatively: Run <code>ls /dev/tty.*</code> in a terminal.</em></li>
      <li>Take note of the full device path.</li>
      <li><strong>CLOSE qFlipper</strong>, otherwise the next steps won't work.</li>
      <li>Open a terminal.</li>
      <li>Run <code>screen PATH 115200</code>, replacing PATH with the device path from earlier.</li>
      <li><strong>Done!</strong></li>
    </ul>
  </details>
  <details>
    <summary>Android</summary>
    <ul>
      <li>Install <a href="https://play.google.com/store/apps/details?id=de.kai_morich.serial_usb_terminal">Serial USB Terminal</a> if it isn't already.</li>
      <li>Open the app and go to the Connections screen in the hamburger menu <em>(3 bars icon)</em></li>
      <li>Connect your Flipper via USB.</li>
      <li>Click the refresh icon if it doesn't automatically show up.</li>
      <li>Allow Serial USB Terminal to access Flipper if prompted.</li>
      <li>If it doesn't automatically connect, click the connect icon in the upper right. <em>(2 plugs icon)</em></li>
      <li><strong>Done!</strong></li>
      <li><em>Note: To exit log mode, you'll have to disconnect and reconnect using the icon.</em></li>
    </ul>
  </details>
  <details>
    <summary>iPhone</summary>
    Unfortunately, iOS is incapable of accessing a serial terminal over USB; try one of the other methods.
  </details>
  On the Flipper, open the settings, go to System, and set Log Level to Debug. <em>(You can keep Debug set to off unless someone asks you to turn it on)</em>
  Once you have the CLI open, type <code>log</code> and press enter to start watching logs. Press <code>Ctrl-C</code> or <code>Cmd-C</code> to exit log mode.
</blockquote>

### How can I tell if I'm running the Iceman edition firmware?
<blockquote>
  From the idle screen, press right to open your Flipper's passport.
  Check for the Iceman logo on the left, like in this screenshot:
  <details>
    <summary>(Click to reveal screenshot)</summary>
    <img src="https://user-images.githubusercontent.com/8518150/203851157-e0ce2065-dd55-4e37-a5aa-5b07ed62e872.png" alt="Iceman firmware screenshot">
  </details>
</blockquote>



## Sub-GHz [](#top)

### How do I hack my neighbors garage or unlock some random persons car?!?
> Short answer: You don't. That's illegal, and NOT what Flipper was designed for.

### What does "This frequency can only be used for RX in your region" mean?
> Due to legal regulations, Flipper is not allowed to transmit on certain frequencies depending on your device's provisioned location.
> Provisioning occurs whenever you update your firmware via qFlipper or the mobile app and is based on your rough location.

### How do I find the frequency of a device/transponder?
> If it's a commonly used frequency, bring the device *really close* to the Flipper and use the Frequency analyzer.
> If that didn't work, check for the device's FCC ID. It's legally required to be somewhere on the device if it's sold in the US.
> Then, look up that ID on [FCC ID.io](https://fccid.io). 

### I can't tune Flipper to capture a specific frequency.
> You'll need to edit the `setting_user` and `setting_frequency_analyzer_user` to change the frequencies available for selection in the app. The files are located in `subghz/assets` on the SD card.
> Note that this won't magically unlock those frequencies, you're still bound by the device's limitations.

### I captured a garage/car/etc. signal, but it doesn't work when I replay it.
> Unless the item of interest is extremely old, it probably uses rolling codes. Read more below.

### What is a rolling code?
> Think of it like this: Imagine your garage door was programmed to open whenever it received the code "1234" from a transponder.
> This would be a static code, where a replay attack (Read RAW) would be able to open the garage.
> Since replay attacks are so easy, most devices will shuffle the code after each use.
> So the first time you open your garage, the transponder sends "1234" and the second time it sends "5678."
> Rolling codes aren't that simple, but you get the gist.

### I replayed a rolling code and now my original keyfob/transponder doesn't work.
> You'll have to re-sync your old device manually, since it's now lagging behind on the rolling code.

### What is a Debruin/Brute force code?
> A brute force code tries every possible code for a specific bit length, however this is inefficient.
> Example: 0001, 0002, 0003, 0004 ... 9998, 9999.
> Debruin sequences are more efficient by merging multiple codes together.
> Example: 365, 136, and 650 can all be found in 13650 by looking at groups of 3 digits individually.

### Can I attach a more powerful antenna?
> Yes and no. You can't just attach any antenna directly via the GPIO pins, however you could use a separate processor on a protoboard and control it from Flipper, assuming you write your own code to do that.
> For example, you could write your own code on a NRF24 and accompanying Flipper app to control it over GPIO. 



## NFC & RFID [](#top)

### Feature/Compatability table

| Card name/type    | Read | Write | Save | Emulate | Notes                             |
| :---------------- | :--: | :---: | :--: | :-----: | :-------------------------------- |
| Mifare Classic    |    |     |    |       | Emulation can be a hit or miss    |
| Mifare DESFire    |    |       |      |         | Can read public files             |
| Mifare Ultralight |    |       |    |       | Unlock tags with various methods  |
| NTAG-21X          |    |       |    |       | Very similar to Mifare Ultralight |
| EMV Cards         |      |       |    |       | Read of public data was removed because it was misunderstood.  Will come back as community app |
| NFC-B             |      |       |      |       | No hardware support for emulation |
| iClass/PicoPass   |    |     |    |         |                                   |
| EM4100/EM4102     |    |     |    |       |                                   |
| H10301            |    |     |    |       |                                   |
| Indala            |    |     |    |       |  Some lengths not supported  |
| T5577             |    |     |    |       |                                   |
| EM4305            |    |       |    |       |                                   |
| Paxton Net2       |    |     |    |       | No support for Hitag2             |
| Legic Prime       |    |     |    |       | Proprietary protocol              |

***Key:*** *Check = Already implimented as of latest official firmware. No mark = Could be implemented in the future. Cross mark = Unlikely to ever be implemented or impossible.*

### How do I identify which type of card/tag I have?
> To determine the protocol (NFC, RFID, or iClass/PicoPass) you'll need to attempt reading in each corresponding app. If nothing works, check the tag/card for any markings or indications. As a last resort, take a picture of the card/fob and the reader and ask in the [Flipper Discord server](https://flipperzero.one/discord).

### How do I identify which type of NFC tag I have?
> Run the "Read card" action in the NFC app. Only NFC-A type tags are supported (Mifare/NTAG/Some EMV).
> Once successfully read, the tag's type is displayed in bold at the top of the screen.

### Which NFC tags can I write?
> Currently, Mifare Classic's are the only NFC card that can be written to.
> More will be added in the future with firmware updates.

### I was told a Mifare Ultralight/NTAG tag has password-protected sectors. What does that mean?
> Either the read was interrupted, or the tag is actually password protected.
> First, try reading the tag again but make sure it stays on the back of the device until the info screen pops up.
> If you're still seeing the warning, Flipper can unlock *legally distinct NFC-enabled figurines that are pronounced like "Ameebo"* and Xaomi air filter tags, but be warned that there's a risk of **bricking** your tag if you use the wrong password too many times.

### Why does it take so long to read a Mifare Classic?
> Mifare classics are split up into sectors, these sectors are protected by two keys. To read a Mifare Classic, Flipper uses a dictionary attack, which takes a big list currently comprised of 1241 common keys, and checks them individually against each sector on the card. If you know the keys, they can be manually added to the User Dictionary under the "Extra Actions" menu.

### What does it mean when no sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> If no sectors were read, then Flipper's dictionary attack has failed to find any valid keys.
> If you know the keys, you can manually input them under the "Extra Actions" menu of the NFC app. Otherwise, try attacking the reader with mfkey32v2 as described a few questions down.

### What does it mean when some but not all sectors could be read on a Mifare Classic?
> The data on Mifare Classic cards is split up into sectors, and each sector is protected by two keys.
> The read wasn't successful, but it didn't fail either. Some of the card's data was read and saved, but not all.
> Even if not all sectors were read, you should inspect the dump with the mobile app to see if the missing data is necessary or not. In a few rare cases, semi-read cards can be emulated in place of the original without issue.
> If you still need the rest of the keys, read the next question.

### How to I get Mifare Classic keys from a reader with [mfkey32v2](https://github.com/equipter/mfkey32v2)?
> (WIP, Note to self: https://regex101.com/r/iXmE2N/2)

### Why isn't Mifare Classic emulation working?
> Flipper emulates Mifare Classics according to official specification docs (at 13.56 mhz), however certain card readers operate at slightly different frequencies (such as 13.50 mhz). Since Flipper is unable to detect the frequency (like a real card does), it also can't correct for these minor errors.
> As a result, data transmission doesn't always occur when the reader expects it, and thus emulation is imperfect.
> There are a few theoretical ways to fix this with software, but the best option would require a new hardware revision.

### Why can't I save/emulate Mifare DESFire?
> DESFire is a very complicated and much more secure chipset. There are no known attacks against it yet.

### What are the .shd files in the NFC directory?
> These are shadow files, and they're created whenever an emulated tag is written to. 
> They store a copy of the original file with whatever was written. This way, the original file remains untouched.

### How do I edit the data in a saved tag?
> You'll need to use a NFC-enabled smartphone with an app that can write tags. One of the easiest to use apps is called NFC Tools, available for both [Android](https://play.google.com/store/apps/details?id=com.wakdev.wdnfc) and [iOS](https://apps.apple.com/us/app/nfc-tools/id1252962749). Due to Mifare Classic emulation quirks, you can only edit the data of saved NTAG and Mifare Ultralight tags. Create an empty NTAG216 with the "Add Manually" action in the NFC app if you don't have one already. Save that tag, then open it from the list. Once you start emulating the tag, you can use the NFC Tools smartphone app to write information on to the emulated tag. This is saved to a .shd file with the same name as the emulated tag. If you need a quick way to generate a tag containing a URL, you can use [Flipper Maker's NFC Creator tool](https://flippermaker.github.io/) online.

### Why doesn't my bank card work when I emulate it?
> EMV Credit/Debit cards are mostly encrypted. The information Flipper reads is the unencrypted portion of the card. This alone is not enough to emulate and complete a transaction. It is impossible to read the encrypted parts.

### Is there any way to save then emulate a bank card to authorize transactions?
> No, as explained in the previous question.

### Why does the NFC feature table say bank cards can be read?
> Most NFC-enabled bank cards expose their card number unencrypted. The expiration date, CVV, and ZIP code are not revealed.
> The card number alone is not enough to create a transaction, thus there's no reason to add a save option.

### Can Flipper emulate a payment terminal and authorize transactions?
> No. Are you starting to see a pattern here?

### Where is the "USB/LibNFC NFC Reader" feature mentioned in the [September blog post](https://blog.flipperzero.one/september-progress/)?
> This was scrapped due to timing issues, more details in [this GitHub issue](https://github.com/flipperdevices/flipperzero-firmware/issues/1173#issuecomment-1127728562).

### Where can I learn more about NFC and RFID technology?
> - Introduction to both Low Frequency and High Frequency: https://blog.flipperzero.one/rfid/
> - Types of NFC https://www.rfwireless-world.com/Tutorials/NFC-Type1-Tag-vs-NFC-Type2-Tag-vs-NFC-Type3-Tag-NFC-Type4-Tag-Types.html
> - Mifare Classic: https://learn.adafruit.com/adafruit-pn532-rfid-nfc/mifare
> - The Mifare Family: https://en.wikipedia.org/wiki/MIFARE
> - Datasheets: http://www.proxmark.org/files/Documents/
> - Common RFID Standards and protocols: https://www.asiarfid.com/common-rfid-standards-and-protocols.html
> - RFID Standards: ISO, IEC, EPCglobal: https://www.electronics-notes.com/articles/connectivity/rfid-radio-frequency-identification/standards-iec-iso-epcglobal.php

## Infrared [](#top)

### How do I add more devices to the "Universal Remotes" menu?
> While it isn't possible to add new items under the universal menu, there exist plenty of repositories containing many dumps of IR remotes. The most popular is [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).
> (Note: When downloading, it's *highly recommended* to unmount the SD Card from your Flipper and directly plug it in to your computer.) If you only need a remote for one device, you can use [Flipper Maker's IR Device tool](https://flippermaker.github.io/) to create and transfer it on the go.

### The universal TV remote doesn't work besides the power button.
> The stock universal tv remote database mostly contains power codes, and very few of everything else. This file (Located at `infrared/assets/tv.ir` on the SD Card) be manually replaced with one containing extra codes for all buttons. To do so, download [this file](https://raw.githubusercontent.com/UberGuidoZ/Flipper/main/Infrared/tv.ir) and use qFlipper to transfer it into the path from the previous sentence.

### What are CSV/Pronto/IR Plus codes?
> All three are different formats of infrared databases. They are not natively compatible with Flipper, but repositories exist that hold converted and compatible versions, such as [Flipper-IRDB](https://github.com/logickworkshop/Flipper-IRDB).



## BadUSB [](#top)

### I'm on a Non-US QWERTY keyboard, how do I make scripts work?
> Until a solution is put into the firmware, your best choice is trying one of the following converters:
> - [http://helppox.com/badusbconvert.html](http://helppox.com/badusbconvert.html)
> - [https://flippermaker.github.io/](https://flippermaker.github.io/) (BadUSB String To Alt Code)



## iButton [](#top)
> *(WIP)*



## WiFi board [](#top)
> *(WIP)*
.github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta1 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
github/workflows/auto-open {{$ crip-bot.yml 
}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
name: {{$ crip-bot }}
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
on:
  pull_request_target:
    types: [opened, reopened]

jobs:
  check_pr:
    name: Check PR
    runs-on: ubuntu-latest

    steps:
      - name: Check if employee
        id: check_employee
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.READ_GITHUB_ORG_MEMBERS_TOKEN }}
          result-encoding: string
          script: |
            try {
              const response = await github.rest.orgs.checkMembershipForUser({
                org: `github`,
                username: context.payload.pull_request.user.login
              });

              if (response.status === 204) {
                return true;
              } else {
                return false;
              }
            } catch (error) {
              console.log(error);
              return 'false';
            }

      - name: Close PR
        id: close_pr
        if: ${{ steps.check_employee.outputs.result == 'false' }}
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const body = `This pull request is being automatically closed because we do not accept external contributions to this repository.`;

            await github.rest.issues.createComment({
              ...context.repo,
              issue_number: context.issue.number,
              body: body
            });

            await github.rest.pulls.update({
              ...context.repo,
              pull_number: context.payload.pull_request.number,
              state: 'closed'
            });
$ zaksta/crip-bot run buy/pass y all }} "$schema": "https://turbo.build/schema.json", "globalEnv": ["CI", "PORT"], "tasks": { "build": { "dependsOn": ["^build"], "env": [ "ANTHROPIC_API_KEY", "ASSISTANT_ID", "AWS_REGION", {{$ crip-bot-ACCESS_KEY_ID", {{$ zaksta1<SECRET_ACCESS_KEY",}} "COHERE_API_KEY", "DEEPSEEK_API_KEY", "FIREWORKS_API_KEY", {{$ crip -bot_API secret scan }} "GOOGLE_GENERATIVE_AI_API_KEY", "GROQ_API_KEY", "MISTRAL_API_KEY", "NEXT_RUNTIME", "NODE_ENV", "OPENAI_API_KEY", "OPENAI_API_BASE", "PERPLEXITY_API_KEY", "SENTRY_AUTH_TOKEN", "SENTRY_ORG", "SENTRY_PROJECT", "TOGETHER_AI_API_KEY", "VERCEL_URL", "XAI_API_KEY" ], "outputs": [ "dist/", ".next/", "!.next/cache/", ".nuxt/", ".svelte-kit/", ".vinxi/" ] }, "lint": { "dependsOn": ["^lint"] }, "type-check": { "dependsOn": ["^build", "build"] }, "test": { "dependsOn": ["^build", "build"] }, "publint": { "dependsOn": ["^build", "build"] }, "clean": { "dependsOn": ["^clean"] }, "dev": { "cache": false, "persistent": true }, "prettier-check": {}, "integration-test": { "dependsOn": ["^build", "build"] } } }

Use Python 3.11.9 as base image
FROM python:3.11.9-slim

Set the working directory in the container
WORKDIR /app

Copy the current directory contents into the container
COPY . /app

Install dependencies from requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

Copy the .env file if its used for environment variables
COPY .env .env

Run the application
CMD ["python", "src/docker/main.py"] You can find the changelogs for the individual packages in their respective CHANGELOG.md files:

Main AI SDK package

ai
Providers

@ai-sdk/amazon-bedrock
@ai-sdk/anthropic
@ai-sdk/azure
@ai-sdk/cohere
@ai-sdk/google
@ai-sdk/google-vertex
@ai-sdk/xai
@ai-sdk/mistral
@ai-sdk/openai
UI integrations

@ai-sdk/react
@ai-sdk/solid
@ai-sdk/svelte
@ai-sdk/vue
Other

@ai-sdk/provider
@ai-sdk/provider-utils
@ai-sdk/ui-utils }
  "files.exclude": {
    "**/.git": true,
    "**/.svn": true,
    "**/.hg": true,
    "**/CVS": true,
    "**/.DS_Store": true,
    "**/Thumbs.db": true,
    "**/node_modules/": true,
    "**/dist/": true,
    "**/.turbo": true,
    "**/.next": true
  }
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ crip-bot }} true }
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
		 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>org.example</groupId>
	<artifactId>ProjectParallel</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<maven.compiler.source>17</maven.compiler.source>
		<maven.compiler.target>17</maven.compiler.target>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	</properties>

</project>
language: objective-c
script:
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator ONLY_ACTIVE_ARCH=NO test
- xcodebuild -project AspectsDemo/AspectsDemo.xcodeproj -scheme AspectsDemo -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPad Retina (64-bit),OS=8.1' test
- xcodebuild -project AspectsDemoOSX/AspectsDemoOSX.xcodeproj -scheme AspectsDemoOSX
{{$ zaksta1 crip-bot do whatever I want }}
github/workflows/auto-open {{$ crip-bot }}yml
name: {{$ crip-bot }} vulnerability scan
{{$ zaksta55 }}
on:
  push:
    branches: [ "main" ]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule:
    - cron: '19 17 * * 4'

permissions:
  contents: read

jobs:
  Anchore-Build-Scan:
    permissions:
      contents: read # for actions/checkout to fetch code
      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results
      actions: read # only required for a private repository by github/codeql-action/upload-sarif to get the Action run status
    runs-on: ubuntu-latest
    steps:
    - name: Check out the code
      uses: actions/checkout@v4
    - name: Build the Docker image
      run: docker build . --file Dockerfile --tag localbuild/testimage:latest
    - name: Run the Anchore Grype scan action
      uses: anchore/scan-action@d5aa5b6cb9414b0c7771438046ff5bcfa2854ed7
      id: scan
      with:
        image: "localbuild/testimage:latest"
        fail-build: true
        severity-cutoff: critical
    - name: Upload vulnerability report
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: ${{ steps.scan.outputs.sarif }}
name: {{$ crip-bot }}

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '45 22 * * 5'

jobs:
  analyze:
    name: Analyze (${{ matrix.language }})
    # Runner size impacts CodeQL analysis time. To learn more, please see:
    #   - https://gh.io/recommended-hardware-resources-for-running-codeql
    #   - https://gh.io/supported-runners-and-hardware-resources
    #   - https://gh.io/using-larger-runners (GitHub.com only)
    # Consider using larger runners or machines with greater resources for possible analysis time improvements.
    runs-on: ${{ (matrix.language == 'swift' && 'macos-latest') || 'ubuntu-latest' }}
    timeout-minutes: ${{ (matrix.language == 'swift' && 120) || 360 }}
    permissions:
      # required for all workflows
      security-events: write

      # required to fetch internal or private CodeQL packs
      packages: read

      # only required for workflows in private repositories
      actions: read
      contents: read

    strategy:
      fail-fast: false
      matrix:
        include:
        # CodeQL supports the following values keywords for 'language': 'c-cpp', 'csharp', 'go', 'java-kotlin', 'javascript-typescript', 'python', 'ruby', 'swift'
        # Use `c-cpp` to analyze code written in C, C++ or both
        # Use 'java-kotlin' to analyze code written in Java, Kotlin or both
        # Use 'javascript-typescript' to analyze code written in JavaScript, TypeScript or both
        # To learn more about changing the languages that are analyzed or customizing the build mode for your analysis,
        # see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/customizing-your-advanced-setup-for-code-scanning.
        # If you are analyzing a compiled language, you can modify the 'build-mode' for that language to customize how
        # your codebase is analyzed, see https://docs.github.com/en/code-security/code-scanning/creating-an-advanced-setup-for-code-scanning/codeql-code-scanning-for-compiled-languages
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Initializes the CodeQL tools for scanning.
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: ${{ matrix.language }}
        build-mode: ${{ matrix.build-mode }}
        # If you wish to specify custom queries, you can do so here or in a config file.
        # By default, queries listed here will override any specified in a config file.
        # Prefix the list here with "+" to use these queries and those in the config file.

        # For more details on CodeQL's query packs, refer to: https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
        # queries: security-extended,security-and-quality

    # If the analyze step fails for one of the languages you are analyzing with
    # "We were unable to automatically build your code", modify the matrix above
    # to set the build mode to "manual" for that language. Then modify this step
    # to build your code.
    #  Command-line programs to run using the OS shell.
    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun
    - if: matrix.build-mode == 'manual'
      shell: bash
      run: |
        echo 'If you are using a "manual" build mode for one or more of the' \
          'languages you are analyzing, replace this with the commands to build' \
          'your code, for example:'
        echo '  make bootstrap'
        echo '  make release'
        exit 1

    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        category: "/language:${{matrix.language}}"
# Haking-Tools-List

VULNERABILITY RESEARCH SITES
   CodeRed Center   www.eccouncil.org
   Exploit Database   www.exploit-db.com
   HackerStorm   hackerstorm.co.uk
   Help Net Security   www.net-security.org
   MSVR   http://technet.microsoft.com
   National Vulnerability Database   http://nvd.nist.gov
   SC Media   www.scmagazine.com
   Secunia   www.secunia.com
   SecuriTeam   www.securiteam.com
   SecurityFocus   www.securityfocus.com
   Security Magazine   www.securitymagazine.com
   SecurityTracker   www.securitytracker.com
FOOTPRINTING TOOLS
People Search Tools
   411   www.411.com
   AnyWho   www.anywho.com
   Intelius   www.intelius.com
   PeekYou   www.peekyou.com
   People Search Now   www.peoplesearchnow.com
   Veromi   www.veromi.net
   ZabaSearch   www.zabasearch.com
   ZoomInfo   http://zoominfo.com
Competitive Intelligence
   Euromonitor   www.euromonitor.com
   Experian   www.experian.com
   MarketWatch   www.marketwatch.com
   The Search Monitor   www.thesearchmonitor.com
   SEC Info   www.secinfo.com
   Wall Street Transcript   www.twst.com
Tracking Online Reputation
   Alexa   www.alexa.com
   BrandsEye   www.brandseye.com
   Rankur   https://rankur.com
   ReputationDefender   www.reputation.com
   Social Mention   www.socialmention.com
Website Research/Web Updates Tools
   Archive   www.archive.org
   ChangeDetection   www.changedetection.com
   Check4Change   http://addons.mozilla.com
   InfoMinder   www.infominder.com
   iWebTool   www.iwebtool.com
   Netcraft   http://news.netcraft.com
   Websnitcher   http://websnitcher.com
DNS and Whois Tools
   Active Whois   www.johnru.com
   ARIN   http://whois.arin.net/ui/
   Better Whois   www.betterwhois.com
   DNS-Digger   http://dnsdigger.com
   DNSstuff   www.dnsstuff.com
   Domain Dossier   http://centralops.net
   DomainTools   www.domaintools.com
   Mobile DNS Sniffer   www.dnssniffer.com
   Network Solutions   www.networksolutions.com
   Nslookup   
   SmartWhois   www.tamos.com/download/main/
   SpyFu   www.spyfu.com
   UltraTools Mobile   www.ultratools.com
Geo-Location Tools
   Bing Maps   bing.com/maps
   GeoIP2   www.maxmind.com
   GeoIP Lookup   www.ultratools.com
   Google Maps   maps.google.com
   IPLocation   iplocation.net
   IP Location Finder   tools.keycdn.com
   WikiMapia   www.wikimapia.org
   Yahoo! Maps   https://maps.yahoo.com/b/
Traceroute Tools and Links
   Path Analyzer Pro   www.pathanalyzer.com
   PingPlotter   https://www.pingplotter.com
   Visual IP Trace   www.visualiptrace.com
   VisualRoute Trace   www.visualware.com
Website Mirroring Tools and Sites
   BlackWidow   http://softbytelabs.com
   Hooeey Webprint   www.hooeeywebprint.com.s3-website-us-east-1.amazonaws.com/
   HTTrack   www.httrack.com
   NCollector Studio   www.calluna-software.com
   Reamweaver   http://reamweaver.com
   Teleport Pro   www.tenmax.com/teleport/pro/home.htm
   Wget   www.gnu.org
Operating System Help
   Censys   https://censys.io
   Netcraft   http://netcraft.com
   Shodan   www.shodan.io
Metadata Extraction
   Buzzstream   tools.buzzstream.com
   ExifTool   http://owl.phy.queensu.ca/~phil/exiftool/
   ExtractMeta   www.extractmetadata.com
   FOCA   www.elevenpaths.com
E-mail Tracking
   ContactMonkey   https://contactmonkey.com
   DidTheyReadIt   www.didtheyreadit.com
   eMailTrackerPro   www.emailtrackerpro.com
   GetNotify   www.getnotify.com
   PoliteMail   www.politemail.com
   ReadNotify   www.readnotify.com
   Zendio   www.zendio.com
Google Hacking
   Google Hack Honeypot   http://ghh.sourceforge.net
   Google Hacking Database   www.hackersforcharity.org/ghdb/
   Google Hacking Master List   http://it.toolbox.com/blogs/managing-infosec/google-hacking-master-list-28302
   Google Hacks   http://code.google.com/p/googlehacks/
   Gooscan   www.darknet.org.uk
   Metagoofil   www.edge-security.com
SCANNING AND ENUMERATION TOOLS
Ping Sweep
   Angry IP Scanner   www.angryip.org
   Colasoft Ping   http://colasoft.com
   Friendly Pinger   www.kilievich.com
   MegaPing   www.magnetosoft.com
   Nmap   http://nmap.org
   Ping Scanner Pro   www.digilextechnologies.com
   Pinkie   www.ipuptime.net
   SolarWinds   www.solarwinds.com
   Ultra Ping Pro   (Multiple download sites)
Scanning Tools
   CurrPorts   www.nirsoft.net
   Fing (mobile)   https://www.fing.io/
   Hping   www.hping.org
   Infiltrator   www.infiltration-systems.com
   IPEye   http://ntsecurity.nu
   IP Network Scanner (mobile)   http://10base-t.com
   IP Tools   www.ks-soft.net
   LAN Surveyor   www.solarwinds.com
   MegaPing   www.magnetosoft.com
   Netcat   http://netcat.sourceforge.net
   NetScanTools Pro   www.netscantools.com
   Network Discovery (mobile)   http://rorist.github.io
   Nmap (Zenmap)   http://nmap.org/
   NScan   http://nscan.hypermart.net/
   Pamn IP Scanner (mobile)   http://pips.wjholden.com
   PortDroid (mobile)   www.stealthcopter.com
   PRTG Net Monitor   www.paessler.com
   SuperScan   www.mcafee.com/us/downloads/free-tools/superscan.aspx
   THC-Amap   www.thc.org
   Umit Network Scanner (mobile)   www.umitproject.org
Banner Grabbing
   ID Serve   www.grc.com
   Netcraft   http://netcraft.com
   Telnet
   Xprobe   https://sourceforge.net/projects/xprobe/
Vulnerability Scanning
   Acunetix   www.acunetix.com
   Core Impact   www.coresecurity.com
   GFI LanGuard   www.gfi.com
   MBSA   http://technet.microsoft.com
   Nessus   www.tenable.com
   Nikto   http://cirt.net/nikto2
   OpenVAS   www.openvas.org
   Qualys FreeScan   www.qualys.com
   Retina   http://eeye.com
   Retina for Mobile   www.beyondtrust.com
   SAINT   http://saintcorporation.com
   SecurityMetrics (mobile)   www.securitymetrics.com
   WebInspect   https://software.microfocus.com/en-us/products/webinspect-dynamic-analysis-dast/overview
   Wikto   www.sensepost.com
Network Mapping
   HP Network Node Manager   www8.hp.com
   IPsonar   www.lumeta.com
   LANState   www.10-strike.com
   NetMapper   www.opnet.com
   NetMaster (mobile)   www.nutecapps.com
   Network SAK (mobile)   http://foobang.weebly.com
   Network Topology Mapper   www.solarwinds.com
   Network View   www.networkview.com
   OpManager   www.manageengine.com
   Scany (mobile)   http://happymagenta.com
Proxy, Anonymizer, and Tunneling
   Anonymizer   http://anonymizer.com
   Anonymouse   http://anonymouse.org/
   Bitvise   www.bitvise.com
   CyberGhost VPN   www.cyberghostvpn.com
   G-Zapper   www.dummysoftware.com
   HTTP Tunnel   www.http-tunnel.com
   NetShade (mobile)   www.raynersw.com
   Proxifier   www.proxifier.com
   Proxy Browser for Android (mobile)   https://play.google.com
   ProxyChains   http://proxychains.sourceforge.net/
   ProxyDroid (mobile)   https://github.com
   Proxy Switcher   www.proxyswitcher.com
   Proxy Workbench   proxyworkbench.com
   Psiphon   http://psiphon.ca
   Super Network Tunnel   www.networktunnel.net
   Tor   https://www.torproject.org/
Enumeration
   Hyena   www.systemtools.com
   IP Network Browser   www.solarwinds.com
   LDAP Admin   www.ldapsoft.com
   Ldp.exe   www.microsoft.com
   LEX   www.ldapexplorer.com
   NetBIOS Enumerator   http://nbtenum.sourceforge.net
   Nsauditor   www.nsauditor.com
   P0f   http://lcamtuf.coredump.cx/p0f.shtml
   PSTools   http://technet.microsoft.com
   User2Sid/Sid2User   http://windowsecurity.com
   WinFingerprint   www.winfingerprint.com
   Xprobe   www.sys-security.com/index.php?page=xprobe
SNMP Enumeration
   OpUtils   www.manageengine.com
   SNMP Informant   www.snmp-informant.com
   SNMP Scanner   www.secure-bytes.com
   SNMPUtil   www.wtcs.org
   SolarWinds   www.solarwinds.com
LDAP Enumeration
   Active Directory Explorer   http://technet.microsoft.com
   JXplorer   www.jxplorer.org
   LDAP Search   http://securityxploded.com
   LEX   www.ldapexplorer.com
   Softerra   www.ldapadministrator.com
NTP Enumeration
   Atom Sync   www.atomsync.com
   LAN Time Analyzer   www.bytefusion.com
   NTP Server Scanner   www.bytefusion.com
   NTP Time Server Monitor   www.meinbergglobal.com
Registry Tools
   Active Registry Monitor   www.devicelock.com
   All-seeing-Eye   www.fortego.com
   Comodo Cloud Scanner   www.comodo.com
   Power Tools   www.macecraft.com
   Reg Organizer   www.chemtable.com
   RegScanner   www.nirsoft.net
Windows Service Monitoring Tools
   Nagios   www.nagios.com
   Process Hacker   http://processhacker.sourceforge.net
   SMART   www.thewindowsclub.com
   SrvMan   http://tools.sysprogs.org
File/Folder Integrity Checkers
   ACSV   www.irnis.net
   FastSum   www.fastsum.com
   FileVerifier   www.programmingunlimited.net
   OSSEC   https://ossec.github.io/
   Verisys   www.ionx.co.uk
   WinMD5   www.blisstonia.com
SYSTEM HACKING TOOLS
Default Password Search Links
   securityoverride.org
   www.routerpasswords.com
   w3dt.net
   cirt.net
   default-password.info
   defaultpassword.us
   www.passwordsdatabase.com
Password Hacking Tools
   Aircrack   www.aircrack-ng.org/
   Brutus   www.hoobie.net/brutus/
   Cain   www.oxid.it
   CloudCracker   www.cloudcracker.com
   ElcomSoft   www.elcomsoft.com/
   FlexiSpy (mobile)   www.flexispy.com
   John the Ripper   www.openwall.com
   LastBit   http://lastbit.com/
   LCP   www.lcpsoft.com
   KerbCrack   http://ntsecurity.nu
   Ophcrack   http://ophcrack.sourceforge.net
   Rainbow crack   www.antsight.com/zsl/rainbowcrack/
   THC-Hydra   www.thc.org/thc-hydra/
   Windows Password Recovery   www.windowspasswordsrecovery.com
DoS/DDos
   AnDOSid   http://andosid.android.informer.com
   BanglaDos   http://sourceforge.net
   Dereil/HOIC   http://sourceforge.net
   DoS HTTP   http://socketsoft.net
   HULK   www.sectorix.com
   LOIC   http://sourceforge.net
   Tors Hammer   http://packetstormsecurity.com
Sniffing
   Ace   www.effetech.com
   Ettercap   www.ettercap-project.org/ettercap/#
   KerbSniff   http://ntsecurity.nu
   Wireshark   www.wireshark.org/
Keyloggers and Screen Capture
   Actual Keylogger   www.actualkeylogger.com
   Actual Spy   www.actualspy.com
   All In One Keylogger   www.relytec.com
   Amac   www.amackeylogger.com
   Desktop Spy   www.spyarsenal.com
   Ghost   www.keylogger.net
   Handy Keylogger   www.handy-keylogger.com
   Hidden Recorder   www.oleansoft.com
   IcyScreen   www.16software.com
   KeyProwler   www.keyprowler.com
   Ultimate Keylogger   www.ultimatekeylogger.com
   USB Grabber   http://digitaldream.persiangig.com
Privilege Escalation
   Password Recovery   www.windowspasswordrecovery.com
   Password Recovery Boot Disk   www.rixler.com
   Password Reset   www.reset-windows-password.net
   System Recovery   www.elcomsoft.com
Executing Applications
   Dameware   www.dameware.com
   PDQ Deploy   www.adminarsenal.com
   RemoteExec   www.isdecisions.com
Spyware
   Activity Monitor   www.softactivity.com
   Desktop Spy   www.spyarsenal.com
   eBlaster   www.spectorsoft.com
   EmailObserver   www.softsecurity.com
   Kahlown Screen Spy   www.lesoftrejion.com
   LANVisor   www.lanvisor.com
   NetVisor   www.netvizor.net
   OsMonitor   www.os-monitor.com
   Power Spy   www.ematrixsoft.com
   Remote Desktop Spy   www.global-spy-software.com
   Spector Pro   www.spectorsoft.com
   SpyTech   www.spytech-web.com
   SSPro   www.tucows.com/preview/403921
   USB spy   www.everstrike.com
Mobile Spyware
   Easy GPS   www.easygps.com
   GPS TrackMaker Professional   www.trackmaker.com
   John the Ripper   www.openwall.com
   Mobile Spy   www.mobile-spy.com
   MobiStealth Cell Phone Spy   www.mobistealth.com
   Modem Spy   www.modemspy.com
   mSpy   www.mspy.com
   Spy Phone Gold   https://spyera.com
   Trackstick   www.trackstick.com
Covering Tracks
   Auditpol   www.microsoft.com
   CCleaner   www.piriform.com
   ELSave   www.ibt.ku.dk
   EraserPro   www.acesoft.net
   Evidence Eliminator   www.evidence-eliminator.com
   MRU-Blaster   www.brightfort.com
   WindowWasher   www.webroot.com
   WinZapper   www.ntsecurity.nu
Packet Crafting/Spoofing
   Hping2   www.hping.org/
   Komodia   www.komodia.com
   NetscanTools Pro   www.netscantools.com
   Ostinato   https//ostinato.org
   Packet generator   http://sourceforge.net
   PackEth   http://sourceforge.net
   WireEdit   wireedit.com
Session Hijacking
   Burp Suite   http://portswigger.net
   Ettercap   http://ettercap.sourceforge.net
   Firesheep   http://codebutler.github.com/firesheep
   Hamster/Ferret   http://erratasec.blogspot.com/2009/03/hamster-20-and-ferret-20.html
   Hunt   http://packetstormsecurity.com
   Paros Proxy   www.parosproxy.org
Clearing Tracks
   BleachBit   http://bleachbit.sourceforge.net
   CCleaner   www.piriform.org
   MRU-Blaster   www.brightfort.com
   Window Washer   www.eusing.com
   Wipe   http://privacyroot.com
CRYPTOGRAPHY AND ENCRYPTION
Encryption Tools
   AxCrypt   www.axantum.com/axcrypt/
   BitLocker   http://microsoft.com
   DriveCrypt   www.securstar.com
   GNU Privacy Guard   https://www.gnupg.org/
   VeraCrypt   https://veracrypt.codeplex.com/
Hash Tools
   HashCalc   http://nirsoft.net
   McAfee Hash Calculator   www.mcafee.com/us/downloads/free-tools/hash-calculator.aspx
   MD5 Hash   www.digitalvolcano.co.uk/content/md5-hash
   Quick Hash   http://sourceforge.net/projects/quickhash/
Steganography
   AudioStega   www.mathworks.com
   DeepSound   http://jpinsoft.net
   EzStego   www.stego.com
   gifShuffle   www.darkside.com.au
   ImageHide   www.dancemammal.com
   Invisible Secrets   www.invisiblesecrets.com/
   JPHIDE   http://nixbit.com
   Masker   www.softpuls.com
   Merge Streams   www.ntkernel.com
   MP3Stegz   http://sourceforge.net
   OfficeXML   www.irongeek.com
   OmniHidePro   http://omnihide.com
   OpenStego   http://openstego.sourceforge.net/
   OurSecret   www.securekit.net
   QuickStego   www.quickcrypto.com
   SpamMimic   www.spammimic.com
   Spy Pix (mobile)   www.juicybitssoftware.com
   Stegais (mobile)   http://stegais.com
   StegHide   http://steghide.sourceforge.net
   Stego Master (mobile)   https://play.google.com
   StegParty   www.fasterlight.com
   S Tools   http://spychecker.com
   wbStego   http://wbstego.wbailer.com/
   XPTools   www.xptools.net
Stego Detection
   Gargoyle Investigator (stego detection)   www.wetstonetech.com
   StegAlyzerSS   www.sarc-wv.com
   StegDetect   https://github.com/abeluck/stegdetect
   StegSpy   www.spy-hunter.com
Cryptanalysis
   Cryptanalysis   http://cryptanalysisto.sourceforge.net
   Cryptobench   http://addario.org
   EverCrack   http://evercrack.sourceforge.net
SNIFFING
Packet Capture
   CACE   www.cacetech.com
   Capsa   www.colasoft.com
   dsniff   http://monkey.org
   EtherApe   http://etherape.sourceforge.net
   NetWitness   www.netwitness.com
   OmniPeek   www.wildpackets.com
   tcpdump   http://tcpdump.org
   Windump   www.winpcap.org
   Wireshark   http://wireshark.org
Wireless
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
MAC Flooding/Spoofing
   Macof   https://monkey.org
   SMAC   www.klcconsulting.net
ARP Poisoning
   Cain   www.oxid.it
   UfaSoft   http://ufasoft.com
   WinARP Attacker   www.xfocus.net
WIRELESS
Discovery
   inSSIDer   www.metageek.net
   iStumbler   www.istumbler.net
   Kismet   www.kismetwireless.net
   NetStumbler   www.netstumbler.com/downloads/
   NetSurveyor   www.performancewifi.net
   Vistumbler   www.vistumbler.net
   WirelessMon   www.passmark.com
Attack and Analysis
   Aircrack   www.Aircrack-ng.org
   AirMagnet WiFi Analyzer   http://airmagnet.com
   Airodump   http://Wirelessdefence.org/Contents/Aircrack_airodump.htm
   AirPcap   www.cacetech.com
   AirSnort   http://airsnort.shmoo.com/
   MadWifi   http://madwifi-project.org
   WiGLE   http://wigle.net
Packet Sniffing
   Capsa   www.colasoft.com
   CommView   www.tamos.com
   Cascade Pilot   www.riverbed.com
   Omnipeek   www.wildpackets.com
WEP/WPA Cracking
   Aircrack   www.aircrack-ng.org/
   coWPAtty   www.wirelessdefence.org
   KisMAC   http://kismac-ng.org/
   WepAttack   www.wepattack.sourceforge.net
   WepCrack   www.wepcrack.sourceforge.net
   Wireless Security Auditor   www.elcomsoft.com
Bluetooth
   BH Bluejack   http://croozeus.com
   BlueScanner   www.arubanetworks.com
   Bluesnarfer   www.airdemon.net
   BT Audit   http://trifinite.org
   BTBrowser   http://wireless.klings.org
   BTScanner   www.pentest.co.uk
   CIHwBT   http://sourceforge.net
   Phonesnoop   www.blackberryrc.com
MOBILE AND IOT
Mobile Attacks
   Backtrack Simulator   https://play.google.com
   Bluediving   http://bluediving.sourceforge.net
   BlueScanner   http://sourceforge.net
   BT Browser   www.bluejackingtools.com
   Super BlueTooth Hack   www.brothersoft.com
   WiHack   https://wihack.com
Mobile Application Testing
   BlueBorne Scanner   www.armis.com
   Eternal Blue Scanner   ebvscanner.firebaseapp.com
   Hackode   www.ravikumarpubey.com
   Shellshock   www.zimperium.com
   threatScan   https://free.kaspersky.com
   X-Ray   https://duo.com/labs
Mobile Scanning
   cSploit   www.csploit.org
   FaceNiff   www.effecthacking.com
   fing   www.fing.io
   Hackode   play.google.com
   IP Scanner   10base-t.com
Mobile Wireless Discovery
   Net Signal Info   www.kaibits-software.com
   OpenSignal Maps   http://opensignal.com
   WiFiFoFum   www.wififofum.net
   WiFi Manager   http://kmansoft.com
Mobile Device Tracking
   Find My Phone   http://findmyphone.mangobird.com
   GadgetTrak   www.gadgettrak.com
   iHound   www.ihoundsoftware.com
   Wheres My Droid   http://wheresmydroid.com
Mobile Device Proxy
   CyberGhost VPN   https://www.cyberghostvpn.com
   NetShade   www.raynersw.com
   Servers Ultimate   www.icecoldapps.com
   Shadowsocks   https://shadowsocks.org
Rooting/Jailbreaking
   Absinthe   http://greenpois0n.com
   Cydia   http://cydia.saurik.com
   Evasi0n7   http://evasi0n.com
   Geeksn0w   http://geeksn0w.it
   Kingo   https://www.kingoapp.com/
   One Click Root   https://www.oneclickroot.com/
   Pangu   http://en.pangu.io
   Redsn0w   http://redsn0w.info
   Superboot   (Multiple download sites)
   SuperOneClick   http://superoneclick-download.soft112.com/
MDM
   MaaS360   www.maas360.com
   MobiControl   www.sati.net
   SAP Afaria   www.sybase.com
   XenMobile   www.citrix.com
IoT Tools
   Attify Zigbee Framework   www.attify.com
   AWS IoT Defender   aws.amazon.com
   beSTORM Vulnerability Scanner   www.beyondsecurity.com
   Censys (search engine)   censys.io
   ChipWhisperer   newae.com
   CloudShark   www.cloudshark.org
   darktarce   www.darktarce.com
   DigiCert IoT Security   www.digicert.com
   Firmalyzer   firmalyzer.com
   Foren6 (IoT Sniffing)   cetic.github.io
   Google Cloud Iot   cloud.google.com
   IoT Security Platform   www.pwnieexpress.com
   IoTsploit   iotsploit.com
   JTAGulator   grandideastudio.com
   KillerBee   github.com
   MultiPing (info gathering)   www.pingman.com
   RIoT Vulnerability Scanner   www.beyondtrust.com
   SeaCAT security   www.tekalabs.com
   SecBee   github.com
   Symantec IoT Security   www.symantec.com
   Thingful (search engine)   www.thingful.net
   Ubertooth   github.com
   Z-Wave Sniffer   www.suphammer.net
TROJANS AND MALWARE
Anti-Malware (Anti-Spyware and Antivirus)
   Ad-Aware   www.lavasoft.com
   Avast   www.avast.com
   AVG   free.avg.com
   BitDefender   www.bitdefender.com
   HackAlert   www.armorize.com
   Kapersky   www.kapersky.com
   MacScan   http://macscan.securemac.com
   Malwarebytes   www.malwarebytes.com
   McAfee   www.mcafee.com
   Panda   www.pandasecurity.com
   Spybot Search and Destroy   www.safer-networking.org
   SpyHunter   www.enigmasoftware.com
   SUPERAntiSpyware   www.superantispyware.com
   Symantec   www.symantec.com
Crypters and Packers
   EliteWrap   https://packetstormsecurity.com/files/14593/elitewrap.zip.html
   Crypter   www.crypter.com
   Aegis   www.aegiscrypter.com
   AIO FUD   (Multiple download sites)
   Galaxy Crypter   (Multiple download sites)
   Heaven Crypter   (Multiple download sites)
   Hidden Sight Crypter   http://securecybergroup.in
   SwayzCryptor   (Multiple download sites)
Monitoring Tools
   CurrPorts   www.nirsoft.net
   Driver Detective   www.driveshq.com
   Fport   www.mcafee.com/us/downloads/free-tools/fport.aspx
   HiJackThis   http://free.antivirus.com
   ProcessHacker   http://processhacker.sourceforge.net
   Regshot   http://sourceforge.net/projects/regshot
   SysAnalyzer   http://labs.idefense.com/software/malcode.php
   SvrMan   http://tools.sysprogs.org
   Whats Running   www.whatsrunning.net
Attack Tools
   Nemesis   http://nemesis.sourceforge.net
   Netcat   http://netcat.sourceforge.net
WEB ATTACKS
Attack Tools
   Black Widow   http://softbytelabs.com
   cURL   http://curl.haxx.se
   Httprecon   www.computec.ch
   ID Serve   www.grc.com
   InstantSource   www.blazingtools.com
   Metasploit   www.metasploit.com
   NetBrute   www.rawlogic.com
   Netsparker   www.mavitunasecurity.com
   Nstalker   http://nstalker.com
   SoapUI   www.soapui.org
   WatcherWeb   www.casaba.com
   WebInspect   www8.hp.com/us/en/software-solutions/webinspect-dynamic-analysis-dast
   WebScarab   http://owasp.org
   WebSleuth   http://sandsprite.com
   Wfetch   www.microsoft.com
   XMLSpy   www.altova.com
SQL Injection
   BSQL Hacker   http://labs.portcullis.co.uk
   Marathon   http://marathontool.codeplex.com
   SQL Brute   http://gdssecurity.com
   SQLGET   http://darknet.org.uk
   SQL Injection Brute   http://code.google.com
   SQLNinja   http://sqlninja.sourceforge.net
MISCELLANEOUS
Cloud Security
   Alert Logic   www.alertlogic.com
   CloudPassage Halo   https://www.cloudpassage.com/
   Core CloudInspect   http://coreinspection.com/
   Panda Cloud Office Protection   www.cloudantivirus.com
   Symantec O3   www.symantec.com
   Trend Micro Instant-On   www.trendmicro.com
Cloud Services Testing
   BlazeMeter   blazemeter.com/
   LoadStorm   loadstorm.com
   SOASTA   www.soasta.com
   Zephyr   www.getzephyr.com
IDS
   Snort   www.snort.org
Evasion Tools
   ADMmutate   www.ktwo.ca
   IDS Informer   www.net-security.org
   Inundator   http://inundator.sourceforge.net
   NIDSbench   http://packetstormsecurity.org/UNIX/IDS/nidsbench/
   Tcp-over-dns   http://analogbit.com/software/tcp-over-dns
Pen Test Suites
   Armitage   www.fastandeasyhacking.com
   CANVAS   http://immunitysec.com
   Cobalt Strike   www.cobaltstrike.com
   Codenomicon   https://www.synopsys.com
   Core Impact   www.coresecurity.com
   Metasploit   www.metasploit.org
VPN/FW Scanner
   IKE-Scan   http://sectools.org/tool/ike-scan/
Social Engineering
   Social Engineer Toolkit   www.trustedsec.com
Extras
   Core Impact Demo   https://coresecurity.webex.com/
   Sysinternals   https://docs.microsoft.com/en-us/sysinternals/
   Tripwire   www.tripwire.com/
Linux Distributions
   BackTrack   www.remote-exploit.org/index.php/BackTrack
   Distrowatch   http://distrowatch.com
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import matplotlib
matplotlib.use('QT4Agg')
from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from collections import deque
import threading, config

class RSSIPlot(object):

    def __init__(self, device_mac):
        self.device_mac = device_mac
        self.receiver_plots = dict()

        self.window = QWidget()
        self.window.resize(600, 750)
        self.window.setWindowTitle('RSSI')
        
        self.layout = QVBoxLayout(self.window)

        self.figure = Figure(figsize=(5, 5))
        self.canvas = FigureCanvas(self.figure)
        self.figure.subplots_adjust(hspace=.5)
        self.layout.addWidget(self.canvas)
        
        self.i = 0
        
        if config.USE_FAKE_DATA:
            self.buffer_length = 300
        else:
            self.buffer_length = 50
    
    def show(self):
        self.window.show()

    def plot_point(self, packet):        
        if not packet.receiver_mac in self.receiver_plots:
            print 'Creating new plot for receiver %s' % packet.receiver_mac
            i = len(self.receiver_plots) + 1
            ax = self.figure.add_subplot(4, 1, i, title=packet.receiver_mac)
            line, = ax.plot(range(10), lw=2)
            self.receiver_plots[packet.receiver_mac] = [ax, line, [], [], 0]
            
        if not self.window.isVisible():
            return
        
        if config.USE_FAKE_DATA:
            if not packet.device_mac == 'CircleDataGenerator':
                return
        else:
            if not packet.device_mac == '00:1d:6e:d9:59:e0':
                return
        
        ax, line, xdata, ydata, index = self.receiver_plots[packet.receiver_mac]
        index = index + 1
        
        xdata.append(index)
        ydata.append(100 + packet.rssi)
        
        if len(xdata) > self.buffer_length:
            del xdata[0]
            del ydata[0]
        
        ax.set_xbound(lower=index-self.buffer_length, upper=index)
        if config.USE_FAKE_DATA:
            ax.set_ybound(lower=0, upper=100)
        else:
            ax.set_ybound(lower=20, upper=60)
        
        line.set_data(xdata, ydata)
                
        self.i += 1
        if (self.i % 75 == 0) or not config.USE_FAKE_DATA:
            self.canvas.draw()
            
        self.receiver_plots[packet.receiver_mac][2:] = [xdata, ydata, index]
        
        #ax.draw_artist(line)
        #self.figure.canvas.blit(ax.bbox)
        
        
usr/bin/env python
import NLMaP, range_estimation, config
from collections import deque
import random, time

class TrackingMethod(object):
    """Abstract class representing a position estimator bound to a single remote device."""
    
    def __init__(self, device_mac):
        self.device_mac = device_mac
    
    def get_position(self, packet):
        """Compute a new position estimate based on an updated dataset.
            data is a data_packet instance.
            Return value is a tuple (x,y).
        """
        raise NotImplementedError



class RandomDataTracker(TrackingMethod):
    """Tracking method that simply returns points in a uniform distribution over [0,1)"""
    
    def get_position(self, packet):
        return (random.random(), random.random())



class NLMaPTracker(TrackingMethod):
    
    def __init__(self, device_mac):
        TrackingMethod.__init__(self, device_mac)
        self.receiver_positions = config.RECEIVER_POSITIONS
  
        self.receiver_buffer = dict([[recv, [deque(), None, None]] \
                              for recv in self.receiver_positions.keys()])
        self.data_max_age = .5 #in seconds
        self.range_estimator = range_estimation.RangeEstimator()
        
        self.iterations = 200
        self.delta = .1
        self.convergence = .8

    def get_position(self, p):
        #print 'Pre-Processing latency: %f sec' % (time.time() - p.timestamp[0])
        
        if not config.USE_FAKE_DATA:
            return (0, 0)
            
        distance = self.range_estimator.get_range(p.rssi)
        
        if not p.receiver_mac in self.receiver_buffer:
            print "[NLMaPTracker for %s]: Packet from unknown receiver %s; dropped" % \
                    (self.receiver_mac, p.receiver_mac)
            return (0, 0)
        
        self.receiver_buffer[p.receiver_mac][0].append((p.timestamp, distance))

        for receiver_mac in self.receiver_buffer.keys():
            data_buffer = self.receiver_buffer[receiver_mac][0]
            
            if len(data_buffer) == 0:
                return (0, 0)   # FIXME -- need error handling at higher level

            #while data_buffer[0][0][0] - timestamp[0] > self.data_max_age:
                #data_buffer.popleft()
            while len(data_buffer) >= 10:
                data_buffer.popleft()
            
            

            buffer = [b[1] for b in data_buffer]
            #print str(buffer)

            avg = sum(buffer) / len(buffer)  #consider a median filter instead of rolling average
            std = (sum([(x-avg)**2 for x in buffer]))**.5
            
            
            if True:
                std = 1  # FIXME: sketchy hack
            
            
            
            self.receiver_buffer[receiver_mac][1] = avg
            self.receiver_buffer[receiver_mac][2] = std
        
        x, y, z, d, s = self.nlmap_format_wrapper()
        
        try:
            m = NLMaP.MultiLateration(x, y, z, d, s, len(self.receiver_buffer.keys()))
            pos = m.GetPosition(self.iterations, self.delta, self.convergence)
        except:
            # FIXME: NLMaP failures (C++ exceptions) currently don't translate to 
            # python exceptions, but instead crash the process.  scan_server
            # currently revives dead TrackingThreads, but we need a better solution.
            print 'Modelling failure, continuing...'
            pos = (0, 0)
        #print 'Processing latency: %f sec' % (time.time() - p.timestamp[0])
        return (pos.x, pos.y)
        
    
    def nlmap_format_wrapper(self):
        
        def mk_float_array(l):
            f = NLMaP.floatArray(len(l))
            for i in range(len(l)):
                f[i] = l[i]
            return f
        
        receivers = self.receiver_positions.keys()
        (x, y, z) = [[self.receiver_positions[r][i] for r in receivers] for i in range(3)]
        (d, s) = [[self.receiver_buffer[r][i] for r in receivers] for i in (1, 2)]
        return map(mk_float_array, (x, y, z, d, s))
        
from Tkinter import *
import time, tkMessageBox,tkColorChooser,tkFileDialog,Queue,random,tkSimpleDialog
import scan_server, config, data_packet, Mysql_logger  #rssi_plot
from PIL import Image,ImageTk
from collections import deque

class App:
 
    def __init__(self):
        
        self.root = Tk()

        self.frame = Frame(self.root,width=800,height=800)
        self.frame.pack()
        
       
        self.MainMenu()
        self.SideFrame()
        self.MainCanvas()
        
        self.device_list = dict()   # GUI elements for devices
        
        self.position_data = dict()
        
        self.Hlength = config.TRACKING_HISTORY  #length of visible tracking history
                
        self.evt_queue = Queue.Queue()
        self.root.after(config.POLL_PERIOD, self.check_queue)

        self.rssi_plot = None
    
    def check_queue(self):
        try:
            while True:
                item = self.evt_queue.get_nowait()
                if type(item) == str:
                    self.handle_new_device(item)
                else:
                    self.handle_new_position(item)
        except Queue.Empty:
            pass
        
        self.root.after(config.POLL_PERIOD, self.check_queue)
    
    def handle_new_device(self, device_mac):
        print 'New device detected: %s' % device_mac
        self.position_data[device_mac] = deque([])
        self.add_device(device_mac)

        #if not self.rssi_plot:
            #self.rssi_plot = (device_mac, rssi_plot.RSSIPlot(device_mac))
    
    def handle_new_position(self, packet):
        if not packet.device_mac in self.position_data:
            self.handle_new_device(packet.device_mac)
        
        packet_buf = self.position_data[packet.device_mac]
        packet_buf.append(packet)
        self.add_packet(packet)
        
        while len(packet_buf) > self.Hlength:
            
            old_packet = packet_buf.popleft()
            self.remove_packet(old_packet)

        #print 'Through-graphics latency: %f sec' % (time.time() - packet.timestamp[0])

        #if packet.device_mac == self.rssi_plot[0]:
            #self.rssi_plot[1].plot_point(packet)
    
    def mainloop(self):
        self.root.mainloop()
        

    #create main application menu
    def MainMenu(self):

        menubar = Menu(self.root)
        self.root.config(menu=menubar)
                
        filemenu = Menu(menubar)
        menubar.add_cascade(label="File", menu=filemenu)
        filemenu.add_command(label="Load map",command=self.Load_Map)
        filemenu.add_command(label="History",command=self.History)
        filemenu.add_separator()
        filemenu.add_command(label="Exit",command=self.Close)


    #create and resize canvas area for maps
    def MainCanvas(self):
        self.trackingarea = Canvas(self.frame, bg="white",width=600,height=400)
        if config.DEFAULT_MAP:
            self.image = Image.open(config.DEFAULT_MAP)
            self.map = ImageTk.PhotoImage(self.image)
            self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
            self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
            self.dimensions = config.DEFAULT_MAP_DIMENSIONS
        self.trackingarea.pack(anchor=NW,fill=BOTH,expand=1)

    def SideFrame(self):
       
        self.sideframe = Frame(self.frame,width=100,height=400)
        self.sideframe.pack(side=RIGHT,expand=1,fill=BOTH)
        Label(self.sideframe, text="track").grid(row=0,column=0)
        Label(self.sideframe, text="BD_ADDR").grid(row=0,column=1)
        Label(self.sideframe, text="#_RCVR").grid(row=0,column=2)
        Label(self.sideframe, text="color").grid(row=0,column=3)

    def add_device(self,device_mac):
                    
        def mk_button_handler(button,color):
            def handle():
                result=tkColorChooser.askcolor()
                color[:] = list(result[1])
                button.config(bg=result[1])
            return handle

        row = len(self.device_list)+1
   
        checkbox_state = IntVar()
        checkbox_state.set(1)
        checkbox = Checkbutton(self.sideframe,variable=checkbox_state).grid(row=row,column=0)
        L1 = Label(self.sideframe, text=device_mac)
        L1.grid(row=row,column=1)
        L2 = Label(self.sideframe, text="#")
        L2.grid(row=row,column=2)
        color = list('blue')
        colorbutton = Button(self.sideframe,text="color")
        colorbutton.config(command=mk_button_handler(colorbutton,color), bg="blue")
        colorbutton.grid(row=row,column=3)

        self.device_list[device_mac] = (checkbox_state,color,(checkbox,L1,L2,colorbutton))




    #handle application closing
    def Close(self):
        if tkMessageBox.askokcancel("Quit","Do you really wish to quit?"):
            self.root.destroy()
    
    def History(self):
        length =  tkSimpleDialog.askinteger("Tracking History","Please input the history length",parent=self.root,minvalue=0,initialvalue=5)
        self.Hlength = length

    #handle opening the map
    def Load_Map(self):
        img_name = tkFileDialog.askopenfilename()
        if img_name == "":
            return
        self.image = Image.open(img_name)
        self.map = ImageTk.PhotoImage(self.image)
        optwindow = MapOptions(self.root, self.map_loaded)

    def map_loaded(self, map_dialog):
        
        if not map_dialog.val:
            return

        name = (map_dialog.e1.get())
        width = float(map_dialog.e2.get())
        height = float(map_dialog.e3.get())
        self.dimensions = (name,width,height)
        
        self.trackingarea.config(width=self.image.size[0],height=self.image.size[1])
        self.trackingarea.delete("map")
        self.trackingarea.create_image(0,0, anchor=NW, image = self.map, tag="map")
        self.trackingarea.pack(fill=BOTH, expand=1)
        
        
    def add_packet(self, packet):
        if not self.trackingarea.find_withtag("map"):
            return
        self.trackingarea.delete("loc")
        widthadj = self.image.size[0]/self.dimensions[1]
        heightadj = self.image.size[1]/self.dimensions[2]

        tracking_state, color, gui_element = self.device_list[packet.device_mac]
        if tracking_state.get() == 1:
            x, y = packet.position
            xloc, yloc = (x*widthadj, y*heightadj)
            c = ''.join(color)
            tag = str(packet.timestamp[0])
            self.trackingarea.create_rectangle(xloc-3, yloc-3, xloc+3, yloc+3, \
                                                   fill=c, tags=(tag))
        self.trackingarea.pack()

    def remove_packet(self, packet):
        tag = str(packet.timestamp[0])
        self.trackingarea.delete(tag)
        self.trackingarea.pack()
        
        
        
        
#file options dialog to define map dimensions
class MapOptions(tkSimpleDialog.Dialog):

    def __init__(self, parent, callback):
        self.callback = callback
        tkSimpleDialog.Dialog.__init__(self, parent)
    
    def body(self,master):
        Label(master, text="Name:").grid(row=0)
        Label(master, text="Width:").grid(row=1)
        Label(master, text="Height:").grid(row=2)
        
        self.e1 = Entry(master)
        self.e2 = Entry(master)
        self.e3 = Entry(master)
        
        self.e1.grid(row=0, column=1)
        self.e2.grid(row=1, column=1)
        self.e3.grid(row=2, column=1)
        
        return self.e1
    
    def validate(self):
        self.val = True
        return 1

    def apply(self):
        self.callback(self)
        
        

if __name__ == '__main__':
    s = scan_server.TrackingPipeline()
    a = App()
    s.scan_server.add_new_device_callback(lambda dev: a.evt_queue.put(dev))
    s.add_new_position_callback(lambda packet: a.evt_queue.put(packet))

    #m = Mysql_logger.MysqlLogger()
    #s.add_new_position_callback(lambda packet: m.log(packet))

    try:
        a.mainloop()
    except KeyboardInterrupt:
        pass

    #m.stop()
version: 1
update_configs:
  - package_manager: "python"
    directory: "/"
    update_schedule: "live"
    allowed_updates:
      - match:
          # Only includes indirect (aka transient/sub-dependencies) for
          # supported package managers: ruby:bundler, python, php:composer, rust:cargo
          update_type: "
import math,time,random
import data_packet, config

class DataGenerator():
    """class used to get pseudo-random data in order to test tracking algorithms"""

    def __init__(self, error):
        
        self.receiver_positions = config.RECEIVER_POSITIONS
        self.mac = "Generator Device"
        self.error = error
        
    def get_position(self):
        """Return an x,y tuple representing the current position."""
        raise NotImplementedError

    def get_data(self):
        """Return a list of DataPackets corresponding to the receiver updates for this timestep. """
        x,y = self.get_position()

        rec = self.receiver_positions.keys()
        dist =  [((self.receiver_positions[i][0]-x)**2 + \
                      (self.receiver_positions[i][1] - y)**2)**.5 for i in rec]
        
        RSSI = [(-40*math.log(i,10) - 50.3) for i in dist]
        noisyRSSI = [int(random.gauss(R,self.error)) for R in RSSI]
                
        packets = [data_packet.DataPacket( \
                (time.time(), 0), rec[i] , self.mac , noisyRSSI[i]) \
                       for i in range(len(rec))]
        
        return packets        

class CircleDataGenerator(DataGenerator):
    
    def __init__(self, error, radius):
        DataGenerator.__init__(self, error)
        self.mac = "CircleDataGenerator"

        self.radius = radius
        
        self.theta = 0
        self.last_update = time.time()
        
    def get_position(self):

        elapsed = time.time() - self.last_update
        self.last_update = time.time()
        self.theta += 2*elapsed

        x = self.radius * (math.cos(self.theta) + 1)
        y = self.radius * (math.sin(self.theta) + 1)
        
        return (x, y)
    

class LinearInterpolator(DataGenerator):
    
    def __init__(self,error,corners_file):
        DataGenerator.__init__(self,error)
        self.mac = "LinearInterpolator"

        f = open(corners_file)
        self.points = [map(float, line[:-1].split(',')) for line in f]
        self.target_point = 1
        self.last_corner = time.time()

        self.time_between_points = 3

    def get_position(self):
        ellapsed = time.time() - self.last_corner
        p0 = self.points[self.target_point]
        p1 = self.points[self.target_point-1]
        x = p1[0] + (p0[0] - p1[0])*(ellapsed/self.time_between_points)
        y = p1[1] + (p0[1] - p1[1])*(ellapsed/self.time_between_points)
        if ellapsed > self.time_between_points:
            self.target_point = (self.target_point +1)% len(self.points)
            self.last_corner = time.time()
        return (x,y)
    

DATA_GENERATORS = [LinearInterpolator(.05, 'points1.txt'), \
                       CircleDataGenerator(1, 0.4)]


if __name__ == '__main__':
    data_gen = CircleDataGenerator(20, .1)
    for i in range(10):
        time.sleep(1.0)
        print str(data_gen.get_data())
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
class DataPacket(object):
    
    __slots__ = ['timestamp', 'receiver_mac', 'device_mac', 'rssi', 'position']
    
    def __init__(self, timestamp, receiver_mac, device_mac, rssi, position = None):
        
        self.timestamp = timestamp
        self.receiver_mac = receiver_mac
        self.device_mac = device_mac
        self.rssi = rssi
        self.position = position
    
    def __getstate__(self):
        return (self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position)
    
    def __setstate__(self, state):
        self.timestamp, self.receiver_mac, self.device_mac, self.rssi, self.position = state

    def __repr__(self):
        return "(DataPacket: t=%f, r=%s, d=%s, rssi=%d, pos=%s)" % (self.timestamp[0], self.receiver_mac, self.device_mac, self.rssi, str(self.position))
!/usr/bin/env python2.7
from tracking_method import TrackingMethod, RandomDataTracker, NLMaPTracker
from data_generator import CircleDataGenerator, LinearInterpolator
import config, data_packet, data_generator
import socket, struct, threading, Queue, multiprocessing, time

PORT = 2410
MSG_MAX_LEN = 128

class ScanListener(threading.Thread):
    """Deocde receiver packet data, asynchronously.
        Provides callbacks on receipt of packets.
    """
    
    def __init__(self, addr='0.0.0.0', port=PORT, open=True):
        threading.Thread.__init__(self)
        self.daemon = True
        
        self.addr = addr
        self.port = port
        
        self.callbacks = []
        if open:
            self.open()
        
    def open(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((self.addr, self.port))
        
    def add_callback(self, callback):
        self.callbacks.append(callback)

    def decode_packet(self, data):
        try:
            #print 'Packet (len %s): %s' % (len(data), [ord(x) for x in data])
            fields = struct.unpack('!LLBBBBBBBBBBBBb', data)
            tstamp_sec, tstamp_usec = fields[0:2]
            receiver_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[2:8]])
            device_mac = ':'.join([hex(f)[2:].zfill(2) for f in fields[13:7:-1]])  # Yes, the bluetooth address comes over backwards
            rssi = fields[14]
            p = data_packet.DataPacket((tstamp_sec, tstamp_usec), receiver_mac, device_mac, rssi)
            print p
            return p
        except Exception, e:
            print 'Malformed packet (%s); dropped' % str(e)

    def run(self):    
        while True:
            data, addr = self.sock.recvfrom(MSG_MAX_LEN)
            info = self.decode_packet(data)
            for c in self.callbacks:
                c(info)

class FakeListener(ScanListener):
    """Return fake data, for the lulz."""

    def __init__(self):
        ScanListener.__init__(self, open=False)
        self.data_sources = data_generator.DATA_GENERATORS
    
    def run(self):
        while True:
            time.sleep(1.0/config.DATA_FREQ)
            data = reduce(lambda x, y: x+y, [source.get_data() for source in self.data_sources])
            for packet in data:
                for c in self.callbacks:
                    c(packet)


class ScanServer(object):
    """Process decoded packet data to provide higher-level tracking status.
    
        self.data is a dictionary mapping device macs to receiver dictionaries,
        each of which mapps receiver macs to a stack of the most recent contacts
        between the given device / receiver pair.
    
    """
    
    def __init__(self, *args, **kwargs):
        if "fakeit" in kwargs and kwargs["fakeit"]:
            self.listener = FakeListener()
        else:
            del kwargs['fakeit']
            self.listener = ScanListener(*args, **kwargs)
        
        self.listener.add_callback(self.process_packet)
        
        self.devices = []
        self.receivers = []
        self.data = dict()
        
        self.new_device_callbacks = []
        self.new_data_callbacks = []
        
        self.listener.start()
        
    def add_new_device_callback(self, callback):
        self.new_device_callbacks.append(callback)
    
    def add_new_data_callback(self, callback):
        self.new_data_callbacks.append(callback)
    
    def process_packet(self, packet):

        if not packet.device_mac in self.data:
            self.data[packet.device_mac] = {packet.receiver_mac : [packet.rssi]}
            self.devices.append(packet.device_mac)
            
            map(lambda c: c(packet.device_mac), self.new_device_callbacks)
            
        else:
            if not packet.receiver_mac in self.data[packet.device_mac]:
                self.data[packet.device_mac][packet.receiver_mac] = [packet.rssi]
                if not packet.receiver_mac in self.receivers:
                    self.receivers.append(packet.receiver_mac)
            else:
                self.data[packet.device_mac][packet.receiver_mac].append(packet.rssi)
        
        map(lambda c: c(packet), self.new_data_callbacks)
        
                    
class TrackingThread(multiprocessing.Process):
    """Multiprocessing wrapper around TrackingMethod."""
    
    def __init__(self, method):
        multiprocessing.Process.__init__(self)
        self.daemon = True
        
        self.method = method
        self.in_queue = multiprocessing.Queue()
        self.out_queue = multiprocessing.Queue()
    
    def handle_new_data(self, data):
        self.in_queue.put(data)
    
    def get_new_packet(self, timeout):
        try:
            return self.out_queue.get(True, timeout)
        except:
            return None
    
    def run(self):
        while True:
            packet = self.in_queue.get()
            packet.position = self.method.get_position(packet)
            self.out_queue.put(packet)

class TrackingPipeline(object):
    """Manage a tracking pipline, handling incoming data to produce 
        a stream of position updates. Callbacks will be invoked as
        c(device, new_pos)
    """
    
    def __init__(self, fakeit=True):
        self.scan_server = ScanServer(fakeit=fakeit)
        self.tracking_threads = dict()
        self.new_position_callbacks = []
        
        self.shouldExit = False
        
        self.scan_server.add_new_device_callback(self.handle_new_device)
        self.scan_server.add_new_data_callback(self.handle_new_data)
        
        self.merge_thread = threading.Thread(target=self.merge_queues)
        self.merge_thread.daemon = True
        self.merge_thread.start()
    
    def add_new_position_callback(self, callback):
        self.new_position_callbacks.append(callback)
        
    def get_tracking_method(self):
        return NLMaPTracker
    
    def handle_new_device(self, device_mac):
        method_cls = self.get_tracking_method()
        method = method_cls(device_mac)
        self.tracking_threads[device_mac] = TrackingThread(method)
        self.tracking_threads[device_mac].start()
    
    def handle_new_data(self, packet):
        if not self.tracking_threads[packet.device_mac].is_alive():
            if self.shouldExit:
                return
            print 'Reviving dead tracking thread'
            self.handle_new_device(packet.device_mac)
        self.tracking_threads[packet.device_mac].handle_new_data(packet)
    
    def merge_queues(self):
        while True:
            for device, tracker in self.tracking_threads.items():
                packet = tracker.get_new_packet(0.1)
                if packet and packet.position:
                    map(lambda c: c(packet), self.new_position_callbacks)
    
    def shutdown(self):
        self.shouldExit = True
        for thread in self.tracking_threads.values():
            thread.terminate()
    
    
        
import config
import ta
import pandas as pd
import time
from binance.client import Client
from binance.enums import *
import winsound

MA_PERIOD = 20
RSI_PERIOD = 6
LOOKBACK_PERIOD = 25
RSI_OVERBOUGHT = 70
RSI_OVERSOLD = 30
TRADE_SYMBOL = 'ETHUSDT'
TRADE_QUANTITY = 0.004

in_position = False
sell_position = False
last_buy = 0
sl_value = 0
p_value = 0
doc = 'log.txt'
FrameConnection = True
buyprice = 0


client = Client(config.API_KEY, config.API_SECRET)

def order(side, quantity, symbol,order_type=ORDER_TYPE_MARKET):
    global doc
    try:
        print("sending order")
        order = client.create_order(symbol=symbol, side=side, type=order_type, quantity=quantity)
        print(order)
        buyprice = float(order['fills'][0]['price'])
    except Exception as e:
        print("an exception occured - {}".format(e))
        log = open(doc, 'a')
        log.write("an exception occured - {}\n".format(e))
        log.close()
        return [False]

    return [True, buyprice]


def getdata(symbol,interval,lookback):
    global FrameConnection
    try:
        frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback + ' min ago UTC'))
        frame = frame.iloc[:,:6]
        frame.columns = ['Time','Open','High','Low','Close','Volume']
        frame = frame.set_index('Time')
        frame.index = pd.to_datetime(frame.index, unit='ms')
        frame = frame.astype(float)
        FrameConnection = True
        return frame

    except Exception as e:
        print("an exception occured - {}".format(e))
        print()
        FrameConnection = False
        return False



def tecnicals(df):
    df['rsi'] = ta.momentum.rsi(df.Close, window=RSI_PERIOD)
    df['macd'] = ta.trend.macd_diff(df.Close)
    df['sma0'] = ta.trend.sma_indicator(df.Close, window=5)
    df['sma1'] = ta.trend.sma_indicator(df.Close, window=10)
    df['sma2'] = ta.trend.sma_indicator(df.Close, window=MA_PERIOD)
    df['K'] = ta.momentum.stoch(df.High,df.Low,df.Close, window=RSI_PERIOD, smooth_window=3)
    df['D'] = df['K'].rolling(3).mean()
    df['bolll'] = ta.volatility.bollinger_lband(df.Close)
    df['bollh'] = ta.volatility.bollinger_hband(df.Close)
    df['bollm'] = ta.volatility.bollinger_mavg(df.Close)
    df.dropna(inplace=True)



def getframe():
    df = getdata(TRADE_SYMBOL, '1m', '100')
    if not FrameConnection:
        return False
    tecnicals(df)
    return df

def strategy(df):
    global in_position, last_buy, doc, sell_position, buyprice,sl_value,p_value

    #diminui o frame
    df = df.iloc[-LOOKBACK_PERIOD:]

    #verifica se existe
    kl = df[df.K < RSI_OVERSOLD]
    kh = df[df.K > RSI_OVERBOUGHT]
    dl = df[df.D < RSI_OVERSOLD]
    dh = df[df.D > RSI_OVERBOUGHT]

    K_low = len(kl.index) > 0
    K_high = len(kh.index) > 0
    D_low = len(dl.index) > 0
    D_high = len(dh.index) > 0

    #define os atuais
    close_now = float(df.Close.iloc[-1])
    macd_now = float(df.macd.iloc[-1])
    rsi_now = float(df.rsi.iloc[-1])
    K = float(df.K.iloc[-1])
    D = float(df.D.iloc[-1])
    time_now = df.index[-1]
        
    print('atual close: {}'.format(close_now))
    print('atual MACD: {}'.format(macd_now))
    print('atual RSI: {}'.format(rsi_now))
    print('atual %K: {}'.format(K))
    print('atual %D: {}'.format(D))
    print('atual time: {}'.format(time_now))
    print()
    print("buy position = {}".format(in_position))
    print("sell position = {}".format(sell_position))
    #print(df)
    print()

    #define as flag booleanas
    rsi = rsi_now > 50
    macd = macd_now > 0
    S_low = K_low and D_low
    S_high = K_high and D_high
    stoch = (K < 70) and (K > 30) and (D < 70) and (D > 30)

    #define stoploss, se nessesario
    if in_position:
        stop_loss = close_now < sl_value
        profit = close_now > p_value
    
    if sell_position:
        stop_loss = close_now > sl_value
        profit = close_now < p_value

    if (not in_position) and (not sell_position):
        stop_loss = False
        profit = False
    

    #estrategia de posicao de venda
    if S_high and stoch and (not rsi) and (not macd) and (not in_position) and (not sell_position):
        sell_position = True  
        sl_value = max(kh.Close)

        if (close_now * (1.0015) ) < sl_value:
            sl_value = close_now*(1.0015)
            
        p_value  = close_now - ((sl_value - close_now) * 1.5)

    
    #estrategia de saida
    if stop_loss or profit:
        if in_position:
            print("Sell! Sell! Sell!")

            # put binance sell logic here
            #order_succeeded = order(SIDE_SELL, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded = [True,close_now]

            if order_succeeded[0]:
                sellprice = order_succeeded[1]
                log = open(doc, 'a')
                log.write("Sell! Sell! Sell!: {}\n".format(sellprice))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = False
                
        else:
            print("We don't own any. Nothing to do.")
            sell_position = False

   
    #esttrategia de posio de compra
    if S_low and stoch and rsi and macd and (not sell_position):
        if in_position:
            print("It is oversold, but you already own it, nothing to do.")
        else:
                    
            print("Oversold! Buy! Buy! Buy!")
            # put binance buy order logic here

            #order_succeeded = order(SIDE_BUY, TRADE_QUANTITY, TRADE_SYMBOL)
            order_succeeded =[True,close_now]

            if order_succeeded[0]:
                buyprice = order_succeeded[1]
                last_buy = buyprice

                log = open(doc, 'a')
                log.write("Buy! Buy! Buy!: {}\n".format(last_buy))
                log.write("MACD: {}\n".format(macd_now))
                log.write("Rsi: {}\n".format(rsi_now))
                log.write("%K: {}\n".format(K))
                log.write("%D: {}\n".format(D))
                log.write("Time: {}\n".format(time_now))
                log.close()
                in_position = True

                sl_value = min(kl.Close)

                if (close_now * (0.995) ) > sl_value:
                    sl_value = close_now*(0.995)
            
                p_value  = ((close_now-sl_value) * 1.5) + close_now

def main():
    while True:
        gt = getframe()

        if not FrameConnection:
            print("waiting for connection")
            print()
            time.sleep(1)
            continue

        strategy(gt)
        time.sleep(1)

if __name__ == '__main__':
    main()
href="https://github.com/djsime1/awesome-crip-bot }">
  <img src="https://user-images.githubusercontent.com/8518150/179464273-7927420c-b60a-48ab-9eb9-d69b563c0a0b.png" align="center" alt="Flipper Zero FAQ" title="Flipper Zero FAQ">
</a>
{{$ Crip-bot }}
<table align="center">
  <tr><th colspan="8">Table of Contents</th></tr>
  <tr>
    <td><a href="#meta-">Meta</a></td>
    <td><a href="#general-">General</a></td>
    <td><a href="#sub-ghz-">Sub-GHz</a></td>(fp-+)
    <td><a href="#nfc--rfid-">NFC & RFID</a></td>
    <td><a href="#infrared-">Infrared</a></td>
    <td><a href="#badusb-">BadUSB</a></td>
    <td><a href="#ibutton-">iButton</a></td>
    <td><a href="#wifi-board-">WiFi board</a></td>
  </tr>
<table>

## Preamble [](#top)
- *This is a community FAQ. Please consider also reading the [Official docs](https://docs.flipperzero.one/).*
- *It is written with information from the latest dev firmware, you may have to wait for a firmware (pre)release before some of the questions/answers become relevant.*
- *This FAQ is still being worked on, and contributions are welcome.*
- *If your question isn't answered here, **SEARCH** the [Discord](https://flipperzero.one/discord) and check pinned messages before asking there.*



## Meta [](#top)

### What is Awesome Flipper Zero?
> It's an [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) that I ([djsime1](https://dj.je)) created shortly after receiving Lurat, my lovely dolphin sidekick.

### What is an Awesome List?
> An [Awesome List](https://github.com/sindresorhus/awesome/blob/main/awesome.md) is a collection of links and resources related to some project or topic. Think of it like a central curated hub to discover interesting stuff.


### How can I contribute to this repo?
> Perferably, open a [Pull Request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) with your changes, or use one of the methods in the next question to contact me.

### I found a mistake, broken link, or something else. What should I do?
> Open a [new discussion](https://github.com/djsime1/awesome-flipperzero/discussions/new) on this repo, or contact me via one of the methods listed on [this page](https://dj.je/pages/contact).

### Why are there so many unmerged pull requests?
> If there's multiple small pull requests open at the same time, I'll often merge them together as a single update. Due to the way GitHub works, I'm unable to mark them as merged when I do this. To compensate, I include the contributors as co-authors on the commit, and mention the Pull Request ID's as part of the update message.

### This is really cool! Is there a way I can donate to you?
. You can find my [PATREON](https://www.patreon.com/RogueMaster) to donate


## General [](#top)

### What MicroSD Card should I use?
> - It should be a reputable brand (Like SanDisk, Sony, etc.) because often cheaper cards don't fully support the communication protocol Flipper uses. 
> - The card should have a capacity between 4 and 64 GB, but an 8 GB card is MORE than enough.
> - After inserting the card, use the Flipper's setting menu to format (clear) and test the card.
> - Before ejecting the card, unmount it via the Settings menu to ensure data isn't corrupted.
> - Note: You might need a paperclip or similar object to push the SD Card in and out of the device.
> - Read the [official documentation](https://docs.flipperzero.one/basics/sd-card) for more information!

### How do I install databases and dumps?
> Make sure there's a working MicroSD Card in the device first by following the steps above.
> Once you download the dump, you can use qFlipper or the Flipper mobile app to transfer them. If you're transfering a large file or many at once, you can also eject the SD Card from Flipper and insert it in your computer for faster transfers.
> - In qFlipper: Plug your device in, go to the file browser tab, navigate into the SD Card, and drop files in their corresponding folders (The folder names are similar to the file extensions).
> - For mobile apps: Make sure you're connected via Bluetooth, save the file to the app's archive, and synchronize it back to the device.
> - For plugging the SD Card into your PC, drop files in their corresponding folders (The folder names are similar to the file extensions).

### How do I install applications and plugins?
> Assuming the application has been packaged as a `.fap` file, installing it is as easy as placing it inside the `apps` directory on your Flipper's SD card. You can launch the app from the `Applications` app. If the app hasn't been compiled into a `.fap`, either *kindly* ask the author or compile it yourself.

### How do I install custom firmwares?
> Make sure there's a working MicroSD Card in your Flipper and head over to [RM Custom Firmware](https://github.com/RogueMaster/flipperzero-firmware-wPlugins/releases/latest). Make sure qFlipper is closed. Use the Web Installer link and you will be all set. Alternatively, look for releases and find the `.dfu` file or update package (typically a `.tar`, `.tar.gz`, or `.zip` file, it always contains a file named `update.fuf`).
> - If you only have a `.dfu`, it must be installed using the "Install from file" option in qFlipper. Select the file and begin the installation.
> - If you have an update package, you can either install it with qFlipper, or install it manually through the Micro SD card by following the steps below.
> - To manually install an update package, extract and transfer the folder (not the original archive file) to the `update` folder on the SD Card (create the folder if it doesn't already exist). Once transferred, go to the desktop/idle screen of the Flipper, press down to access the file browser, then left to view all folders. From there, open the `update` folder (typically at the bottom of the list) and find the folder you just transferred. Lastly, select the file named `update` and choose "Run in app" to install the firmware.
> 
> If there was no pre-compiled update file/package, you'll have to build the firmware yourself. See the next question for details.
> For more information, read the [official documentation](https://docs.flipperzero.one/basics/firmware-update).

### Where and when are developer Q&A sessions held?
> Question and Answer session are held every week on Saturday, at 01:00 and 13:00 (GMT)
> 
> | Time zone      | Side A  |  Side B |
> | :------------: | :-----: | :-----: |
> | GMT/UTC        | 01:00   | 13:00   |
> | Pacific (PDT)  | 6:00 PM | 6:00 AM |
> | Mountain (MDT) | 7:00 PM | 7:00 AM |
> | Central (CDT)  | 8:00 PM | 8:00 AM |
> | Eastern (EDT)  | 9:00 PM | 9:00 AM |
> | China Standard | 09:00   | 21:00   |
> | India Standard | 06:30   | 18:30   |

### Are there archives of past Q&A sessions?
> Archival is a community effort, so only some are available.
> [https://github.com/flipperdevices/flipper-questions-and-answers](https://github.com/flipperdevices/flipper-questions-and-answers)

### How do I write/compile my own applications/plugins/firmware/assets?
<blockquote>
  <em>(The following is a summary of the <a href="https://github.com/flipperdevices/flipperzero-firmw
version: 2
updates:
  - package-ecosystem: github-actions
    directory: /
    schedule:
      interval: weekly
    groups:
      actions-minor:
        update-types:
          - minor
          - patch
    ignore:
      - dependency-name: 'actions/attest-build-provenance'

  - package-ecosystem: npm
    directory: /
    schedule:
      interval: weekly
    groups:
      npm-development:
        dependency-type: development
        update-types:
          - minor
          - patch
      npm-production:
        dependency-type: production
        update-types:
          - patch
